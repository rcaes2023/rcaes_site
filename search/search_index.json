{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Research Computing","text":"<p>Fall 2023 | 16:107:606 Special Topics in Atmospheric Sciences Research Computing in Atmospheric and Environmental Sciences Rutgers University, Department of Environmental Sciences</p> <p></p>"},{"location":"Assignment_0/","title":"Create your Accounts on Amarel and GitHub","text":""},{"location":"Assignment_0/#amarel-account","title":"Amarel Account","text":"<p>https://oarc.rutgers.edu/amarel-cluster-access-request/</p>"},{"location":"Assignment_0/#github-account","title":"GitHub Account","text":"<p>https://github.com  Student Account: https://education.github.com/benefits?type=student</p>"},{"location":"Assignment_3/","title":"Assignment 3 - Numpy and Matplotlib","text":"<p>First import numpy and matplotlib</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\ndf = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates=['LST_DATE'])\ndf = df.set_index('LST_DATE')\n\n#########################################################\n#### BELOW ARE THE VARIABLES YOU SHOULD USE IN THE PLOTS!\n#### (numpy arrays) \n#### NO PANDAS ALLOWED!\n#########################################################\n\nt_daily_min = df.T_DAILY_MIN.values\nt_daily_max = df.T_DAILY_MAX.values\nt_daily_mean = df.T_DAILY_MEAN.values\np_daily_calc = df.P_DAILY_CALC.values\nsoil_moisture_5 = df.SOIL_MOISTURE_5_DAILY.values\nsoil_moisture_10 = df.SOIL_MOISTURE_10_DAILY.values\nsoil_moisture_20 = df.SOIL_MOISTURE_20_DAILY.values\nsoil_moisture_50 = df.SOIL_MOISTURE_50_DAILY.values\nsoil_moisture_100 = df.SOIL_MOISTURE_100_DAILY.values\ndate = df.index.values\n</pre> import pandas as pd  df = pd.read_csv('Millbrook_NY_daily_weather.csv', parse_dates=['LST_DATE']) df = df.set_index('LST_DATE')  ######################################################### #### BELOW ARE THE VARIABLES YOU SHOULD USE IN THE PLOTS! #### (numpy arrays)  #### NO PANDAS ALLOWED! #########################################################  t_daily_min = df.T_DAILY_MIN.values t_daily_max = df.T_DAILY_MAX.values t_daily_mean = df.T_DAILY_MEAN.values p_daily_calc = df.P_DAILY_CALC.values soil_moisture_5 = df.SOIL_MOISTURE_5_DAILY.values soil_moisture_10 = df.SOIL_MOISTURE_10_DAILY.values soil_moisture_20 = df.SOIL_MOISTURE_20_DAILY.values soil_moisture_50 = df.SOIL_MOISTURE_50_DAILY.values soil_moisture_100 = df.SOIL_MOISTURE_100_DAILY.values date = df.index.values In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[7]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Assignment_3/#assignment-3-numpy-and-matplotlib","title":"Assignment 3 - Numpy and Matplotlib\u00b6","text":""},{"location":"Assignment_3/#1-creating-and-manipulating-arrays","title":"1 Creating and Manipulating Arrays\u00b6","text":""},{"location":"Assignment_3/#11-create-two-2d-arrays-xx-and-yy-representing-coordinates-x-y-on-the-cartesian-plan","title":"1.1. Create two 2D arrays (xx and yy) representing coordinates x, y on the cartesian plan\u00b6","text":"<p>Both should cover the range (-2, 2) and have 100 points in each direction</p>"},{"location":"Assignment_3/#12-visualize-each-2d-array-using-pcolormesh","title":"1.2. Visualize each 2D array using <code>pcolormesh</code>\u00b6","text":"<p>Use the correct coordiantes for the x and y axes. Provide axis labels for all of your plots in this assignment.</p>"},{"location":"Assignment_3/#13-from-your-cartesian-coordinates-create-polar-coordinates-r-and-varphi","title":"1.3 From your cartesian coordinates, create polar coordinates $r$ and $\\varphi$\u00b6","text":"<p>Refer to the wikipedia page for the conversion formula. You will need to use numpy's <code>arctan2</code> function. Read its documentation.</p>"},{"location":"Assignment_3/#14-visualize-r-and-varphi-as-functions-of-x-and-y","title":"1.4. Visualize $r$ and $\\varphi$ as functions of $x$ and $y$\u00b6","text":""},{"location":"Assignment_3/#15-define-the-function-f-cos24r-sin24varphi-and-plot-it-as-a-function-of-x-and-y","title":"1.5 Define the function $f = \\cos^2(4r) + \\sin^2(4\\varphi)$ and Plot it as a function of $x$ and $y$\u00b6","text":""},{"location":"Assignment_3/#16-plot-the-mean-of-f-with-respect-to-the-x-axis","title":"1.6 Plot the mean of f with respect to the x axis\u00b6","text":"<p>as a function of y</p>"},{"location":"Assignment_3/#17-plot-the-mean-of-f-with-respect-to-the-y-axis","title":"1.7 Plot the mean of f with respect to the y axis\u00b6","text":"<p>as a function of x</p>"},{"location":"Assignment_3/#part-ii-making-plots-with-matplotlib-for-real-data","title":"Part II: Making plots with Matplotlib for real data\u00b6","text":"<p>In this problem, we will plot some daily weather data from a NOAA station in Millbrook, NY.</p> <p>The cell below uses pandas to load the data and populate a bunch of numpy arrays (<code>t_daily_min</code>, <code>t_daily_max</code>, etc.)</p>"},{"location":"Assignment_3/#21-use-numpy-to-calculate-mean-temperature-precipitation-and-soil-moisture-at-different-layers","title":"2.1 Use numpy to calculate mean temperature, precipitation and soil moisture at different layers.\u00b6","text":"<p>Write a loop to make the code short and efficient.</p>"},{"location":"Assignment_3/#22-use-the-numpy-arrays-to-try-to-re-create-the-plot-you-see-below","title":"2.2 Use the numpy arrays to try to re-create the plot you see below\u00b6","text":"<p>Hint: Try fill_between to plot range values</p>"},{"location":"Assignment_4/","title":"Assignment 4: Pandas","text":"In\u00a0[1]: Copied! <pre># do imports here\n</pre> # do imports here In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Use the following code to download a csv file of the NOAA IBTrACS hurrican dataset.</p> In\u00a0[\u00a0]: Copied! <pre>! wget https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/csv/ibtracs.since1980.list.v04r00.csv\n</pre> ! wget https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/csv/ibtracs.since1980.list.v04r00.csv In\u00a0[\u00a0]: Copied! <pre>df=pd.read_csv('ibtracs.since1980.list.v04r00.csv',usecols=range(12), skiprows  = [1], parse_dates=['ISO_TIME'],na_values=[-999, ' '])\n</pre> df=pd.read_csv('ibtracs.since1980.list.v04r00.csv',usecols=range(12), skiprows  = [1], parse_dates=['ISO_TIME'],na_values=[-999, ' ']) In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>You will notice some names are repeated.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Assignment_4/#assignment-4-pandas","title":"Assignment 4: Pandas\u00b6","text":""},{"location":"Assignment_4/#part-i-basic-pandas","title":"Part I: Basic Pandas\u00b6","text":""},{"location":"Assignment_4/#1-use-pandas-read_csv-function-to-open-the-ground-level-ozone-data-at-rutgers-site-in-2021-epa_aqs_ozone_rutgers_2022csv-as-a-dataframe","title":"1) Use Pandas <code>read_csv</code> function to open the ground-level ozone data at Rutgers site in 2021 ('EPA_AQS_Ozone_Rutgers_2022.csv') as a DataFrame\u00b6","text":"<p>(Don't use any special options). Display the first few rows and the DataFrame info.</p>"},{"location":"Assignment_4/#2-re-read-the-data-in-such-a-way-that-the-date-column-is-identified-as-date-and-date-is-used-as-the-index","title":"2) Re-read the data in such a way that the Date column is identified as date and Date is used as the index\u00b6","text":""},{"location":"Assignment_4/#3-rename-the-column-daily-max-8-hour-ozone-concentration-as-ozone","title":"3) Rename the column 'Daily Max 8-hour Ozone Concentration' as 'ozone'\u00b6","text":""},{"location":"Assignment_4/#4-use-describe-to-get-the-basic-statistics-of-ozone-in-2022","title":"4) Use <code>describe</code> to get the basic statistics of ozone in 2022\u00b6","text":""},{"location":"Assignment_4/#5-use-nlargest-to-get-the-10-days-with-highest-ozone-concentration-in-2022","title":"5) Use <code>nlargest</code> to get the 10 days with highest ozone concentration in 2022\u00b6","text":""},{"location":"Assignment_4/#6-make-a-time-series-plot-of-daily-ozone-concentration-in-2022","title":"6) Make a time series plot of daily ozone concentration in 2022\u00b6","text":""},{"location":"Assignment_4/#7-make-a-time-series-plot-of-monthly-average-ozone-concentration-in-2022","title":"7) Make a time series plot of monthly average ozone concentration in 2022\u00b6","text":""},{"location":"Assignment_4/#8-read-the-ozone-data-in-2021-and-merge-it-with-the-data-in-2022","title":"8) Read the ozone data in 2021, and merge it with the data in 2022.\u00b6","text":"<p>Remember to rename the ozone column in the new data before merging two dataframes.</p>"},{"location":"Assignment_4/#9-make-a-time-series-plot-of-monthly-average-ozone-concentration-from-2021-to-2022","title":"9) Make a time series plot of monthly average ozone concentration from 2021 to 2022\u00b6","text":""},{"location":"Assignment_4/#part-ii-advanced-pandas-with-hurricane-data","title":"Part II: Advanced Pandas with hurricane data\u00b6","text":""},{"location":"Assignment_4/#1-get-the-unique-values-of-the-basin-subbasin-and-nature-columns","title":"1) Get the unique values of the <code>BASIN</code>, <code>SUBBASIN</code>, and <code>NATURE</code> columns\u00b6","text":""},{"location":"Assignment_4/#2-rename-the-wmo_wind-column-to-wind-and-wmo_pres-column-to-pressure","title":"2) Rename the <code>WMO_WIND</code> column to <code>Wind</code>, and <code>WMO_PRES</code> column to <code>Pressure</code>\u00b6","text":""},{"location":"Assignment_4/#3-get-the-10-largest-rows-in-the-dataset-by-wind","title":"3) Get the 10 largest rows in the dataset by <code>Wind</code>\u00b6","text":""},{"location":"Assignment_4/#4-group-the-data-on-sid-and-get-the-10-largest-hurricanes-by-maximum-wind","title":"4) Group the data on <code>SID</code> and get the 10 largest hurricanes by maximum <code>Wind</code>\u00b6","text":""},{"location":"Assignment_4/#5-plot-the-count-of-all-datapoints-by-basin","title":"5) Plot the count of all datapoints by Basin\u00b6","text":"<p>as a bar chart</p>"},{"location":"Assignment_4/#6-plot-the-count-of-unique-hurricanes-by-basin","title":"6) Plot the count of unique hurricanes by Basin\u00b6","text":"<p>as a bar chart. (You will need to call <code>groupby</code> twice.)</p>"},{"location":"Assignment_4/#7-make-a-hexbin-of-the-location-of-datapoints-in-latitude-and-longitude","title":"7) Make a <code>hexbin</code> of the location of datapoints in Latitude and Longitude\u00b6","text":""},{"location":"Assignment_4/#8-find-hurricane-sandy-from-2012-and-plot-its-track-as-a-scatter-plot","title":"8) Find Hurricane Sandy (from 2012) and plot its track as a scatter plot\u00b6","text":"<p>Use wind speed to color the points.</p>"},{"location":"Assignment_4/#9-make-time-the-index-on-your-dataframe","title":"9) Make time the index on your dataframe\u00b6","text":""},{"location":"Assignment_4/#10-plot-the-count-of-all-datapoints-per-year-as-a-timeseries","title":"10) Plot the count of all datapoints per year as a timeseries\u00b6","text":"<p>You should use <code>resample</code></p>"},{"location":"Assignment_4/#11-plot-all-tracks-from-the-west-pacific-basinwp-in-2005-color-the-tracks-by-hurricane-sid","title":"11) Plot all tracks from the West Pacific (BASIN:'WP') in 2005. Color the tracks by hurricane SID.\u00b6","text":"<p>First create a subset dataframe by searching <code>SEASON</code> and <code>BASIN</code>. You will probably have to iterate through a <code>GroupBy</code> object from the subset dataframe.</p>"},{"location":"Assignment_4/#12-create-a-filtered-dataframe-that-contains-only-data-from-the-west-pacific-wp-basin","title":"12) Create a filtered dataframe that contains only data from the West Pacific (\"WP\") Basin\u00b6","text":"<p>Use this for the rest of the assignment</p>"},{"location":"Assignment_4/#13-plot-the-number-of-datapoints-per-day","title":"13) Plot the number of datapoints per day\u00b6","text":"<p>Make sure you figure is big enough to actually see the plot</p>"},{"location":"Assignment_4/#14-calculate-the-climatology-of-datapoint-counts-as-a-function-of-dayofyear","title":"14) Calculate the climatology of datapoint counts as a function of <code>dayofyear</code>\u00b6","text":""},{"location":"Assignment_5/","title":"Assignment 5 : Xarray","text":"<p>In this assignment, we will use Xarray to analyze top-of-atmosphere radiation data from NASA's CERES project.</p> <p> Public domain, by NASA, from Wikimedia Commons</p> <p>Start by importing xarray, numpy, and matplotlib</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <p>The answer is that each \"pixel\" or \"grid point\" of this dataset does not represent an equal area of Earth's surface. So naively taking the mean, i.e. giving equal weight to each point, gives the wrong answer.</p> <p>On a lat / lon grid, the relative area of each grid point is proportional to $\\cos(\\lambda)$. ($\\lambda$ is latitude)</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <p>This time around, you should have found something much closer to zero. Ask a climate scientist what the net energy imbalance of Earth due to global warming is estimate to be. Do you think our calculation is precise enough to detect this?</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied!"},{"location":"Assignment_5/#assignment-5-xarray","title":"Assignment 5 : Xarray\u00b6","text":""},{"location":"Assignment_5/#part-i-xarray-for-earths-energy-budget","title":"Part I: Xarray for earth's energy budget\u00b6","text":""},{"location":"Assignment_5/#11-open-the-ceres-dataset-and-display-its-contents","title":"1.1) Open the CERES dataset and display its contents.\u00b6","text":"<p>The CERES dataset has been predownloaded and processed. You can access the dataset here: /scratch/xj103/rcaes/CERES_EBAF-TOA_Edition4.0_200003-201701.condensed.nc</p>"},{"location":"Assignment_5/#12-print-out-the-long_name-attribute-of-each-variable","title":"1.2) Print out the <code>long_name</code> attribute of each variable\u00b6","text":""},{"location":"Assignment_5/#21-calculate-the-time-mean-of-the-entire-dataset","title":"2.1) Calculate the time-mean of the entire dataset\u00b6","text":""},{"location":"Assignment_5/#22-from-this-make-a-2d-plot-of-the-the-time-mean-toa-longwave-shortwave-and-incoming-solar-radiation-flux","title":"2.2) From this, make a 2D plot of the the time-mean TOA longwave, shortwave, and incoming solar radiation flux\u00b6","text":"<p>(All-Sky conditions)</p> <p>Note the sign conventions on each variable.</p>"},{"location":"Assignment_5/#23-add-up-the-three-variables-above-and-verify-visually-that-they-are-equivalent-to-the-toa-net-flux","title":"2.3) Add up the three variables above and verify (visually) that they are equivalent to the TOA net flux\u00b6","text":"<p>You have to pay attention to and think about the sign conventions for each variable in order to get this to work.</p>"},{"location":"Assignment_5/#31-calculate-the-global-mean-of-toa-net-radiation-directly-from-the-dataset","title":"3.1) Calculate the global mean of TOA net radiation directly from the dataset\u00b6","text":"<p>Since the Earth is approximately in radiative balance, the net TOA radiation should be zero. But taking the naive mean from this dataset, you should find a number far from zero. Why?</p>"},{"location":"Assignment_5/#32-create-a-weight-array-proportional-to-coslambda-with-a-mean-value-of-1","title":"3.2) Create a <code>weight</code> array proportional to $\\cos(\\lambda)$ with a mean value of 1\u00b6","text":"<p>Verify its mean is 1 and plot it. Be careful about radians vs. degrees.</p>"},{"location":"Assignment_5/#33-redo-your-global-mean-toa-net-radiation-calculation-with-this-weight-factor","title":"3.3) Redo your global mean TOA net radiation calculation with this weight factor\u00b6","text":"<p>Remember Xarray's handling of broadcasting. Don't make this harder than it needs to be.</p>"},{"location":"Assignment_5/#34-now-that-you-have-a-weight-factor-verify-that-the-toa-incoming-solar-outgoing-longwave-and-outgoing-shortwave-approximately-match-up-with-the-cartoon-above","title":"3.4) Now that you have a <code>weight</code> factor, verify that the TOA incoming solar, outgoing longwave, and outgoing shortwave approximately match up with the cartoon above\u00b6","text":""},{"location":"Assignment_5/#41-plot-the-time-mean-cloud-area-fraction-day-and-night","title":"4.1) Plot the time-mean cloud area fraction (day and night)\u00b6","text":""},{"location":"Assignment_5/#42-define-boolean-masks-for-low-cloud-area-le-25-and-high-cloud-area-ge-75","title":"4.2) Define boolean masks for low cloud area ($\\le$ 25%) and high cloud area ($\\ge$ 75%)\u00b6","text":"<p>Use the whole dataset, not the time mean.</p>"},{"location":"Assignment_5/#43-calculate-and-plot-composites-of-time-mean-outgoing-shortwave-and-longwave-radiation-for-low-and-high-cloud-area-regions","title":"4.3) Calculate and plot composites of time-mean outgoing shortwave and longwave radiation for low and high cloud area regions\u00b6","text":"<p>Your results should be 2D maps.</p> <p>Xarray's where function will be helpful.</p>"},{"location":"Assignment_5/#51-make-a-figure-of-4-subplots-that-show-the-seasonal-mean-toa-outgoing-shortwave-and-another-figure-for-toa-longwave-radiation","title":"5.1) Make a figure of 4 subplots that show the seasonal mean TOA outgoing shortwave and another figure for TOA longwave radiation\u00b6","text":""},{"location":"Assignment_5/#52-subset-the-dataset-for-nj-region-74-w-756-w-388-n-415-n-and-calculate-the-monthly-climatology-of-cloud-visible-optical-depth-and-cloud-area-fraction","title":"5.2) Subset the dataset for NJ region (74\u02daW - 75.6\u02daW, 38.8\u02daN - 41.5\u02daN) and calculate the monthly climatology of cloud visible optical depth and cloud area fraction\u00b6","text":""},{"location":"Final_Project/","title":"Final Project","text":""},{"location":"Final_Project/#part-i-individual-project-20","title":"Part I: Individual Project (20%)","text":"<p>The goal of the final project is to assess your ability to combine and apply the skills you have learned in class in the context of a real-world research problem. Our class has mostly focused on tools for data analysis and visualization, so this must be the focus of your final project. Specifically, we seek to assess your ability to do the following tasks: \u2022   Discover and download real datasets in standard formats (e.g. CSV, netCDF) \u2022   Load the data into pandas or xarray, performing any necessary data cleanup (dealing with missing values, proper time encoding, etc.) along the way. \u2022   Perform realistic scientific calculation involving, for example tasks such as grouping, aggregating, and applying mathematical formulas. \u2022   Visualize your results in well-formatted plots.</p>"},{"location":"Final_Project/#part-ii-reproducing-another-students-project-10","title":"Part II: Reproducing Another Student\u2019s Project (10%)","text":"<p>The goal of the second part is to assess the reproducibility of the student\u2019s project, and whether the students can reproduce and collaborate with others on code development. Our class focuses on conducting open-source research that are transparent, accessible, reproducible and inclusive, so your final project should demonstrate your understanding and ability to perform open-source research. We seek to assess your ability to: \u2022   Clearly document your analysis to make it reproducible. \u2022   Reproduce the other student\u2019s final project. \u2022   Bonus points will be given if the students submit pull requests and issues for code development. </p>"},{"location":"Lecture_2_Core_Python/","title":"Lecture 2 Core Python Language","text":"In\u00a0[1]: Copied! <pre># comments are anything that comes after the \"#\" symbol\na = 1       # assign 1 to variable a\nb = \"hello\" # assign \"hello\" to variable b\n</pre> # comments are anything that comes after the \"#\" symbol a = 1       # assign 1 to variable a b = \"hello\" # assign \"hello\" to variable b <p>The following identifiers are used as reserved words, or keywords of the language, and cannot be used as ordinary identifiers. They must be spelled exactly as written here:</p> <pre><code>False      class      finally    is         return\nNone       continue   for        lambda     try\nTrue       def        from       nonlocal   while\nand        del        global     not        with\nas         elif       if         or         yield\nassert     else       import     pass\nbreak      except     in         raise</code></pre> <p>Additionally, the following a built in functions which are always available in your namespace once you open a python interpreter</p> <pre><code>abs() dict() help() min() setattr() all() dir() hex() next() slice() any()\ndivmod() id() object() sorted() ascii() enumerate() input() oct() staticmethod()\nbin() eval() int() open() str() bool() exec() isinstance() ord() sum() bytearray()\nfilter() issubclass() pow() super() bytes() float() iter() print() tuple()\ncallable() format() len() property() type() chr() frozenset() list() range()\nvars() classmethod() getattr() locals() repr() zip() compile() globals() map()\nreversed() __import__() complex() hasattr() max() round() delattr() hash()\nmemoryview() set()</code></pre> In\u00a0[2]: Copied! <pre># how to we see our variables?\nprint(a)\nprint(b)\nprint(a,b)\n</pre> # how to we see our variables? print(a) print(b) print(a,b) <pre>1\nhello\n1 hello\n</pre> <p>All variables are objects. Every object has a type (class). To find out what type your variables are</p> In\u00a0[5]: Copied! <pre># as a shortcut, iPython notebooks will automatically print whatever is on the last line\ntype(b)\n</pre> # as a shortcut, iPython notebooks will automatically print whatever is on the last line type(b) Out[5]: <pre>str</pre> In\u00a0[6]: Copied! <pre>type(a) is int\n</pre> type(a) is int Out[6]: <pre>True</pre> <p>Different objects attributes and methods, which can be accessed via the syntax <code>variable.method</code></p> <p>IPython will autocomplete if you press <code>&lt;tab&gt;</code> to show you the methods available.</p> In\u00a0[7]: Copied! <pre># this returns the method itself\nb.capitalize\n</pre> # this returns the method itself b.capitalize Out[7]: <pre>&lt;function str.capitalize()&gt;</pre> In\u00a0[8]: Copied! <pre># this calls the method\nb.capitalize()\n# there are lots of other methods\n</pre> # this calls the method b.capitalize() # there are lots of other methods Out[8]: <pre>'Hello'</pre> In\u00a0[9]: Copied! <pre># binary operations act differently on different types of objects\nc = 'World'\nprint(b + c)\nprint(a + 2)\nprint(a + b)\n</pre> # binary operations act differently on different types of objects c = 'World' print(b + c) print(a + 2) print(a + b) <pre>helloWorld\n3\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 5\n      3 print(b + c)\n      4 print(a + 2)\n----&gt; 5 print(a + b)\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'</pre> In\u00a0[10]: Copied! <pre># addition / subtraction\n1+1-5\n</pre> # addition / subtraction 1+1-5 Out[10]: <pre>-3</pre> In\u00a0[11]: Copied! <pre># multiplication\n5 * 10\n</pre> # multiplication 5 * 10 Out[11]: <pre>50</pre> In\u00a0[12]: Copied! <pre># division\n1/2\n</pre> # division 1/2 Out[12]: <pre>0.5</pre> In\u00a0[13]: Copied! <pre># that was automatically converted to a float\ntype(1/2)\n</pre> # that was automatically converted to a float type(1/2) Out[13]: <pre>float</pre> In\u00a0[13]: Copied! <pre># exponentiation\n2**4\n</pre> # exponentiation 2**4 Out[13]: <pre>16</pre> In\u00a0[14]: Copied! <pre># rounding\nround(9/10)\n</pre> # rounding round(9/10) Out[14]: <pre>1</pre> In\u00a0[15]: Copied! <pre># built in complex number support\n(1+2j) / (3-4j)\n</pre> # built in complex number support (1+2j) / (3-4j) Out[15]: <pre>(-0.2+0.4j)</pre> In\u00a0[15]: Copied! <pre># logic\nTrue and True\n</pre> # logic True and True Out[15]: <pre>True</pre> In\u00a0[16]: Copied! <pre>True and False\n</pre> True and False Out[16]: <pre>False</pre> In\u00a0[17]: Copied! <pre>True or True\n</pre> True or True Out[17]: <pre>True</pre> In\u00a0[18]: Copied! <pre>(not True) or (not False)\n</pre> (not True) or (not False) Out[18]: <pre>True</pre> In\u00a0[19]: Copied! <pre>x = 100\nif x &gt; 0:\n    print('Positive Number')\nelif x &lt; 0:\n    print('Negative Number')\nelse:\n    print ('Zero!')\n</pre> x = 100 if x &gt; 0:     print('Positive Number') elif x &lt; 0:     print('Negative Number') else:     print ('Zero!') <pre>Positive Number\n</pre> In\u00a0[20]: Copied! <pre># indentation is MANDATORY\n# blocks are closed by indentation level\nif x &gt; 0:\n    print('Positive Number')\n    if x &gt;= 100:\n        print('Huge number!')\n</pre> # indentation is MANDATORY # blocks are closed by indentation level if x &gt; 0:     print('Positive Number')     if x &gt;= 100:         print('Huge number!') <pre>Positive Number\nHuge number!\n</pre> In\u00a0[21]: Copied! <pre># make a loop \ncount = 0\nwhile count &lt; 10:\n    # bad way\n    # count = count + 1\n    # better way\n    count += 1\nprint(count)\n</pre> # make a loop  count = 0 while count &lt; 10:     # bad way     # count = count + 1     # better way     count += 1 print(count) <pre>10\n</pre> In\u00a0[22]: Copied! <pre># use range\nfor i in range(5):\n    print(i)\n</pre> # use range for i in range(5):     print(i) <pre>0\n1\n2\n3\n4\n</pre> <p>Important point: in python, we always count from 0!</p> In\u00a0[23]: Copied! <pre># what is range?\ntype(range)\n</pre> # what is range? type(range) Out[23]: <pre>type</pre> In\u00a0[24]: Copied! <pre>range?\n</pre> range? <pre>Init signature: range(self, /, *args, **kwargs)\nDocstring:     \nrange(stop) -&gt; range object\nrange(start, stop[, step]) -&gt; range object\n\nReturn an object that produces a sequence of integers from start (inclusive)\nto stop (exclusive) by step.  range(i, j) produces i, i+1, i+2, ..., j-1.\nstart defaults to 0, and stop is omitted!  range(4) produces 0, 1, 2, 3.\nThese are exactly the valid indices for a list of 4 elements.\nWhen step is given, it specifies the increment (or decrement).\nType:           type\nSubclasses:     </pre> In\u00a0[25]: Copied! <pre># iterate over a list we make up\nfor pet in ['dog', 'cat', 'fish']:\n    print(pet, len(pet))\n</pre> # iterate over a list we make up for pet in ['dog', 'cat', 'fish']:     print(pet, len(pet)) <pre>dog 3\ncat 3\nfish 4\n</pre> <p>What is the thing in brackets? A list! Lists are one of the core python data structures.</p> In\u00a0[26]: Copied! <pre>l = ['dog', 'cat', 'fish']\ntype(l)\n</pre> l = ['dog', 'cat', 'fish'] type(l) Out[26]: <pre>list</pre> In\u00a0[27]: Copied! <pre># list have lots of methods\nl.sort()\nl\n</pre> # list have lots of methods l.sort() l Out[27]: <pre>['cat', 'dog', 'fish']</pre> In\u00a0[28]: Copied! <pre># we can convert a range to a list\nr = list(range(5))\nr\n</pre> # we can convert a range to a list r = list(range(5)) r Out[28]: <pre>[0, 1, 2, 3, 4]</pre> In\u00a0[29]: Copied! <pre>while r:\n    p = r.pop()\n    print('p:', p)\n    print('r:', r)\n</pre> while r:     p = r.pop()     print('p:', p)     print('r:', r) <pre>p: 4\nr: [0, 1, 2, 3]\np: 3\nr: [0, 1, 2]\np: 2\nr: [0, 1]\np: 1\nr: [0]\np: 0\nr: []\n</pre> <p>There are many different ways to interact with lists. Exploring them is part of the fun of python.</p> <p>list.append(x) Add an item to the end of the list. Equivalent to a[len(a):] = [x].</p> <p>list.extend(L) Extend the list by appending all the items in the given list. Equivalent to a[len(a):] = L.</p> <p>list.insert(i, x) Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x).</p> <p>list.remove(x) Remove the first item from the list whose value is x. It is an error if there is no such item.</p> <p>list.pop([i]) Remove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and returns the last item in the list. (The square brackets around the i in the method signature denote that the parameter is optional, not that you should type square brackets at that position. You will see this notation frequently in the Python Library Reference.)</p> <p>list.clear() Remove all items from the list. Equivalent to del a[:].</p> <p>list.index(x) Return the index in the list of the first item whose value is x. It is an error if there is no such item.</p> <p>list.count(x) Return the number of times x appears in the list.</p> <p>list.sort() Sort the items of the list in place.</p> <p>list.reverse() Reverse the elements of the list in place.</p> <p>list.copy() Return a shallow copy of the list. Equivalent to a[:].</p> <p>Don't assume you know how list operations work!</p> In\u00a0[30]: Copied! <pre># \"add\" two lists\nx = list(range(5))\ny = list(range(10,15))\nz = x + y\nz\n</pre> # \"add\" two lists x = list(range(5)) y = list(range(10,15)) z = x + y z Out[30]: <pre>[0, 1, 2, 3, 4, 10, 11, 12, 13, 14]</pre> In\u00a0[31]: Copied! <pre># access items from a list\nprint('first', z[0])\nprint('last', z[-1])\nprint('first 3', z[:3])\nprint('last 3', z[-3:])\nprint('middle, skipping every other item', z[5:10:2])\n</pre> # access items from a list print('first', z[0]) print('last', z[-1]) print('first 3', z[:3]) print('last 3', z[-3:]) print('middle, skipping every other item', z[5:10:2]) <pre>first 0\nlast 14\nfirst 3 [0, 1, 2]\nlast 3 [12, 13, 14]\nmiddle, skipping every other item [10, 12, 14]\n</pre> <p>MEMORIZE THIS SYNTAX! It is central to so much of python and often proves confusing for users coming from other languages.</p> <p>In terms of set notation, python indexing is left inclusive, right exclusive. If you remember this, you will never go wrong.</p> In\u00a0[32]: Copied! <pre># that means we get an error from the following\nN = len(z)\nz[N]\n</pre> # that means we get an error from the following N = len(z) z[N] <pre>\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[32], line 3\n      1 # that means we get an error from the following\n      2 N = len(z)\n----&gt; 3 z[N]\n\nIndexError: list index out of range</pre> In\u00a0[33]: Copied! <pre># this index notation also applies to strings\nname = 'Xiaomeng Jin'\nprint(name[:4])\n</pre> # this index notation also applies to strings name = 'Xiaomeng Jin' print(name[:4]) <pre>Xiao\n</pre> In\u00a0[34]: Copied! <pre>print(name[:-4])\n</pre> print(name[:-4]) <pre>Xiaomeng\n</pre> In\u00a0[36]: Copied! <pre>print(name[-3:])\n</pre> print(name[-3:]) <pre>Jin\n</pre> In\u00a0[37]: Copied! <pre># you can also test for the presence of items in a list\n5 in z\n</pre> # you can also test for the presence of items in a list 5 in z Out[37]: <pre>False</pre> <p>Lists are not meant for math! They don't have a datatype.</p> In\u00a0[38]: Copied! <pre>z[4] = 'fish'\nz\n</pre> z[4] = 'fish' z Out[38]: <pre>[0, 1, 2, 3, 'fish', 10, 11, 12, 13, 14]</pre> <p>Python is full of tricks for iterating and working with lists</p> In\u00a0[42]: Copied! <pre># a cool python trick: list comprehension\nsquares = [n**2 for n in range(5)]\nsquares\n</pre> # a cool python trick: list comprehension squares = [n**2 for n in range(5)] squares Out[42]: <pre>[0, 1, 4, 9, 16]</pre> In\u00a0[39]: Copied! <pre># iterate over two lists together uzing zip\nfor item1, item2 in zip(x,y):\n    print('first:', item1, 'second:', item2)\n</pre> # iterate over two lists together uzing zip for item1, item2 in zip(x,y):     print('first:', item1, 'second:', item2) <pre>first: 0 second: 10\nfirst: 1 second: 11\nfirst: 2 second: 12\nfirst: 3 second: 13\nfirst: 4 second: 14\n</pre> In\u00a0[43]: Copied! <pre># tuples are created with parentheses, or just commas\na = ('Jin', 32, True)\nb = 'Wang', 25, False\ntype(b)\n</pre> # tuples are created with parentheses, or just commas a = ('Jin', 32, True) b = 'Wang', 25, False type(b) Out[43]: <pre>tuple</pre> In\u00a0[44]: Copied! <pre>b\n</pre> b Out[44]: <pre>('Wang', 25, False)</pre> In\u00a0[45]: Copied! <pre># can be indexed like arrays\nprint(a[1]) # not the first element!\n</pre> # can be indexed like arrays print(a[1]) # not the first element! <pre>32\n</pre> In\u00a0[46]: Copied! <pre># and they can be unpacked\nname, age, status = a\n</pre> # and they can be unpacked name, age, status = a In\u00a0[47]: Copied! <pre># different ways to create dictionaries : Curly brackets or dict\nd = {'name': 'Jin', 'age': 32}\ne = dict(name='Wang', age=25)\ne\n</pre> # different ways to create dictionaries : Curly brackets or dict d = {'name': 'Jin', 'age': 32} e = dict(name='Wang', age=25) e Out[47]: <pre>{'name': 'Wang', 'age': 25}</pre> In\u00a0[48]: Copied! <pre># access a value\nd['name']\n</pre> # access a value d['name'] Out[48]: <pre>'Jin'</pre> <p>Square brackets <code>[...]</code> are python for \"get item\" in many different contexts.</p> In\u00a0[49]: Copied! <pre># test for the presence of a key\nprint('age' in d)\nprint('height' in e)\n</pre> # test for the presence of a key print('age' in d) print('height' in e) <pre>True\nFalse\n</pre> In\u00a0[50]: Copied! <pre># try to access a non-existant key\nd['height']\n</pre> # try to access a non-existant key d['height'] <pre>\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[50], line 2\n      1 # try to access a non-existant key\n----&gt; 2 d['height']\n\nKeyError: 'height'</pre> In\u00a0[51]: Copied! <pre># add a new key\nd['height'] = (5,3) # a tuple\nd\n</pre> # add a new key d['height'] = (5,3) # a tuple d Out[51]: <pre>{'name': 'Jin', 'age': 32, 'height': (5, 3)}</pre> In\u00a0[52]: Copied! <pre># keys don't have to be strings\nd[99] = 'nighty nine'\nd\n</pre> # keys don't have to be strings d[99] = 'nighty nine' d Out[52]: <pre>{'name': 'Jin', 'age': 32, 'height': (5, 3), 99: 'nighty nine'}</pre> In\u00a0[53]: Copied! <pre># iterate over keys\nfor k in d:\n    print(k, d[k])\n</pre> # iterate over keys for k in d:     print(k, d[k]) <pre>name Jin\nage 32\nheight (5, 3)\n99 nighty nine\n</pre> In\u00a0[54]: Copied! <pre># better way\n### python 2\n### for key, val in d.iteritems()\nfor key, val in d.items():\n    print(key, val)\n</pre> # better way ### python 2 ### for key, val in d.iteritems() for key, val in d.items():     print(key, val) <pre>name Jin\nage 32\nheight (5, 3)\n99 nighty nine\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_2_Core_Python/#lecture-2-core-python-language","title":"Lecture 2 Core Python Language\u00b6","text":"<p>Mostly copied from the official python tutorial</p>"},{"location":"Lecture_2_Core_Python/#invoking-python","title":"Invoking Python\u00b6","text":"<p>There are three main ways to use python.</p> <ol> <li>By running a python file, e.g. <code>python myscript.py</code></li> <li>Through an interactive console (python interpreter or ipython shell)</li> <li>In an interactive iPython notebook</li> </ol> <p>We will be using the iPython notebook.</p>"},{"location":"Lecture_2_Core_Python/#basic-variables-numbers-and-string","title":"Basic Variables: Numbers and String\u00b6","text":""},{"location":"Lecture_2_Core_Python/#math","title":"Math\u00b6","text":"<p>Basic arithmetic and boolean logic is part of the core python library.</p>"},{"location":"Lecture_2_Core_Python/#conditionals","title":"Conditionals\u00b6","text":"<p>The first step to programming. Plus an intro to python syntax.</p>"},{"location":"Lecture_2_Core_Python/#more-flow-control","title":"More Flow Control\u00b6","text":""},{"location":"Lecture_2_Core_Python/#lists","title":"Lists\u00b6","text":""},{"location":"Lecture_2_Core_Python/#other-data-structures","title":"Other Data Structures\u00b6","text":"<p>We are almost there. We have the building blocks we need to do basic programming. But python has some other data structures we need to learn about.</p>"},{"location":"Lecture_2_Core_Python/#tuples","title":"Tuples\u00b6","text":"<p>Tuples are similar to lists, but they are immutable\u2014they can't be extended or modified. What is the point of this? Generally speaking: to pack together inhomogeneous data. Tuples can then be unpacked and distributed by other parts of your code.</p> <p>Tuples may seem confusing at first, but with time you will come to appreciate them. Tuples are great to use if you want the data in your collection to be read-only, never to change, and always remain the same and constant.</p>"},{"location":"Lecture_2_Core_Python/#dictionaries","title":"Dictionaries\u00b6","text":"<p>This is an extremely useful data structure. It maps keys to values.</p> <p>Dictionaries are unordered!</p> <p>Tuples can be used as dictionary keys (specifically, tuples that contain immutable values like strings, numbers, and other tuples). Lists can never be used as dictionary keys, because lists are mutable.</p>"},{"location":"Lecture_2_install_python_amarel/","title":"Install Conda and Python","text":"<ul> <li>Connect to Amarel Open OnDemand </li> <li>Click Clusters </li> <li>Choose Amarel Cluster Shell Access </li> <li>Enter your password </li> <li>In the terminal, do the following commands (one line each time). If you're using Windows, type 'Ctrl+c' to copy and 'Ctrl+Shift+v' to paste command. </li> </ul> <pre><code>$ module use /projects/community/modulefiles\n$ module load anaconda/2020.07-gc563\n$ cd\n$ source .bashrc\n$ mkdir -p .conda/pkgs/cache .conda/envs \n</code></pre> <ul> <li>Test if conda is successfully installed: </li> </ul> <pre><code>$ which conda\n</code></pre> <ul> <li>Install a conda environment called 'rcaes_env': </li> </ul> <pre><code>$ conda create -n rcaes_env\n</code></pre> <ul> <li>Enter Y to proceed. Wait until you see the following. It may take a while. </li> </ul> <pre><code>#                                                                                                                                                               \n# To activate this environment, use                                                                                                                             \n#                                                                                                                                                               \n#     $ conda activate rcaes_env                                                                                                                              \n#                                                                                                                                                               \n# To deactivate an active environment, use                                                                                                                      \n#                                                                                                                                                               \n#     $ conda deactivate    \n</code></pre> <ul> <li>Now let's activate the environment:</li> </ul> <pre><code>$ conda activate rcaes_env \n</code></pre> <ul> <li>First, let's install essential packages</li> </ul> <pre><code>conda install -c conda-forge python=3.9 jupyter jupyterlab notebook numpy scipy ipython\n</code></pre> <ul> <li>Next, let's install github CLI, a command-line interface to GitHub for use in your terminal or your scripts</li> </ul> <pre><code>conda install -c conda-forge gh\n</code></pre> <ul> <li> <p>Next, go back to Amarel Open OnDemand. This time, we will launch a personal jupyter. Click on 'Interactive Apps', choose 'Personal Jupyter'. </p> </li> <li> <p>Settings for Personal Jupyter: </p> </li> </ul> <pre><code>    Number of hours: 10 \n    Number of cores: 1 \n    Gigabytes of memory: 10 \n    Partition: main\n    Leave Reservation and slurm feature blank \n    conda path: /projects/community/anaconda/2020.07/gc563 \n    conda environment: rcaes_env\n</code></pre>"},{"location":"Lecture_2_install_python_amarel/#conda-alternative-mamba","title":"Conda Alternative: Mamba","text":"<ul> <li> <p>If you find Conda super slow at solving the environment, I'd recommend you try using an alternative package manager Mamba. </p> </li> <li> <p>Install Miniforge using: </p> </li> </ul> <pre><code>wget \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh\n</code></pre> <ul> <li> <p>Close and reopen the terminal window. </p> </li> <li> <p>Create a new environment <code>rcaes_env_new</code>: </p> </li> </ul> <pre><code>mamba create -n rcaes_env_new python=3.9 jupyter jupyterlab notebook numpy scipy ipython pandas matplotlib cartopy geopandas xarray dask netCDF4 bottleneck gh\n</code></pre> <ul> <li> <p>Next, go back to Amarel Open OnDemand. This time, we will launch a personal jupyter. Click on 'Interactive Apps', choose 'Personal Jupyter'. </p> </li> <li> <p>Settings for Personal Jupyter: </p> </li> </ul> <pre><code>    Number of hours: 10 \n    Number of cores: 1 \n    Gigabytes of memory: 10 \n    Partition: main\n    Leave Reservation and slurm feature blank \n    conda path: /home/YOURNETID/miniforge3\n    conda environment: rcaes_env_new\n</code></pre>"},{"location":"Lecture_2_intro_to_unix/","title":"Intro to Unix","text":"<p>The notes below are modified from the excellent Unix Shell tutorial  that is freely available on the Software Carpentry website. I highly recommend checking out the full version for further reading. The material is being used here under the terms of the Creative Commons Attribution license.</p>"},{"location":"Lecture_2_intro_to_unix/#what-is-unix-shell","title":"What is Unix shell?","text":"<p>The Unix shell is both a command-line interface and a scripting language. With the shell, it is possible to invoke complicated programs like climate modeling or a simple command that create an empty directory.  The most popular Unix Shell is Bash. </p>"},{"location":"Lecture_2_intro_to_unix/#navigating-files-and-directories","title":"Navigating Files and Directories","text":"<p>Several commands are frequently used to create, inspect, rename, and delete files and directories.</p> <p>To get started, open a terminal using the OpenOnDemand Clusters: Amarel Cluster Shell Access. After entering your password, you will see the welcome message. </p> <pre><code>(base) [xj103@amarel2 ~]$ \n</code></pre> <p>The dollar sign is a prompt, which shows us that the shell is waiting for input.</p> <p><code>xj103</code> is our username and <code>amarel2</code> is the hostname. The username will be your NetID. The hostname indicates the node you're at. Here we are using login nodes (amarel1, amarel2, etc.). Cluster login nodes provide a shared environment where users can transfer data, build software, and prepare their calculations.  Running applications on a shared login node or doing things that consume significant compute, memory, or network resources can unfairly impact other users.  Please do not do that. Do not run your research applications on the login node.  If you log into the terminal via a compute nodes, you will see the hostname as hal0001, hal0002 etc., which are nodes assigned to you for computation. </p> <p>From now on, we will just use a <code>$</code> to indicate the prompt.</p> <p>To find out your username in general, you can use the command</p> <pre><code>$ whoami\nxj103\n</code></pre> <p>and to find out your hostname</p> <pre><code>$ hostname\namarel2.amarel.rutgers.edu\n</code></pre> <p>Next, let's find out where we are by running a command called <code>pwd</code> (which stands for \"print working directory\"). At any moment, our current working directory is our current default directory, i.e., the directory that the computer assumes we want to run commands in unless we explicitly specify something else. Here, the computer's response is <code>/home/xj103</code>, which is the home directory of the user named <code>xj103</code>.</p> <pre><code>$ pwd\n</code></pre> <pre><code>/home/xj103\n</code></pre> <p>To understand what a \"home directory\" is, let's have a look at how the file system as a whole is organized.  For the sake of this example, we'll be illustrating the filesystem on Amarel.  </p> <pre><code>$ cd /\n</code></pre> <p>Now let's learn the command that will let us see the contents of our own filesystem.  We can see what's in our home directory by running <code>ls</code>, which stands for \"listing\":</p> <pre><code>$ ls\n</code></pre> <p>On a Unix computer, at the top is the root directory that holds everything else. We refer to it using a slash character <code>/</code> on its own; this is the leading slash in <code>/home/xj103</code>.</p> <p>Inside that directory are several other directories: <code>bin</code> (which is where some built-in programs are stored), <code>lib</code> (for the software \"libraries\" used by different programs), <code>home</code> (where users' personal directories are located), <code>projects</code> (where project data are stored), <code>etc</code> (system-wide configuration files), and so on.  </p> <p>Now let's go back to our home directory with ~ (tilde)</p> <pre><code>$ cd ~\n</code></pre> <p><code>ls</code> prints the names of the files and directories in the current directory in alphabetical order, arranged neatly into columns. We can make its output more comprehensible by using the flag <code>-F</code>, which tells <code>ls</code> to add a trailing <code>/</code> to the names of directories:</p> <pre><code>$ ls -F\n</code></pre> <p><code>ls</code> has lots of other options. To find out what they are, we can type:</p> <pre><code>$ man ls\n</code></pre> <p><code>man</code> is the Unix \"manual\" command: it prints a description of a command and its options, and (if you're lucky) provides a few examples of how to use it. To navigate through the <code>man</code> pages, you may use the up and down arrow keys to move line-by-line. Quit the <code>man</code> pages by typing \"q\".</p> <p>The command to change locations is <code>cd</code> followed by a directory name to change our working directory. <code>cd</code> stands for \"change directory\", which is a bit misleading: the command doesn't change the directory, it changes the shell's idea of what directory we are in.</p> <p>Let's say we want to move to the <code>Documents</code> directory we saw above.  We can use the following series of commands to get there:</p> <pre><code>$ cd Documents\n</code></pre> <p>These commands will move us from our home directory onto into the <code>Documents</code> directory. <code>cd</code> doesn't print anything, but if we run <code>pwd</code> after it, we can see that we are now in <code>/home/xj103/Documents</code>.</p> <p>We now know how to go down the directory tree, but how do we go up? There is a shortcut in the shell to move up one directory level that looks like this:</p> <pre><code>$ cd ..\n</code></pre> <p><code>..</code> is a special directory name meaning \"the directory containing this one\", or more succinctly, the parent of the current directory. Sure enough, if we run <code>pwd</code> after running <code>cd ..</code>, we're back in <code>/home/xj103</code>:</p> <pre><code>$ pwd\n</code></pre> <pre><code>/home/xj103\n</code></pre> <p>The special directory <code>..</code> doesn't usually show up when we run <code>ls</code>.  If we want to display it, we can give <code>ls</code> the <code>-a</code> flag:</p> <pre><code>$ ls -F -a\n</code></pre> <p><code>-a</code> stands for \"show all\"; it forces <code>ls</code> to show us file and directory names that begin with <code>.</code>, such as <code>..</code> (which, if we're in <code>/home/xj103/Documents</code>, refers to the <code>/home/xj103</code> directory) As you can see, it also displays another special directory that's just called <code>.</code>, which means \"the current working directory\". It may seem redundant to have a name for it, but we'll see some uses for it soon.</p> <p>Note that in most command line tools, multiple parameters can be combined with a single <code>-</code> and no spaces between the parameters: <code>ls -F -a</code> is equivalent to <code>ls -Fa</code>.</p> <p>These then, are the basic commands for navigating the filesystem on your computer: <code>pwd</code>, <code>ls</code> and <code>cd</code>.  Let's explore some variations on those commands.  What happens if you type <code>cd</code> on its own, without giving a directory?  </p> <pre><code>$ cd\n</code></pre> <p>How can you check what happened?  <code>pwd</code> gives us the answer!  </p> <pre><code>$ pwd\n</code></pre> <pre><code>/home/xj103\n</code></pre> <p>It turns out that <code>cd</code> without an argument will return you to your home directory, which is great if you've gotten lost in your own filesystem.  </p> <pre><code>$ cd \n</code></pre> <p>Check that we've moved to the right place by running <code>pwd</code> and <code>ls -F</code> </p> <p>If we want to move up one level from the data directory, we could use <code>cd ..</code>.  But there is another way to move to any directory, regardless of your current location.  </p> <p>So far, when specifying directory names, or even a directory path (as above), we have been using relative paths.  When you use a relative path with a command like <code>ls</code> or <code>cd</code>, it tries to find that location from where we are, rather than from the root of the file system.  </p> <p>However, it is possible to specify the absolute path to a directory by including its entire path from the root directory, which is indicated by a leading slash.  The leading <code>/</code> tells the computer to follow the path from the root of the file system, so it always refers to exactly one directory, no matter where we are when we run the command.</p> <p>This allows us to move to our <code>examples</code> directory from anywhere on the filesystem.  To find the absolute path we're looking for, we can use <code>pwd</code> and then extract the piece we need to move to <code>examples</code>.  </p> <pre><code>$ pwd\n</code></pre> <pre><code>$ cd /home/xj103/Documents/\n</code></pre> <p>Run <code>pwd</code> and <code>ls -F</code> to ensure that we're in the directory we expect.  </p>"},{"location":"Lecture_2_intro_to_unix/#two-more-shortcuts","title":"Two More Shortcuts","text":"<p>The shell interprets the character <code>~</code> (tilde) at the start of a path to mean \"the current user's home directory\". For example, if my home directory is <code>/home/xj103</code>, then <code>~/rcaes</code> is equivalent to <code>/home/xj103/rcaes</code>. This only works if it is the first character in the path.</p> <p>Another shortcut is the <code>-</code> (dash) character.  <code>cd</code> will translate <code>-</code> into the previous directory I was in, which is faster than having to remember, then type, the full path.  This is a very efficient way of moving back and forth between directories. The difference between <code>cd ..</code> and <code>cd -</code> is that the former brings you up, while the latter brings you back. You can think of it as the Last Channel button on a TV remote.</p>"},{"location":"Lecture_2_intro_to_unix/#tab-completion","title":"Tab Completion","text":"<p>Typing the full path to directories and files can be slow and annoying. Fortunately, we have \"tab completion\" to help us. Try typing <code>cd Doc</code> and then press the <code>&lt;tab&gt;</code>. The system will try to \"auto complete\" your command. Pressing tab twice brings up a list of all the files, and so on. This is called tab completion, and we will see it in many other tools as we go on.</p>"},{"location":"Lecture_2_intro_to_unix/#key-points","title":"Key Points:","text":"<ul> <li>\"The file system is responsible for managing information on the disk.\"</li> <li>\"Information is stored in files, which are stored in directories (folders).\"</li> <li>\"Directories can also store other directories, which forms a directory tree.\"</li> <li>\"<code>cd path</code> changes the current working directory.\"</li> <li>\"<code>ls path</code> prints a listing of a specific file or directory; <code>ls</code> on its own lists the current working directory.\"</li> <li><code>pwd</code> prints the user's current working directory.</li> <li><code>whoami</code> shows the user's current identity.</li> <li><code>/</code> on its own is the root directory of the whole file system.</li> <li>A relative path specifies a location starting from the current location.</li> <li>An absolute path specifies a location from the root of the file system.</li> <li>Directory names in a path are separated with '/' (forward slash) on Unix, but '\\\\' (backslash) on Windows.</li> <li>'..' means 'the directory above the current one'; '.' on its own means 'the current directory'.</li> <li>Most files' names are <code>something.extension</code>. The extension isn't required, and doesn't guarantee anything, but is normally used to indicate the type of data in the file.</li> <li>Most commands take options (flags) which begin with a '-'.</li> </ul>"},{"location":"Lecture_2_intro_to_unix/#working-with-files-and-directories","title":"Working with Files and Directories","text":"<p>We now know how to explore files and directories, but how do we create them in the first place? Let's go back to our home directory and use <code>ls -F</code> to see what it contains:</p> <pre><code>$ cd\n$ pwd\n</code></pre> <pre><code>/home/xj103/\n</code></pre> <p>Let's create a new directory called <code>thesis</code> using the command <code>mkdir thesis</code> (which has no output):</p> <pre><code>$ mkdir thesis\n</code></pre> <p>As you might guess from its name, <code>mkdir</code> means \"make directory\". Since <code>thesis</code> is a relative path (i.e., doesn't have a leading slash), the new directory is created in the current working directory:</p> <pre><code>$ ls -F\n</code></pre>"},{"location":"Lecture_2_intro_to_unix/#good-names-for-files-and-directories","title":"Good names for files and directories","text":"<p>Complicated names of files and directories can make your life painful  when working on the command line. Here we provide a few useful  tips for the names of your files.</p> <ol> <li> <p>Don't use whitespaces.</p> <p>Whitespaces can make a name more meaningful    but since whitespace is used to break arguments on the command line    is better to avoid them on name of files and directories. You can use <code>-</code> (dash) and <code>_</code> (underscore) instead of whitespace.</p> </li> <li> <p>Don't begin the name with <code>-</code> (dash).</p> <p>Commands treat names starting with <code>-</code> as options.</p> </li> <li> <p>Stick with letters, numbers, <code>.</code> (period), <code>-</code> (dash) and <code>_</code> (underscore).</p> <p>Many other characters have special meanings on the command line. We will learn about some of these during this lesson. There are special characters that can cause your command to not work as expected and can even result in data loss.</p> </li> </ol> <p>If you need to refer to names of files or directories that have whitespace  or another non-alphanumeric character, you should surround the name in quotes (<code>\"\"</code>).</p> <p>Since we've just created the <code>thesis</code> directory, there's nothing in it yet:</p> <pre><code>$ ls -F thesis\n</code></pre> <p>Let's change our working directory to <code>thesis</code> using <code>cd</code>. We then create a blank new file called <code>draft.txt</code> using the <code>touch command</code>:</p> <pre><code>$ cd thesis\n$ touch draft.txt\n</code></pre> <p>Now we can edit the file in JupyterLab's text editor. Let's type in a few lines of text. Once we're happy with our text, we save the file, and return to the shell.</p> <p><code>ls</code> now shows that we have created a file called <code>draft.txt</code>:</p> <pre><code>$ ls\ndraft.txt\n</code></pre> <p>Let's tidy up by running <code>rm draft.txt</code>:</p> <pre><code>$ rm draft.txt\n</code></pre> <p>This command removes files (<code>rm</code> is short for \"remove\"). If we run <code>ls</code> again, its output is empty once more, which tells us that our file is gone:</p> <pre><code>$ ls\n</code></pre>"},{"location":"Lecture_2_intro_to_unix/#deleting-is-forever","title":"Deleting Is Forever","text":"<p>The Unix shell doesn't have a trash bin that we can recover deleted files from (though most graphical interfaces to Unix do).  Instead, when we delete files, they are unhooked from the file system so that their storage space on disk can be recycled. Tools for finding and recovering deleted files do exist, but there's no guarantee they'll work in any particular situation, since the computer may recycle the file's disk space right away.</p> <p>Let's re-create that file and then move up one directory to <code>/home/xj103</code> using <code>cd ..</code>:</p> <pre><code>$ touch draft.txt\n$ cd ..\n</code></pre> <p>If we try to remove the entire <code>thesis</code> directory using <code>rm thesis</code>, we get an error message:</p> <pre><code>$ rm thesis\n</code></pre> <pre><code>rm: cannot remove `thesis`: Is a directory\n</code></pre> <p>This happens because <code>rm</code> by default only works on files, not directories.</p> <p>To really get rid of <code>thesis</code> we must also delete the file <code>draft.txt</code>. We can do this with the recursive option for <code>rm</code>:</p> <pre><code>$ rm -r thesis\n</code></pre>"},{"location":"Lecture_2_intro_to_unix/#with-great-power-comes-great-responsibility","title":"With Great Power Comes Great Responsibility","text":"<p>Removing the files in a directory recursively can be very dangerous  operation. If we're concerned about what we might be deleting we can  add the \"interactive\" flag <code>-i</code> to <code>rm</code> which will ask us for confirmation  before each step</p> <pre><code> $ rm -r -i thesis\n rm: descend into directory \u2018thesis\u2019? y\n rm: remove regular file \u2018thesis/draft.txt\u2019? y\n rm: remove directory \u2018thesis\u2019? y\n</code></pre> <p>This removes everything in the directory, then the directory itself, asking  at each step for you to confirm the deletion.</p> <p>Let's create that directory and file one more time.</p> <pre><code>$ mkdir thesis\n$ touch thesis/draft.txt\n$ ls thesis\n</code></pre> <pre><code>draft.txt\n</code></pre> <p><code>draft.txt</code> isn't a particularly informative name, so let's change the file's name using <code>mv</code>, which is short for \"move\":</p> <pre><code>$ mv thesis/draft.txt thesis/quotes.txt\n</code></pre> <p>The first parameter tells <code>mv</code> what we're \"moving\", while the second is where it's to go. In this case, we're moving <code>thesis/draft.txt</code> to <code>thesis/quotes.txt</code>, which has the same effect as renaming the file. Sure enough, <code>ls</code> shows us that <code>thesis</code> now contains one file called <code>quotes.txt</code>:</p> <pre><code>$ ls thesis\n</code></pre> <pre><code>quotes.txt\n</code></pre> <p>One has to be careful when specifying the target file name, since <code>mv</code> will silently overwrite any existing file with the same name, which could lead to data loss. An additional flag, <code>mv -i</code> (or <code>mv --interactive</code>), can be used to make <code>mv</code> ask you for confirmation before overwriting.</p> <p>Just for the sake of consistency, <code>mv</code> also works on directories</p> <p>Let's move <code>quotes.txt</code> into the current working directory. We use <code>mv</code> once again, but this time we'll just use the name of a directory as the second parameter to tell <code>mv</code> that we want to keep the filename, but put the file somewhere new. (This is why the command is called \"move\".) In this case, the directory name we use is the special directory name <code>.</code> that we mentioned earlier.</p> <pre><code>$ mv thesis/quotes.txt .\n</code></pre> <p>The effect is to move the file from the directory it was in to the current working directory. <code>ls</code> now shows us that <code>thesis</code> is empty:</p> <pre><code>$ ls thesis\n</code></pre> <p>Further, <code>ls</code> with a filename or directory name as a parameter only lists that file or directory. We can use this to see that <code>quotes.txt</code> is still in our current directory:</p> <pre><code>$ ls quotes.txt\n</code></pre> <pre><code>quotes.txt\n</code></pre> <p>The <code>cp</code> command works very much like <code>mv</code>, except it copies a file instead of moving it. We can check that it did the right thing using <code>ls</code> with two paths as parameters --- like most Unix commands, <code>ls</code> can be given multiple paths at once:</p> <pre><code>$ cp quotes.txt thesis/quotations.txt\n$ ls \n</code></pre> <pre><code>quotes.txt   thesis/quotations.txt\n</code></pre> <p>To prove that we made a copy, let's delete the <code>quotes.txt</code> file in the current directory and then run that same <code>ls</code> again.</p> <pre><code>$ rm quotes.txt\n$ ls quotes.txt thesis/quotations.txt\n</code></pre> <pre><code>ls: cannot access quotes.txt: No such file or directory\nthesis/quotations.txt\n</code></pre> <p>This time it tells us that it can't find <code>quotes.txt</code> in the current directory, but it does find the copy in <code>thesis</code> that we didn't delete.</p>"},{"location":"Lecture_2_intro_to_unix/#key-points_1","title":"Key Points","text":"<ul> <li><code>cp old new</code> copies a file.</li> <li><code>mkdir path</code> creates a new directory.</li> <li><code>mv old new</code> moves (renames) a file or directory.</li> <li><code>rm path</code> removes (deletes) a file.</li> <li>Use of the Control key may be described in many ways, including <code>Ctrl-X</code>, <code>Control-X</code>, and <code>^X</code>.</li> <li>The shell does not have a trash bin: once something is deleted, it's really gone.</li> <li>Depending on the type of work you do, you may need a more powerful text editor than Nano.</li> </ul>"},{"location":"Lecture_2_intro_to_unix/#learning-more","title":"Learning More","text":"<p>The goal of this lesson was to familiarize you with the basics of working with files and directories. There is a lot more to the unix shell and filexsystem than what we have  covered here! To ge deeper with self study, we recommend the excellent Software Carpentry Unix Shell Lesson, on which the above material was based.</p>"},{"location":"Lecture_3_GitHub/","title":"Summary of useful Git commands","text":""},{"location":"Lecture_3_GitHub/#configuring","title":"Configuring:","text":"<p>Set up your username and email</p> <pre><code>git config --global user.name \"Xiaomeng Jin\"\ngit config --global user.email \"xiaomeng.jin@rutgers.edu\"\n</code></pre>"},{"location":"Lecture_3_GitHub/#branches","title":"Branches:","text":"<p>Branches are an important part of working with Git.  Any commits you make will be made on the branch you're currently \u201cchecked out\u201d to. Use git status to see which branch that is.</p> <pre><code>git branch [branch-name] #creates a new branch\ngit checkout [branch-name] # switch to the specified branch and updates the working directory\ngit merge [branch] # combines the specified branch's history into the current branch.\ngit branch -d [branch-name] #deletes the specified branch\n</code></pre>"},{"location":"Lecture_3_GitHub/#create-repositories","title":"Create repositories:","text":"<p>Start out a new repository:</p> <pre><code>cd my_project\ngit init      \n</code></pre> <p>Or clone a repository using git clone</p> <pre><code>git clone https://github.com/rcaes2023/assignment_1_python-MazvitaChikomo.git\n</code></pre> <p>Or clone a repository using GitHub Command Line OWNER/REPO syntax.</p> <pre><code>gh repo clone rcaes2023/assignment_1_python-MazvitaChikomo\ncd assignment_1_python-MazvitaChikomo\n</code></pre> <p>If you want to get a repository that you don't have permission to push to, you can fork the repository.</p> <pre><code>gh repo fork cli/cli\n</code></pre>"},{"location":"Lecture_3_GitHub/#make-changes","title":"Make Changes","text":"<p>Browse and inspect the evolution of project files</p> <pre><code>git status    # tells you which branch you are at, what files are staged, which ones have been modified, are new,...\ngit log       # view the commit log\ngit diff      # view file content differences\n</code></pre> <p>Version control</p> <pre><code>git add &lt;filenames&gt;  #Snapshots the file in preparation for versioning\ngit commit -m \"your brief commit message goes here\" #Records file snapshots permanently in version history\n</code></pre>"},{"location":"Lecture_3_GitHub/#synchronize-changes","title":"Synchronize changes:","text":"<pre><code>git push #uploads all local branch commits to GitHub\ngit pull # updates your current local working branch with all new commits from the corresponding remote branch on GitHub.\n</code></pre>"},{"location":"Lecture_3_GitHub/#basic-github-workflow","title":"Basic GitHub workflow:","text":"<ul> <li>clone your local repo with <code>gh repo clone &lt;REPO&gt;</code>,</li> <li>make your changes and stage them with <code>git add &lt;filenames&gt;</code>,</li> <li>commit your changes with <code>git commit -m \"your brief commit message goes here\"</code>, and</li> <li>upload the changes to GitHub with<code>git push</code></li> </ul>"},{"location":"Lecture_3_functions_classes_modules/","title":"Lecture 3 Python Functions and Classes","text":"In\u00a0[48]: Copied! <pre># define a function\ndef say_hello():\n\"\"\"Return the word hello.\"\"\"\n    return 'Hello'\n</pre> # define a function def say_hello():     \"\"\"Return the word hello.\"\"\"     return 'Hello' In\u00a0[49]: Copied! <pre># functions are also objects\ntype(say_hello)\n</pre> # functions are also objects type(say_hello) Out[49]: <pre>function</pre> In\u00a0[50]: Copied! <pre># this doesnt call\nsay_hello?\n</pre> # this doesnt call say_hello? <pre>Signature: say_hello()\nDocstring: Return the word hello.\nFile:      /var/folders/7b/6t7qqfj57bb0_ml_y_5bw86r0000gn/T/ipykernel_76551/1650374671.py\nType:      function</pre> In\u00a0[51]: Copied! <pre># this does\nsay_hello()\n</pre> # this does say_hello() Out[51]: <pre>'Hello'</pre> In\u00a0[52]: Copied! <pre># assign the result to something\nres = say_hello()\nres\n</pre> # assign the result to something res = say_hello() res Out[52]: <pre>'Hello'</pre> In\u00a0[12]: Copied! <pre># take some arguments\ndef say_hello_to(name):\n\"\"\"Return a greeting to `name`\"\"\"\n    return 'Hello ' + name\n</pre> # take some arguments def say_hello_to(name):     \"\"\"Return a greeting to `name`\"\"\"     return 'Hello ' + name In\u00a0[13]: Copied! <pre># intended usage\nsay_hello_to('World')\n</pre> # intended usage say_hello_to('World') Out[13]: <pre>'Hello World'</pre> In\u00a0[14]: Copied! <pre>say_hello_to(10)\n</pre> say_hello_to(10) <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[14], line 1\n----&gt; 1 say_hello_to(10)\n\nCell In[12], line 4, in say_hello_to(name)\n      2 def say_hello_to(name):\n      3 \"\"\"Return a greeting to `name`\"\"\"\n----&gt; 4     return 'Hello ' + name\n\nTypeError: can only concatenate str (not \"int\") to str</pre> In\u00a0[15]: Copied! <pre># redefine the function\ndef say_hello_to(name):\n\"\"\"Return a greeting to `name`\"\"\"\n    return 'Hello ' + str(name)\n</pre> # redefine the function def say_hello_to(name):     \"\"\"Return a greeting to `name`\"\"\"     return 'Hello ' + str(name) In\u00a0[16]: Copied! <pre>say_hello_to(10)\n</pre> say_hello_to(10) Out[16]: <pre>'Hello 10'</pre> In\u00a0[17]: Copied! <pre># take an optional keyword argument\ndef say_hello_language(name, chinese=False):\n\"\"\"Say hello in multiple languages.\"\"\"\n    if chinese:\n        greeting = 'Ni Hao '\n    else:\n        greeting = 'Hello '\n    return greeting + name\n</pre> # take an optional keyword argument def say_hello_language(name, chinese=False):     \"\"\"Say hello in multiple languages.\"\"\"     if chinese:         greeting = 'Ni Hao '     else:         greeting = 'Hello '     return greeting + name In\u00a0[18]: Copied! <pre>print(say_hello_language('Matt'))\nprint(say_hello_language('Siyi', chinese=True))\n</pre> print(say_hello_language('Matt')) print(say_hello_language('Siyi', chinese=True))  <pre>Hello Matt\nNi Hao Siyi\n</pre> In\u00a0[19]: Copied! <pre># flexible number of arguments\ndef say_hello_to_everyone(*args):\n    return ['hello ' + str(a) for a in args]\n</pre> # flexible number of arguments def say_hello_to_everyone(*args):     return ['hello ' + str(a) for a in args] In\u00a0[20]: Copied! <pre>say_hello_to_everyone('Matt', 'Siyi', 'Kerry')\n</pre> say_hello_to_everyone('Matt', 'Siyi', 'Kerry') Out[20]: <pre>['hello Matt', 'hello Siyi', 'hello Kerry']</pre> In\u00a0[53]: Copied! <pre># The function doesn't return anything, but it changes the input arguments. \ndef remove_last_from_list(input_list):\n    input_list.pop()\n</pre> # The function doesn't return anything, but it changes the input arguments.  def remove_last_from_list(input_list):     input_list.pop() In\u00a0[22]: Copied! <pre>names = ['Matt', 'Siyi', 'Kerry']\nremove_last_from_list(names)\nprint(names)\nremove_last_from_list(names)\nprint(names)\n</pre> names = ['Matt', 'Siyi', 'Kerry'] remove_last_from_list(names) print(names) remove_last_from_list(names) print(names) <pre>['Matt', 'Siyi']\n['Matt']\n</pre> <p>We can do something similar with a pure function.</p> <p>In general, pure functions are safer and more reliable.</p> In\u00a0[23]: Copied! <pre>def remove_last_from_list_pure(input_list):\n    new_list = input_list.copy()\n    new_list.pop()\n    return new_list\n</pre> def remove_last_from_list_pure(input_list):     new_list = input_list.copy()     new_list.pop()     return new_list In\u00a0[24]: Copied! <pre>names = ['Matt', 'Siyi', 'Kerry']\nnew_names = remove_last_from_list_pure(names)\nprint(names)\nprint(new_names)\n</pre> names = ['Matt', 'Siyi', 'Kerry'] new_names = remove_last_from_list_pure(names) print(names) print(new_names) <pre>['Matt', 'Siyi', 'Kerry']\n['Matt', 'Siyi']\n</pre> <p>We could spend the rest of the day talking about functions, but we have to move on.</p> In\u00a0[25]: Copied! <pre># Create a class named Student with a name. \nclass Student:\n    name = 'Matt'\n</pre> # Create a class named Student with a name.  class Student:     name = 'Matt' In\u00a0[26]: Copied! <pre>print(Student.name)\n</pre> print(Student.name) <pre>Matt\n</pre> In\u00a0[27]: Copied! <pre>class Student:\n    \n    def __init__(self, name):\n        self.name = name\n</pre> class Student:          def __init__(self, name):         self.name = name  In\u00a0[28]: Copied! <pre>s1 = Student('Matt')\ns1\n</pre> s1 = Student('Matt') s1 Out[28]: <pre>&lt;__main__.Student at 0x111dfa250&gt;</pre> <p>Our class only has a single attribute so far:</p> In\u00a0[29]: Copied! <pre>s1.name\n</pre> s1.name Out[29]: <pre>'Matt'</pre> <p>Let's add more, along with some input validation:</p> In\u00a0[54]: Copied! <pre>class Student:\n    \n    def __init__(self, name, age, major):\n        self.name = name.upper()\n        self.major = major\n        self.age = age\n</pre> class Student:          def __init__(self, name, age, major):         self.name = name.upper()         self.major = major         self.age = age          In\u00a0[57]: Copied! <pre>s1 = Student('Matt', 22, 'Environmental Science')\n</pre> s1 = Student('Matt', 22, 'Environmental Science')  In\u00a0[58]: Copied! <pre>s1.major\n</pre> s1.major Out[58]: <pre>'Environmental Science'</pre> In\u00a0[59]: Copied! <pre>s1.name\n</pre> s1.name Out[59]: <pre>'MATT'</pre> In\u00a0[60]: Copied! <pre>s1.age\n</pre> s1.age Out[60]: <pre>22</pre> In\u00a0[61]: Copied! <pre>class Student:\n    \n    def __init__(self, name, age, major):\n        self.name = name.upper()\n        self.major = major\n        \n        if age&lt;0:\n            raise ValueError(f'Invalid age {age}')\n        self.age = age\n</pre> class Student:          def __init__(self, name, age, major):         self.name = name.upper()         self.major = major                  if age&lt;0:             raise ValueError(f'Invalid age {age}')         self.age = age          In\u00a0[62]: Copied! <pre>s1 = Student('Matt', -46, 'Environmental Science')\ns1\n</pre> s1 = Student('Matt', -46, 'Environmental Science') s1 <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[62], line 1\n----&gt; 1 s1 = Student('Matt', -46, 'Environmental Science')\n      2 s1\n\nCell In[61], line 8, in Student.__init__(self, name, age, major)\n      5 self.major = major\n      7 if age&lt;0:\n----&gt; 8     raise ValueError(f'Invalid age {age}')\n      9 self.age = age\n\nValueError: Invalid age -46</pre> In\u00a0[63]: Copied! <pre>s1 = Student('Matt', 22, 'Environmental Science')\ns1\n</pre> s1 = Student('Matt', 22, 'Environmental Science') s1 Out[63]: <pre>&lt;__main__.Student at 0x1123fe6d0&gt;</pre> In\u00a0[36]: Copied! <pre>class Student:\n    \n    def __init__(self, name, age, major):\n        self.name = name.upper()\n        self.major = major\n        \n        if age&lt;0:\n            raise ValueError(f'Invalid age {age}')\n        self.age = age\n    \n    def is_ES(self):\n        return self.major == 'Environmental Science'\n</pre> class Student:          def __init__(self, name, age, major):         self.name = name.upper()         self.major = major                  if age&lt;0:             raise ValueError(f'Invalid age {age}')         self.age = age          def is_ES(self):         return self.major == 'Environmental Science' In\u00a0[37]: Copied! <pre>s1 = Student('Matt', 22, 'Environmental Science')\ns1.is_ES()\n</pre> s1 = Student('Matt', 22, 'Environmental Science') s1.is_ES() Out[37]: <pre>True</pre> In\u00a0[38]: Copied! <pre>s2 = Student('Siyi', 25, 'Ecology')\ns2.is_ES()\n</pre> s2 = Student('Siyi', 25, 'Ecology') s2.is_ES() Out[38]: <pre>False</pre> In\u00a0[39]: Copied! <pre>s1.age = 40\n</pre> s1.age = 40 In\u00a0[40]: Copied! <pre>s1.age\n</pre> s1.age Out[40]: <pre>40</pre> In\u00a0[41]: Copied! <pre>del(s1.age)\n</pre> del(s1.age) In\u00a0[42]: Copied! <pre>s1.age\n</pre> s1.age <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[42], line 1\n----&gt; 1 s1.age\n\nAttributeError: 'Student' object has no attribute 'age'</pre> In\u00a0[43]: Copied! <pre>s2.age\n</pre> s2.age Out[43]: <pre>25</pre> In\u00a0[44]: Copied! <pre>s1.is_ES()\n</pre> s1.is_ES() Out[44]: <pre>True</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_3_functions_classes_modules/#lecture-3-python-functions-and-classes","title":"Lecture 3 Python Functions and Classes\u00b6","text":"<p>For longer and more complex tasks, it is important to organize your code into reuseable elements. For example, if you find yourself cutting and pasting the same or similar lines of code over and over, you probably need to define a function to encapsulate that code and make it reusable. An important principle in programming in DRY: \"don't repeat yourself\". Repetition is tedious and opens you up to errors. Strive for elegance and simplicity in your programs.</p>"},{"location":"Lecture_3_functions_classes_modules/#functions","title":"Functions\u00b6","text":"<p>Functions are a central part of advanced python programming. Functions take some inputs (\"arguments\") and do something in response. Usually functions return something, but not always.</p>"},{"location":"Lecture_3_functions_classes_modules/#pure-vs-impure-functions","title":"Pure vs. Impure Functions\u00b6","text":"<p>Functions that don't modify their arguments or produce any other side-effects are called pure.</p> <p>Functions that modify their arguments or cause other actions to occur are called impure.</p> <p>Below is an impure function.</p>"},{"location":"Lecture_3_functions_classes_modules/#classes","title":"Classes\u00b6","text":"<p>We have worked with many different types of python objects so far: strings, lists, dictionaries, etc. These objects have different attributes and respond in different ways to the built-in functions (<code>len</code>, etc.)</p> <p>Python is an object oriented programming language.</p> <p>Almost everything in Python is an object, with its properties and methods.</p> <p>How can we make our own, custom objects? Answer: by defining classes.</p>"},{"location":"Lecture_3_functions_classes_modules/#a-class-to-represent-a-student","title":"A class to represent a Student\u00b6","text":""},{"location":"Lecture_3_functions_classes_modules/#the-__init__-function","title":"The __init__() function\u00b6","text":"<p>All classes have a function called __init__(), which is always executed when the class is being initiated.</p>"},{"location":"Lecture_3_functions_classes_modules/#now-lets-add-a-custom-method","title":"Now let's add a custom method:\u00b6","text":""},{"location":"Lecture_3_functions_classes_modules/#modify-object-properties","title":"Modify Object Properties\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/","title":"Lecture 4: Numpy and Matplotlib","text":"In\u00a0[4]: Copied! <pre>import numpy as np\n</pre> import numpy as np <p>What did we just do? We imported a package. This brings new variables (mostly functions) into our interpreter. We access them as follows.</p> In\u00a0[3]: Copied! <pre># find out what's in numpy\ndir(np)\n</pre> # find out what's in numpy dir(np) Out[3]: <pre>['ALLOW_THREADS',\n 'AxisError',\n 'BUFSIZE',\n 'CLIP',\n 'ComplexWarning',\n 'DataSource',\n 'ERR_CALL',\n 'ERR_DEFAULT',\n 'ERR_IGNORE',\n 'ERR_LOG',\n 'ERR_PRINT',\n 'ERR_RAISE',\n 'ERR_WARN',\n 'FLOATING_POINT_SUPPORT',\n 'FPE_DIVIDEBYZERO',\n 'FPE_INVALID',\n 'FPE_OVERFLOW',\n 'FPE_UNDERFLOW',\n 'False_',\n 'Inf',\n 'Infinity',\n 'MAXDIMS',\n 'MAY_SHARE_BOUNDS',\n 'MAY_SHARE_EXACT',\n 'MachAr',\n 'ModuleDeprecationWarning',\n 'NAN',\n 'NINF',\n 'NZERO',\n 'NaN',\n 'PINF',\n 'PZERO',\n 'PackageLoader',\n 'RAISE',\n 'RankWarning',\n 'SHIFT_DIVIDEBYZERO',\n 'SHIFT_INVALID',\n 'SHIFT_OVERFLOW',\n 'SHIFT_UNDERFLOW',\n 'ScalarType',\n 'Tester',\n 'TooHardError',\n 'True_',\n 'UFUNC_BUFSIZE_DEFAULT',\n 'UFUNC_PYVALS_NAME',\n 'VisibleDeprecationWarning',\n 'WRAP',\n '_NoValue',\n '__NUMPY_SETUP__',\n '__all__',\n '__builtins__',\n '__cached__',\n '__config__',\n '__doc__',\n '__file__',\n '__git_revision__',\n '__loader__',\n '__mkl_version__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '__version__',\n '_distributor_init',\n '_globals',\n '_import_tools',\n '_mat',\n 'abs',\n 'absolute',\n 'absolute_import',\n 'add',\n 'add_docstring',\n 'add_newdoc',\n 'add_newdoc_ufunc',\n 'add_newdocs',\n 'alen',\n 'all',\n 'allclose',\n 'alltrue',\n 'amax',\n 'amin',\n 'angle',\n 'any',\n 'append',\n 'apply_along_axis',\n 'apply_over_axes',\n 'arange',\n 'arccos',\n 'arccosh',\n 'arcsin',\n 'arcsinh',\n 'arctan',\n 'arctan2',\n 'arctanh',\n 'argmax',\n 'argmin',\n 'argpartition',\n 'argsort',\n 'argwhere',\n 'around',\n 'array',\n 'array2string',\n 'array_equal',\n 'array_equiv',\n 'array_repr',\n 'array_split',\n 'array_str',\n 'asanyarray',\n 'asarray',\n 'asarray_chkfinite',\n 'ascontiguousarray',\n 'asfarray',\n 'asfortranarray',\n 'asmatrix',\n 'asscalar',\n 'atleast_1d',\n 'atleast_2d',\n 'atleast_3d',\n 'average',\n 'bartlett',\n 'base_repr',\n 'bench',\n 'binary_repr',\n 'bincount',\n 'bitwise_and',\n 'bitwise_not',\n 'bitwise_or',\n 'bitwise_xor',\n 'blackman',\n 'block',\n 'bmat',\n 'bool',\n 'bool8',\n 'bool_',\n 'broadcast',\n 'broadcast_arrays',\n 'broadcast_to',\n 'busday_count',\n 'busday_offset',\n 'busdaycalendar',\n 'byte',\n 'byte_bounds',\n 'bytes0',\n 'bytes_',\n 'c_',\n 'can_cast',\n 'cast',\n 'cbrt',\n 'cdouble',\n 'ceil',\n 'cfloat',\n 'char',\n 'character',\n 'chararray',\n 'choose',\n 'clip',\n 'clongdouble',\n 'clongfloat',\n 'column_stack',\n 'common_type',\n 'compare_chararrays',\n 'compat',\n 'complex',\n 'complex128',\n 'complex256',\n 'complex64',\n 'complex_',\n 'complexfloating',\n 'compress',\n 'concatenate',\n 'conj',\n 'conjugate',\n 'convolve',\n 'copy',\n 'copysign',\n 'copyto',\n 'core',\n 'corrcoef',\n 'correlate',\n 'cos',\n 'cosh',\n 'count_nonzero',\n 'cov',\n 'cross',\n 'csingle',\n 'ctypeslib',\n 'cumprod',\n 'cumproduct',\n 'cumsum',\n 'datetime64',\n 'datetime_as_string',\n 'datetime_data',\n 'deg2rad',\n 'degrees',\n 'delete',\n 'deprecate',\n 'deprecate_with_doc',\n 'diag',\n 'diag_indices',\n 'diag_indices_from',\n 'diagflat',\n 'diagonal',\n 'diff',\n 'digitize',\n 'disp',\n 'divide',\n 'division',\n 'divmod',\n 'dot',\n 'double',\n 'dsplit',\n 'dstack',\n 'dtype',\n 'e',\n 'ediff1d',\n 'einsum',\n 'einsum_path',\n 'emath',\n 'empty',\n 'empty_like',\n 'equal',\n 'errstate',\n 'euler_gamma',\n 'exp',\n 'exp2',\n 'expand_dims',\n 'expm1',\n 'extract',\n 'eye',\n 'fabs',\n 'fastCopyAndTranspose',\n 'fft',\n 'fill_diagonal',\n 'find_common_type',\n 'finfo',\n 'fix',\n 'flatiter',\n 'flatnonzero',\n 'flexible',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float',\n 'float128',\n 'float16',\n 'float32',\n 'float64',\n 'float_',\n 'float_power',\n 'floating',\n 'floor',\n 'floor_divide',\n 'fmax',\n 'fmin',\n 'fmod',\n 'format_parser',\n 'frexp',\n 'frombuffer',\n 'fromfile',\n 'fromfunction',\n 'fromiter',\n 'frompyfunc',\n 'fromregex',\n 'fromstring',\n 'full',\n 'full_like',\n 'fv',\n 'generic',\n 'genfromtxt',\n 'geomspace',\n 'get_array_wrap',\n 'get_include',\n 'get_printoptions',\n 'getbufsize',\n 'geterr',\n 'geterrcall',\n 'geterrobj',\n 'gradient',\n 'greater',\n 'greater_equal',\n 'half',\n 'hamming',\n 'hanning',\n 'heaviside',\n 'histogram',\n 'histogram2d',\n 'histogramdd',\n 'hsplit',\n 'hstack',\n 'hypot',\n 'i0',\n 'identity',\n 'iinfo',\n 'imag',\n 'in1d',\n 'index_exp',\n 'indices',\n 'inexact',\n 'inf',\n 'info',\n 'infty',\n 'inner',\n 'insert',\n 'int',\n 'int0',\n 'int16',\n 'int32',\n 'int64',\n 'int8',\n 'int_',\n 'int_asbuffer',\n 'intc',\n 'integer',\n 'interp',\n 'intersect1d',\n 'intp',\n 'invert',\n 'ipmt',\n 'irr',\n 'is_busday',\n 'isclose',\n 'iscomplex',\n 'iscomplexobj',\n 'isfinite',\n 'isfortran',\n 'isin',\n 'isinf',\n 'isnan',\n 'isnat',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'isrealobj',\n 'isscalar',\n 'issctype',\n 'issubclass_',\n 'issubdtype',\n 'issubsctype',\n 'iterable',\n 'ix_',\n 'kaiser',\n 'kron',\n 'ldexp',\n 'left_shift',\n 'less',\n 'less_equal',\n 'lexsort',\n 'lib',\n 'linalg',\n 'linspace',\n 'little_endian',\n 'load',\n 'loads',\n 'loadtxt',\n 'log',\n 'log10',\n 'log1p',\n 'log2',\n 'logaddexp',\n 'logaddexp2',\n 'logical_and',\n 'logical_not',\n 'logical_or',\n 'logical_xor',\n 'logspace',\n 'long',\n 'longcomplex',\n 'longdouble',\n 'longfloat',\n 'longlong',\n 'lookfor',\n 'ma',\n 'mafromtxt',\n 'mask_indices',\n 'mat',\n 'math',\n 'matmul',\n 'matrix',\n 'matrixlib',\n 'max',\n 'maximum',\n 'maximum_sctype',\n 'may_share_memory',\n 'mean',\n 'median',\n 'memmap',\n 'meshgrid',\n 'mgrid',\n 'min',\n 'min_scalar_type',\n 'minimum',\n 'mintypecode',\n 'mirr',\n 'mod',\n 'modf',\n 'moveaxis',\n 'msort',\n 'multiply',\n 'nan',\n 'nan_to_num',\n 'nanargmax',\n 'nanargmin',\n 'nancumprod',\n 'nancumsum',\n 'nanmax',\n 'nanmean',\n 'nanmedian',\n 'nanmin',\n 'nanpercentile',\n 'nanprod',\n 'nanstd',\n 'nansum',\n 'nanvar',\n 'nbytes',\n 'ndarray',\n 'ndenumerate',\n 'ndfromtxt',\n 'ndim',\n 'ndindex',\n 'nditer',\n 'negative',\n 'nested_iters',\n 'newaxis',\n 'nextafter',\n 'nonzero',\n 'not_equal',\n 'nper',\n 'npv',\n 'numarray',\n 'number',\n 'obj2sctype',\n 'object',\n 'object0',\n 'object_',\n 'ogrid',\n 'oldnumeric',\n 'ones',\n 'ones_like',\n 'outer',\n 'packbits',\n 'pad',\n 'partition',\n 'percentile',\n 'pi',\n 'piecewise',\n 'pkgload',\n 'place',\n 'pmt',\n 'poly',\n 'poly1d',\n 'polyadd',\n 'polyder',\n 'polydiv',\n 'polyfit',\n 'polyint',\n 'polymul',\n 'polynomial',\n 'polysub',\n 'polyval',\n 'positive',\n 'power',\n 'ppmt',\n 'print_function',\n 'prod',\n 'product',\n 'promote_types',\n 'ptp',\n 'put',\n 'putmask',\n 'pv',\n 'r_',\n 'rad2deg',\n 'radians',\n 'random',\n 'rank',\n 'rate',\n 'ravel',\n 'ravel_multi_index',\n 'real',\n 'real_if_close',\n 'rec',\n 'recarray',\n 'recfromcsv',\n 'recfromtxt',\n 'reciprocal',\n 'record',\n 'remainder',\n 'repeat',\n 'require',\n 'reshape',\n 'resize',\n 'result_type',\n 'right_shift',\n 'rint',\n 'roll',\n 'rollaxis',\n 'roots',\n 'rot90',\n 'round',\n 'round_',\n 'row_stack',\n 's_',\n 'safe_eval',\n 'save',\n 'savetxt',\n 'savez',\n 'savez_compressed',\n 'sctype2char',\n 'sctypeDict',\n 'sctypeNA',\n 'sctypes',\n 'searchsorted',\n 'select',\n 'set_numeric_ops',\n 'set_printoptions',\n 'set_string_function',\n 'setbufsize',\n 'setdiff1d',\n 'seterr',\n 'seterrcall',\n 'seterrobj',\n 'setxor1d',\n 'shape',\n 'shares_memory',\n 'short',\n 'show_config',\n 'sign',\n 'signbit',\n 'signedinteger',\n 'sin',\n 'sinc',\n 'single',\n 'singlecomplex',\n 'sinh',\n 'size',\n 'sometrue',\n 'sort',\n 'sort_complex',\n 'source',\n 'spacing',\n 'split',\n 'sqrt',\n 'square',\n 'squeeze',\n 'stack',\n 'std',\n 'str',\n 'str0',\n 'str_',\n 'string_',\n 'subtract',\n 'sum',\n 'swapaxes',\n 'take',\n 'tan',\n 'tanh',\n 'tensordot',\n 'test',\n 'testing',\n 'tile',\n 'timedelta64',\n 'trace',\n 'tracemalloc_domain',\n 'transpose',\n 'trapz',\n 'tri',\n 'tril',\n 'tril_indices',\n 'tril_indices_from',\n 'trim_zeros',\n 'triu',\n 'triu_indices',\n 'triu_indices_from',\n 'true_divide',\n 'trunc',\n 'typeDict',\n 'typeNA',\n 'typecodes',\n 'typename',\n 'ubyte',\n 'ufunc',\n 'uint',\n 'uint0',\n 'uint16',\n 'uint32',\n 'uint64',\n 'uint8',\n 'uintc',\n 'uintp',\n 'ulonglong',\n 'unicode',\n 'unicode_',\n 'union1d',\n 'unique',\n 'unpackbits',\n 'unravel_index',\n 'unsignedinteger',\n 'unwrap',\n 'ushort',\n 'vander',\n 'var',\n 'vdot',\n 'vectorize',\n 'version',\n 'void',\n 'void0',\n 'vsplit',\n 'vstack',\n 'warnings',\n 'where',\n 'who',\n 'zeros',\n 'zeros_like']</pre> In\u00a0[3]: Copied! <pre># find out what version we have\nnp.__version__\n</pre> # find out what version we have np.__version__ Out[3]: <pre>'1.25.1'</pre> <p>The numpy documentation is crucial!</p> <p>http://docs.scipy.org/doc/numpy/reference/</p> In\u00a0[5]: Copied! <pre># create an array from a list\na = np.array([9,0,2,1,0])\n</pre> # create an array from a list a = np.array([9,0,2,1,0]) In\u00a0[6]: Copied! <pre># find out the datatype\na.dtype\n</pre> # find out the datatype a.dtype Out[6]: <pre>dtype('int64')</pre> In\u00a0[7]: Copied! <pre># find out the shape\na.shape\n</pre> # find out the shape a.shape Out[7]: <pre>(5,)</pre> In\u00a0[8]: Copied! <pre># what is the shape\ntype(a.shape)\n</pre> # what is the shape type(a.shape) Out[8]: <pre>tuple</pre> In\u00a0[9]: Copied! <pre># another array with a different datatype and shape\nb = np.array([[5,3,1,9],[9,2,3,0]], dtype=np.float64)\n</pre> # another array with a different datatype and shape b = np.array([[5,3,1,9],[9,2,3,0]], dtype=np.float64) In\u00a0[98]: Copied! <pre># array with 3 rows x 4 columns\na_2d = np.array([[3,2,0,1],[9,1,8,7],[4,0,1,6]]) \na_2d\n</pre> # array with 3 rows x 4 columns a_2d = np.array([[3,2,0,1],[9,1,8,7],[4,0,1,6]])  a_2d Out[98]: <pre>array([[3, 2, 0, 1],\n       [9, 1, 8, 7],\n       [4, 0, 1, 6]])</pre> In\u00a0[99]: Copied! <pre># check dtype and shape\nb.dtype, b.shape\n</pre> # check dtype and shape b.dtype, b.shape Out[99]: <pre>(dtype('float64'), (2, 4))</pre> <p>Important Concept: The fastest varying dimension is the last dimension! The outer level of the hierarchy is the first dimension. (This is called \"c-style\" indexing)</p> In\u00a0[96]: Copied! <pre># create some uniform arrays\nc = np.zeros((9,9))\nd = np.ones((3,6,3), dtype=np.complex128)\ne = np.full((3,3), np.pi)\ne = np.ones_like(c)\nf = np.zeros_like(d)\n# \ng = np.random.rand(3,4)\n</pre> # create some uniform arrays c = np.zeros((9,9)) d = np.ones((3,6,3), dtype=np.complex128) e = np.full((3,3), np.pi) e = np.ones_like(c) f = np.zeros_like(d) #  g = np.random.rand(3,4) <p>The <code>np.arange()</code> function is used to generate an array with evenly spaced values within a given interval. <code>np.arange()</code> can be used with one, two, or three parameters to specify the start, stop, and step values. If only one value is passed to the function, it will be interpreted as the stop value:</p> In\u00a0[12]: Copied! <pre># create some ranges\nnp.arange(10)\n</pre> # create some ranges np.arange(10) Out[12]: <pre>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre> In\u00a0[13]: Copied! <pre># arange is left inclusive, right exclusive\nnp.arange(2,4,0.25)\n</pre> # arange is left inclusive, right exclusive np.arange(2,4,0.25) Out[13]: <pre>array([2.  , 2.25, 2.5 , 2.75, 3.  , 3.25, 3.5 , 3.75])</pre> <p>Similarly, the <code>np.linspace()</code> function is used to construct an array with evenly spaced numbers over a given interval. However, instead of the step parameter, <code>np.linspace()</code> takes a num parameter to specify the number of samples within the given interval:</p> In\u00a0[14]: Copied! <pre># linearly spaced\nnp.linspace(2,4,20)\n</pre> # linearly spaced np.linspace(2,4,20) Out[14]: <pre>array([2.        , 2.10526316, 2.21052632, 2.31578947, 2.42105263,\n       2.52631579, 2.63157895, 2.73684211, 2.84210526, 2.94736842,\n       3.05263158, 3.15789474, 3.26315789, 3.36842105, 3.47368421,\n       3.57894737, 3.68421053, 3.78947368, 3.89473684, 4.        ])</pre> <p>Note that unlike <code>np.arange()</code>, <code>np.linspace()</code> includes the stop value by default (this can be changed by passing <code>endpoint=True</code>). Finally, it should be noted that while we could have used <code>np.arange()</code> to generate the same array in the above example, it is recommended to use <code>np.linspace()</code> when a non-integer step (e.g. 0.25) is desired.</p> In\u00a0[87]: Copied! <pre>np.linspace(2,4,20, endpoint = False)\n</pre> np.linspace(2,4,20, endpoint = False) Out[87]: <pre>array([2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2,\n       3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9])</pre> In\u00a0[3]: Copied! <pre>x = np.linspace(-4, 4, 9)\n \ny = np.linspace(-5, 5, 11)\n \nx_2d, y_2d = np.meshgrid(x, y)\n</pre> x = np.linspace(-4, 4, 9)   y = np.linspace(-5, 5, 11)   x_2d, y_2d = np.meshgrid(x, y) In\u00a0[4]: Copied! <pre>x_2d\n</pre> x_2d Out[4]: <pre>array([[-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.],\n       [-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.]])</pre> In\u00a0[5]: Copied! <pre>y_2d\n</pre> y_2d Out[5]: <pre>array([[-5., -5., -5., -5., -5., -5., -5., -5., -5.],\n       [-4., -4., -4., -4., -4., -4., -4., -4., -4.],\n       [-3., -3., -3., -3., -3., -3., -3., -3., -3.],\n       [-2., -2., -2., -2., -2., -2., -2., -2., -2.],\n       [-1., -1., -1., -1., -1., -1., -1., -1., -1.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.],\n       [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.],\n       [ 4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.],\n       [ 5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.]])</pre> In\u00a0[7]: Copied! <pre># get some individual elements of xx\nx_2d[0,0], x_2d[-1,-1], x_2d[3,-5]\n</pre> # get some individual elements of xx x_2d[0,0], x_2d[-1,-1], x_2d[3,-5] Out[7]: <pre>(-4.0, 4.0, 0.0)</pre> In\u00a0[8]: Copied! <pre># get some whole rows and columns\nx_2d[0].shape, x_2d[:,-1].shape\n</pre> # get some whole rows and columns x_2d[0].shape, x_2d[:,-1].shape Out[8]: <pre>((9,), (11,))</pre> In\u00a0[9]: Copied! <pre># get some ranges\nx_2d[3:10,3:5].shape\n</pre> # get some ranges x_2d[3:10,3:5].shape Out[9]: <pre>(7, 2)</pre> <p>There are many advanced ways to index arrays. You can read about them in the manual. Here is one example.</p> In\u00a0[10]: Copied! <pre># use a boolean array as an index\nidx = x_2d&lt;0\nx_2d[idx].shape\n</pre> # use a boolean array as an index idx = x_2d&lt;0 x_2d[idx].shape Out[10]: <pre>(44,)</pre> In\u00a0[11]: Copied! <pre># two dimensional grids\nx = np.linspace(-2*np.pi, 2*np.pi, 100)\ny = np.linspace(-np.pi, np.pi, 50)\nxx, yy = np.meshgrid(x, y)\nxx.shape, yy.shape\n</pre> # two dimensional grids x = np.linspace(-2*np.pi, 2*np.pi, 100) y = np.linspace(-np.pi, np.pi, 50) xx, yy = np.meshgrid(x, y) xx.shape, yy.shape Out[11]: <pre>((50, 100), (50, 100))</pre> In\u00a0[12]: Copied! <pre>f = np.sin(xx) * np.cos(0.5*yy)\n</pre> f = np.sin(xx) * np.cos(0.5*yy) <p>At this point you might be getting curious what these arrays \"look\" like. So we need to introduce some visualization.</p> In\u00a0[7]: Copied! <pre>from matplotlib import pyplot as plt\n# %matplotlib inline\n</pre> from matplotlib import pyplot as plt # %matplotlib inline In\u00a0[14]: Copied! <pre>plt.pcolormesh(f)\n</pre> plt.pcolormesh(f) Out[14]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1143ebc10&gt;</pre> In\u00a0[15]: Copied! <pre># transpose\nplt.pcolormesh(f.T)\n</pre> # transpose plt.pcolormesh(f.T) Out[15]: <pre>&lt;matplotlib.collections.QuadMesh at 0x11457d760&gt;</pre> In\u00a0[16]: Copied! <pre># Flip the array up/down (reverse the order of the rows)\nplt.pcolormesh(np.flipud(f))\n</pre> # Flip the array up/down (reverse the order of the rows) plt.pcolormesh(np.flipud(f))  Out[16]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1145e6e80&gt;</pre> In\u00a0[17]: Copied! <pre># reshape an array (wrong size)\ng = np.reshape(f, (8,9))\n</pre> # reshape an array (wrong size) g = np.reshape(f, (8,9)) <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[17], line 2\n      1 # reshape an array (wrong size)\n----&gt; 2 g = np.reshape(f, (8,9))\n\nFile /opt/anaconda3/envs/research_computing_scipy/lib/python3.9/site-packages/numpy/core/fromnumeric.py:285, in reshape(a, newshape, order)\n    200 @array_function_dispatch(_reshape_dispatcher)\n    201 def reshape(a, newshape, order='C'):\n    202 \"\"\"\n    203     Gives a new shape to an array without changing its data.\n    204 \n   (...)\n    283            [5, 6]])\n    284     \"\"\"\n--&gt; 285     return _wrapfunc(a, 'reshape', newshape, order=order)\n\nFile /opt/anaconda3/envs/research_computing_scipy/lib/python3.9/site-packages/numpy/core/fromnumeric.py:59, in _wrapfunc(obj, method, *args, **kwds)\n     56     return _wrapit(obj, method, *args, **kwds)\n     58 try:\n---&gt; 59     return bound(*args, **kwds)\n     60 except TypeError:\n     61     # A TypeError occurs if the object does have such a method in its\n     62     # class, but its signature is not identical to that of NumPy's. This\n   (...)\n     66     # Call _wrapit from within the except clause to ensure a potential\n     67     # exception has a traceback chain.\n     68     return _wrapit(obj, method, *args, **kwds)\n\nValueError: cannot reshape array of size 5000 into shape (8,9)</pre> In\u00a0[18]: Copied! <pre># reshape an array (right size) and mess it up\nprint(f.size)\ng = np.reshape(f, (200,25))\nplt.pcolormesh(g)\n</pre> # reshape an array (right size) and mess it up print(f.size) g = np.reshape(f, (200,25)) plt.pcolormesh(g) <pre>5000\n</pre> Out[18]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1147de760&gt;</pre> In\u00a0[19]: Copied! <pre>f.shape\n</pre> f.shape Out[19]: <pre>(50, 100)</pre> In\u00a0[20]: Copied! <pre>np.tile(f,(6,1)).shape\n</pre> np.tile(f,(6,1)).shape Out[20]: <pre>(300, 100)</pre> In\u00a0[21]: Copied! <pre># tile an array\nplt.pcolormesh(np.tile(f,(6,1)))\n</pre> # tile an array plt.pcolormesh(np.tile(f,(6,1))) Out[21]: <pre>&lt;matplotlib.collections.QuadMesh at 0x114948a60&gt;</pre> In\u00a0[23]: Copied! <pre>from IPython.display import Image\nImage(url='http://scipy-lectures.github.io/_images/numpy_broadcasting.png',\n     width=720)\n</pre> from IPython.display import Image Image(url='http://scipy-lectures.github.io/_images/numpy_broadcasting.png',      width=720) Out[23]: In\u00a0[24]: Copied! <pre># multiply f by x\nprint(f.shape, x.shape)\ng = f * x\nprint(g.shape)\n</pre> # multiply f by x print(f.shape, x.shape) g = f * x print(g.shape) <pre>(50, 100) (100,)\n(50, 100)\n</pre> In\u00a0[25]: Copied! <pre># multiply f by y\nprint(f.shape, y.shape)\nh = f * y\nprint(h.shape)\n</pre> # multiply f by y print(f.shape, y.shape) h = f * y print(h.shape) <pre>(50, 100) (50,)\n</pre> <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[25], line 3\n      1 # multiply f by y\n      2 print(f.shape, y.shape)\n----&gt; 3 h = f * y\n      4 print(h.shape)\n\nValueError: operands could not be broadcast together with shapes (50,100) (50,) </pre> In\u00a0[26]: Copied! <pre># use newaxis special syntax\nh = f * y[:,np.newaxis]\nprint(h.shape)\n</pre> # use newaxis special syntax h = f * y[:,np.newaxis] print(h.shape) <pre>(50, 100)\n</pre> In\u00a0[27]: Copied! <pre># sum\ng.sum()\n</pre> # sum g.sum() Out[27]: <pre>-3083.038387807155</pre> In\u00a0[28]: Copied! <pre># mean\ng.mean()\n</pre> # mean g.mean() Out[28]: <pre>-0.616607677561431</pre> In\u00a0[29]: Copied! <pre># std\ng.std()\n</pre> # std g.std() Out[29]: <pre>1.6402280119141424</pre> In\u00a0[30]: Copied! <pre># apply on just one axis\n\n# Mean of each row (calculated across columns)\ng_xmean = g.mean(axis=1)\n\n# Mean of each column (calculated across rows)\n\ng_ymean = g.mean(axis=0)\n</pre> # apply on just one axis  # Mean of each row (calculated across columns) g_xmean = g.mean(axis=1)  # Mean of each column (calculated across rows)  g_ymean = g.mean(axis=0) In\u00a0[31]: Copied! <pre>plt.plot(x, g_ymean)\n</pre> plt.plot(x, g_ymean) Out[31]: <pre>[&lt;matplotlib.lines.Line2D at 0x114a38880&gt;]</pre> In\u00a0[32]: Copied! <pre>plt.plot(g_xmean, y)\n</pre> plt.plot(g_xmean, y) Out[32]: <pre>[&lt;matplotlib.lines.Line2D at 0x114a8e6a0&gt;]</pre> <p>Most real-world datasets \u2013 environmental or otherwise \u2013 have data gaps. Data can be missing for any number of reasons, including observations not being recorded or data corruption. While a cell corresponding to a data gap may just be left blank in a spreadsheet, when imported into Python, there must be some way to handle \"blank\" or missing values.</p> <p>Missing data should not be replaced with zeros, as 0 can be a valid value for many datasets, (e.g. temperature, precipitation, etc.). Instead, the convention is to fill all missing data with the constant NaN. NaN stands for \"Not a Number\" and is implemented in NumPy as np.nan.</p> <p>NaNs are handled differently by different packages. In NumPy, all computations involving NaN values will return nan:</p> In\u00a0[33]: Copied! <pre>data = np.array([[2.,2.7,1.89],\n                 [1.1, 0.0, np.nan],\n                 [3.2, 0.74, 2.1]])\n</pre> data = np.array([[2.,2.7,1.89],                  [1.1, 0.0, np.nan],                  [3.2, 0.74, 2.1]]) In\u00a0[34]: Copied! <pre>np.mean(data)\n</pre> np.mean(data) Out[34]: <pre>nan</pre> In\u00a0[35]: Copied! <pre>np.nanmean(data)\n</pre> np.nanmean(data) Out[35]: <pre>1.71625</pre> In\u00a0[36]: Copied! <pre>fig = plt.figure()\n</pre> fig = plt.figure() <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> In\u00a0[37]: Copied! <pre>fig = plt.figure(figsize=(13, 5))\n</pre> fig = plt.figure(figsize=(13, 5)) <pre>&lt;Figure size 1300x500 with 0 Axes&gt;</pre> In\u00a0[38]: Copied! <pre>fig = plt.figure()\nax = fig.add_axes([0, 0, 1, 1])\n</pre> fig = plt.figure() ax = fig.add_axes([0, 0, 1, 1]) In\u00a0[39]: Copied! <pre>fig = plt.figure()\nax = fig.add_axes([0, 0, 0.5, 1])\n</pre> fig = plt.figure() ax = fig.add_axes([0, 0, 0.5, 1]) In\u00a0[40]: Copied! <pre>fig = plt.figure()\nax1 = fig.add_axes([0, 0, 0.5, 1])\nax2 = fig.add_axes([0.6, 0, 0.3, 0.5], facecolor='g')\n</pre> fig = plt.figure() ax1 = fig.add_axes([0, 0, 0.5, 1]) ax2 = fig.add_axes([0.6, 0, 0.3, 0.5], facecolor='g') In\u00a0[41]: Copied! <pre>fig = plt.figure()\naxes = fig.subplots(nrows=2, ncols=3)\n</pre> fig = plt.figure() axes = fig.subplots(nrows=2, ncols=3) In\u00a0[43]: Copied! <pre>fig = plt.figure(figsize=(12, 6))\naxes = fig.subplots(nrows=2, ncols=3)\n</pre> fig = plt.figure(figsize=(12, 6)) axes = fig.subplots(nrows=2, ncols=3) In\u00a0[44]: Copied! <pre>axes\n</pre> axes Out[44]: <pre>array([[&lt;Axes: &gt;, &lt;Axes: &gt;, &lt;Axes: &gt;],\n       [&lt;Axes: &gt;, &lt;Axes: &gt;, &lt;Axes: &gt;]], dtype=object)</pre> <p>There is a shorthand for doing this all at once.</p> <p>This is our recommended way to create new figures!</p> In\u00a0[45]: Copied! <pre>fig, ax = plt.subplots()\n</pre> fig, ax = plt.subplots() In\u00a0[46]: Copied! <pre>ax\n</pre> ax Out[46]: <pre>&lt;Axes: &gt;</pre> In\u00a0[47]: Copied! <pre>fig, axes = plt.subplots(ncols=2, figsize=(8, 4), subplot_kw={'facecolor': 'g'})\n</pre> fig, axes = plt.subplots(ncols=2, figsize=(8, 4), subplot_kw={'facecolor': 'g'}) In\u00a0[48]: Copied! <pre>axes\n</pre> axes Out[48]: <pre>array([&lt;Axes: &gt;, &lt;Axes: &gt;], dtype=object)</pre> In\u00a0[49]: Copied! <pre># create some data to plot\nimport numpy as np\nx = np.linspace(-np.pi, np.pi, 100)\ny = np.cos(x)\nz = np.sin(6*x)\n</pre> # create some data to plot import numpy as np x = np.linspace(-np.pi, np.pi, 100) y = np.cos(x) z = np.sin(6*x) In\u00a0[50]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y)\n</pre> fig, ax = plt.subplots() ax.plot(x, y) Out[50]: <pre>[&lt;matplotlib.lines.Line2D at 0x114ca27c0&gt;]</pre> <p>This does the same thing as</p> In\u00a0[51]: Copied! <pre>plt.plot(x, y)\n</pre> plt.plot(x, y) Out[51]: <pre>[&lt;matplotlib.lines.Line2D at 0x173539e80&gt;]</pre> <p>This starts to matter when we have multiple axes to worry about.</p> In\u00a0[52]: Copied! <pre>fig, axes = plt.subplots(figsize=(8, 4), ncols=2)\nax0, ax1 = axes\nax0.plot(x, y)\nax1.plot(x, z)\n</pre> fig, axes = plt.subplots(figsize=(8, 4), ncols=2) ax0, ax1 = axes ax0.plot(x, y) ax1.plot(x, z) Out[52]: <pre>[&lt;matplotlib.lines.Line2D at 0x1736068e0&gt;]</pre> In\u00a0[53]: Copied! <pre>fig, axes = plt.subplots(figsize=(8, 4), ncols=2)\nax0, ax1 = axes\n\nax0.plot(x, y)\nax0.set_xlabel('x')\nax0.set_ylabel('y')\nax0.set_title('x vs. y')\n\nax1.plot(x, z)\nax1.set_xlabel('x')\nax1.set_ylabel('z')\nax1.set_title('x vs. z')\n\n# squeeze everything in\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(figsize=(8, 4), ncols=2) ax0, ax1 = axes  ax0.plot(x, y) ax0.set_xlabel('x') ax0.set_ylabel('y') ax0.set_title('x vs. y')  ax1.plot(x, z) ax1.set_xlabel('x') ax1.set_ylabel('z') ax1.set_title('x vs. z')  # squeeze everything in plt.tight_layout() In\u00a0[54]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, x, z)\n</pre> fig, ax = plt.subplots() ax.plot(x, y, x, z) Out[54]: <pre>[&lt;matplotlib.lines.Line2D at 0x1737b42e0&gt;,\n &lt;matplotlib.lines.Line2D at 0x1737b4340&gt;]</pre> <p>It's simple to switch axes</p> In\u00a0[55]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(y, x, z, x)\n</pre> fig, ax = plt.subplots() ax.plot(y, x, z, x) Out[55]: <pre>[&lt;matplotlib.lines.Line2D at 0x173839670&gt;,\n &lt;matplotlib.lines.Line2D at 0x1738396d0&gt;]</pre> In\u00a0[56]: Copied! <pre>fig, axes = plt.subplots(figsize=(16, 5), ncols=3)\naxes[0].plot(x, y, linestyle='dashed')\naxes[0].plot(x, z, linestyle='--')\n\naxes[1].plot(x, y, linestyle='dotted')\naxes[1].plot(x, z, linestyle=':')\n\naxes[2].plot(x, y, linestyle='dashdot', linewidth=5)\naxes[2].plot(x, z, linestyle='-.', linewidth=0.5)\n</pre> fig, axes = plt.subplots(figsize=(16, 5), ncols=3) axes[0].plot(x, y, linestyle='dashed') axes[0].plot(x, z, linestyle='--')  axes[1].plot(x, y, linestyle='dotted') axes[1].plot(x, z, linestyle=':')  axes[2].plot(x, y, linestyle='dashdot', linewidth=5) axes[2].plot(x, z, linestyle='-.', linewidth=0.5)  Out[56]: <pre>[&lt;matplotlib.lines.Line2D at 0x1739476d0&gt;]</pre> In\u00a0[57]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, color='k')\nax.plot(x, z, color='r')\n</pre> fig, ax = plt.subplots() ax.plot(x, y, color='k') ax.plot(x, z, color='r') Out[57]: <pre>[&lt;matplotlib.lines.Line2D at 0x173a47850&gt;]</pre> <p>Other ways to specify colors:</p> In\u00a0[58]: Copied! <pre>fig, axes = plt.subplots(figsize=(16, 5), ncols=3)\n\n# grayscale\naxes[0].plot(x, y, color='0.8')\naxes[0].plot(x, z, color='0.2')\n\n# RGB tuple\naxes[1].plot(x, y, color=(1, 0, 0.7))\naxes[1].plot(x, z, color=(0, 0.4, 0.3))\n\n# HTML hex code\naxes[2].plot(x, y, color='#00dcba')\naxes[2].plot(x, z, color='#b029ee')\n</pre> fig, axes = plt.subplots(figsize=(16, 5), ncols=3)  # grayscale axes[0].plot(x, y, color='0.8') axes[0].plot(x, z, color='0.2')  # RGB tuple axes[1].plot(x, y, color=(1, 0, 0.7)) axes[1].plot(x, z, color=(0, 0.4, 0.3))  # HTML hex code axes[2].plot(x, y, color='#00dcba') axes[2].plot(x, z, color='#b029ee') Out[58]: <pre>[&lt;matplotlib.lines.Line2D at 0x173b536d0&gt;]</pre> <p>There is a default color cycle built into matplotlib.</p> In\u00a0[59]: Copied! <pre>plt.rcParams['axes.prop_cycle']\n</pre> plt.rcParams['axes.prop_cycle'] Out[59]: 'color''#1f77b4''#ff7f0e''#2ca02c''#d62728''#9467bd''#8c564b''#e377c2''#7f7f7f''#bcbd22''#17becf' In\u00a0[60]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 10))\nfor factor in np.linspace(0.2, 1, 11):\n    ax.plot(x, factor*y)\n</pre> fig, ax = plt.subplots(figsize=(12, 10)) for factor in np.linspace(0.2, 1, 11):     ax.plot(x, factor*y) In\u00a0[61]: Copied! <pre>fig, axes = plt.subplots(figsize=(12, 5), ncols=2)\n\naxes[0].plot(x[:20], y[:20], marker='.')\naxes[0].plot(x[:20], z[:20], marker='o')\n\naxes[1].plot(x[:20], z[:20], marker='^',\n             markersize=10, markerfacecolor='r',\n             markeredgecolor='k')\n</pre> fig, axes = plt.subplots(figsize=(12, 5), ncols=2)  axes[0].plot(x[:20], y[:20], marker='.') axes[0].plot(x[:20], z[:20], marker='o')  axes[1].plot(x[:20], z[:20], marker='^',              markersize=10, markerfacecolor='r',              markeredgecolor='k') Out[61]: <pre>[&lt;matplotlib.lines.Line2D at 0x114e7e310&gt;]</pre> In\u00a0[73]: Copied! <pre>fig, ax = plt.subplots(figsize=(12, 7))\nax.plot(x, y)\n\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_title('A complicated math function: $f(x) = \\cos(x)$')\n\nax.set_xticks(np.pi * np.array([-1, 0, 1]))\nax.set_xticklabels(['$-\\pi$', '0', '$\\pi$'])\nax.set_yticks([-1, 0, 1])\n\nax.set_yticks(np.arange(-1, 1.1, 0.2), minor=True)\n#ax.set_xticks(np.arange(-3, 3.1, 0.2), minor=True)\n\nax.grid(which='minor', linestyle='--')\nax.grid(which='major', linewidth=2)\n</pre> fig, ax = plt.subplots(figsize=(12, 7)) ax.plot(x, y)  ax.set_xlabel('x') ax.set_ylabel('y') ax.set_title('A complicated math function: $f(x) = \\cos(x)$')  ax.set_xticks(np.pi * np.array([-1, 0, 1])) ax.set_xticklabels(['$-\\pi$', '0', '$\\pi$']) ax.set_yticks([-1, 0, 1])  ax.set_yticks(np.arange(-1, 1.1, 0.2), minor=True) #ax.set_xticks(np.arange(-3, 3.1, 0.2), minor=True)  ax.grid(which='minor', linestyle='--') ax.grid(which='major', linewidth=2)  In\u00a0[63]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, x, z)\nax.set_xlim(-5, 5)\nax.set_ylim(-3, 3)\n</pre> fig, ax = plt.subplots() ax.plot(x, y, x, z) ax.set_xlim(-5, 5) ax.set_ylim(-3, 3) Out[63]: <pre>(-3.0, 3.0)</pre> In\u00a0[64]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y, x, z)\nax.set_xlim(-5, 5)\nax.set_ylim(-100, 100)\n</pre> fig, ax = plt.subplots() ax.plot(x, y, x, z) ax.set_xlim(-5, 5) ax.set_ylim(-100, 100) Out[64]: <pre>(-100.0, 100.0)</pre> In\u00a0[65]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y)\nax.text(-3, 0.3, 'hello world')\nax.annotate('the maximum', xy=(0, 1),\n             xytext=(0, 0), arrowprops={'facecolor': 'k'})\n</pre> fig, ax = plt.subplots() ax.plot(x, y) ax.text(-3, 0.3, 'hello world') ax.annotate('the maximum', xy=(0, 1),              xytext=(0, 0), arrowprops={'facecolor': 'k'}) Out[65]: <pre>Text(0, 0, 'the maximum')</pre> In\u00a0[78]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x, y)\nax.text(0.1, 0.9, 'hello world', transform=ax.transAxes)\nax.annotate('the maximum', xy=(0, 1),\n             xytext=(0, 0), arrowprops={'facecolor': 'k'})\n</pre> fig, ax = plt.subplots() ax.plot(x, y) ax.text(0.1, 0.9, 'hello world', transform=ax.transAxes) ax.annotate('the maximum', xy=(0, 1),              xytext=(0, 0), arrowprops={'facecolor': 'k'}) Out[78]: <pre>Text(0, 0, 'the maximum')</pre> In\u00a0[66]: Copied! <pre>fig, ax = plt.subplots()\n\nsplot = ax.scatter(y, z, c=x, s=(100*z**2 + 5))\nfig.colorbar(splot)\n</pre> fig, ax = plt.subplots()  splot = ax.scatter(y, z, c=x, s=(100*z**2 + 5)) fig.colorbar(splot) Out[66]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x173e08af0&gt;</pre> In\u00a0[67]: Copied! <pre>labels = ['first', 'second', 'third']\nvalues = [10, 5, 30]\n\nfig, axes = plt.subplots(figsize=(10, 5), ncols=2)\naxes[0].bar(labels, values)\naxes[1].barh(labels, values)\n</pre> labels = ['first', 'second', 'third'] values = [10, 5, 30]  fig, axes = plt.subplots(figsize=(10, 5), ncols=2) axes[0].bar(labels, values) axes[1].barh(labels, values) Out[67]: <pre>&lt;BarContainer object of 3 artists&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[5]: Copied! <pre>x1d = np.linspace(-2*np.pi, 2*np.pi, 100)\ny1d = np.linspace(-np.pi, np.pi, 50)\nxx, yy = np.meshgrid(x1d, y1d)\nf = np.cos(xx) * np.sin(yy)\nprint(f.shape)\n</pre> x1d = np.linspace(-2*np.pi, 2*np.pi, 100) y1d = np.linspace(-np.pi, np.pi, 50) xx, yy = np.meshgrid(x1d, y1d) f = np.cos(xx) * np.sin(yy) print(f.shape) <pre>(50, 100)\n</pre> In\u00a0[8]: Copied! <pre>fig, ax = plt.subplots(figsize=(12,4), ncols=2)\nax[0].imshow(f)\nax[1].imshow(f, origin='lower')\n</pre> fig, ax = plt.subplots(figsize=(12,4), ncols=2) ax[0].imshow(f) ax[1].imshow(f, origin='lower') Out[8]: <pre>&lt;matplotlib.image.AxesImage at 0x10c79f3d0&gt;</pre> In\u00a0[9]: Copied! <pre>fig, ax = plt.subplots(ncols=2, figsize=(12, 5))\npc0 = ax[0].pcolormesh(x1d, y1d, f)\npc1 = ax[1].pcolormesh(xx, yy, f)\nfig.colorbar(pc0, ax=ax[0])\nfig.colorbar(pc1, ax=ax[1])\n</pre> fig, ax = plt.subplots(ncols=2, figsize=(12, 5)) pc0 = ax[0].pcolormesh(x1d, y1d, f) pc1 = ax[1].pcolormesh(xx, yy, f) fig.colorbar(pc0, ax=ax[0]) fig.colorbar(pc1, ax=ax[1])  Out[9]: <pre>&lt;matplotlib.colorbar.Colorbar at 0x10c9d2e20&gt;</pre> In\u00a0[13]: Copied! <pre>x_sm, y_sm, f_sm = xx[:10, :10], yy[:10, :10], f[:10, :10]\n\nfig, ax = plt.subplots(figsize=(12,5), ncols=2)\n\n# last row and column ignored!\nax[0].pcolormesh(x_sm, y_sm, f_sm, edgecolors='k', shading = 'nearest')\n\n# same!\nax[1].pcolormesh(x_sm, y_sm, f_sm[:-1, :-1], edgecolors='k', shading = 'flat')\n</pre> x_sm, y_sm, f_sm = xx[:10, :10], yy[:10, :10], f[:10, :10]  fig, ax = plt.subplots(figsize=(12,5), ncols=2)  # last row and column ignored! ax[0].pcolormesh(x_sm, y_sm, f_sm, edgecolors='k', shading = 'nearest')  # same! ax[1].pcolormesh(x_sm, y_sm, f_sm[:-1, :-1], edgecolors='k', shading = 'flat')  Out[13]: <pre>&lt;matplotlib.collections.QuadMesh at 0x10d8555b0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_4_numpy_and_matplotlib/#lecture-4-numpy-and-matplotlib","title":"Lecture 4: Numpy and Matplotlib\u00b6","text":"<p>These are two of the most fundamental parts of the scientific python \"ecosystem\". Most everything else is built on top of them.</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#to-install-matplotlib","title":"To install Matplotlib:\u00b6","text":"<p>Open a Terminal window, activate rcaes_env: </p> <p>conda activate rcaes_env  conda install -c conda-forge matplotlib </p>"},{"location":"Lecture_4_numpy_and_matplotlib/#numpy","title":"Numpy\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#ndarrays","title":"NDArrays\u00b6","text":"<p>The core class is the numpy ndarray (n-dimensional array). The n-dimensional array object in NumPy is referred to as an ndarray, a multidimensional container of homogeneous items \u2013 i.e. all values in the array are the same type and size. These arrays can be one-dimensional (one row or column vector), two-dimensional (m rows x n columns), or three-dimensional (arrays within arrays).</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#create-array-from-a-list","title":"Create array from a list\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#create-arrays-using-functions","title":"Create arrays using functions\u00b6","text":"<p>There are lots of ways to create arrays.</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#create-two-dimensional-grids","title":"Create two-dimensional grids\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#indexing","title":"Indexing\u00b6","text":"<p>Basic indexing is similar to lists</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#array-operations","title":"Array Operations\u00b6","text":"<p>There are a huge number of operations available on arrays. All the familiar arithemtic operators are applied on an element-by-element basis.</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#basic-math","title":"Basic Math\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#manipulating-array-dimensions","title":"Manipulating array dimensions\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#broadcasting","title":"Broadcasting\u00b6","text":"<p>Broadcasting is an efficient way to multiply arrays of different sizes</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#reduction-operations","title":"Reduction Operations\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#missing-data","title":"Missing data\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#more-matplotlib","title":"More Matplotlib\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#figure-and-axes","title":"Figure and Axes\u00b6","text":"<p>The figure is the highest level of organization of matplotlib objects. If we want, we can create a figure explicitly.</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#subplots","title":"Subplots\u00b6","text":"<p>Subplot syntax is one way to specify the creation of multiple axes.</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#drawing-into-axes","title":"Drawing into Axes\u00b6","text":"<p>All plots are drawn into axes. It is easiest to understand how matplotlib works if you use the object-oriented style.</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#labeling-plots","title":"Labeling Plots\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#customizing-line-plots","title":"Customizing Line Plots\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#line-styles","title":"Line Styles\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#colors","title":"Colors\u00b6","text":"<p>As described in the colors documentation, there are some special codes for commonly used colors:</p> <ul> <li>b: blue</li> <li>g: green</li> <li>r: red</li> <li>c: cyan</li> <li>m: magenta</li> <li>y: yellow</li> <li>k: black</li> <li>w: white</li> </ul>"},{"location":"Lecture_4_numpy_and_matplotlib/#markers","title":"Markers\u00b6","text":"<p>There are lots of different markers availabile in matplotlib!</p>"},{"location":"Lecture_4_numpy_and_matplotlib/#label-ticks-and-gridlines","title":"Label, Ticks, and Gridlines\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#axis-limits","title":"Axis Limits\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#text-annotations","title":"Text Annotations\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#other-1d-plots","title":"Other 1D Plots\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#scatter-plots","title":"Scatter Plots\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#bar-plots","title":"Bar Plots\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#2d-plotting-methods","title":"2D Plotting Methods\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#imshow","title":"imshow\u00b6","text":""},{"location":"Lecture_4_numpy_and_matplotlib/#pcolormesh","title":"pcolormesh\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/","title":"Lecture 6: Pandas Basics","text":"<p>Let's start by importing pandas library</p> In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n</pre> import pandas as pd import numpy as np from matplotlib import pyplot as plt In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>A Series represents a one-dimensional array of data. The main difference between a Series and numpy array is that a Series has an index. The index contains the labels that we use to access the data.</p> <p>There are many ways to create a Series. We will just show a few.</p> In\u00a0[16]: Copied! <pre># Create a series from list \nnames = ['Xiaomeng', 'Siyi','Siyi', 'Matt']\nvalues = [32, 25,26, 22]\nages = pd.Series(values, index=names)\nages\n</pre> # Create a series from list  names = ['Xiaomeng', 'Siyi','Siyi', 'Matt'] values = [32, 25,26, 22] ages = pd.Series(values, index=names) ages Out[16]: <pre>Xiaomeng    32\nSiyi        25\nSiyi        26\nMatt        22\ndtype: int64</pre> In\u00a0[17]: Copied! <pre>ages.plot(kind='bar')\n</pre> ages.plot(kind='bar') Out[17]: <pre>&lt;Axes: &gt;</pre> <p>Arithmetic operations and most numpy function can be applied to Series.</p> <p>An important point is that the Series keep their index during such operations.</p> In\u00a0[19]: Copied! <pre>np.sqrt(ages)\n</pre> np.sqrt(ages) Out[19]: <pre>Xiaomeng    5.656854\nSiyi        5.000000\nSiyi        5.099020\nMatt        4.690416\ndtype: float64</pre> <p>We can access the underlying index object if we need to:</p> In\u00a0[7]: Copied! <pre>ages.index\n</pre> ages.index Out[7]: <pre>Index(['Xiaomeng', 'Siyi', 'Siyi', 'Matt'], dtype='object')</pre> <p>We can get values back out using the index via the <code>.loc</code> attribute</p> In\u00a0[8]: Copied! <pre>ages.loc['Xiaomeng']\n</pre> ages.loc['Xiaomeng'] Out[8]: <pre>32</pre> In\u00a0[9]: Copied! <pre>ages.loc['Siyi']\n</pre> ages.loc['Siyi'] Out[9]: <pre>Siyi    25\nSiyi    26\ndtype: int64</pre> <p>Or by raw position using <code>.iloc</code></p> In\u00a0[20]: Copied! <pre>ages.iloc[2]\n</pre> ages.iloc[2] Out[20]: <pre>26</pre> <p>We can pass a list or array to loc to get multiple rows back:</p> In\u00a0[21]: Copied! <pre>ages.loc[['Matt', 'Siyi']]\n</pre> ages.loc[['Matt', 'Siyi']] Out[21]: <pre>Matt    22\nSiyi    25\nSiyi    26\ndtype: int64</pre> <p>And we can even use slice notation</p> In\u00a0[22]: Copied! <pre>ages.loc['Xiaomeng':'Matt']\n</pre> ages.loc['Xiaomeng':'Matt'] Out[22]: <pre>Xiaomeng    32\nSiyi        25\nSiyi        26\nMatt        22\ndtype: int64</pre> In\u00a0[23]: Copied! <pre>ages.iloc[:2]\n</pre> ages.iloc[:2] Out[23]: <pre>Xiaomeng    32\nSiyi        25\ndtype: int64</pre> <p>If we need to, we can always get the raw data back out as well</p> In\u00a0[24]: Copied! <pre>ages.values # a numpy array\n</pre> ages.values # a numpy array Out[24]: <pre>array([32, 25, 26, 22])</pre> In\u00a0[25]: Copied! <pre>ages.index # a pandas Index object\n</pre> ages.index # a pandas Index object Out[25]: <pre>Index(['Xiaomeng', 'Siyi', 'Siyi', 'Matt'], dtype='object')</pre> In\u00a0[26]: Copied! <pre># first we create a dictionary\ndata = {'age': [32, 25, 22],\n        'height': [160, np.NaN, np.NaN],\n        'is_teacher': [True, False, False]}\ndf = pd.DataFrame(data, index=['Xiaomeng', 'Siyi', 'Matt'])\ndf\n</pre> # first we create a dictionary data = {'age': [32, 25, 22],         'height': [160, np.NaN, np.NaN],         'is_teacher': [True, False, False]} df = pd.DataFrame(data, index=['Xiaomeng', 'Siyi', 'Matt']) df Out[26]: age height is_teacher Xiaomeng 32 160.0 True Siyi 25 NaN False Matt 22 NaN False In\u00a0[31]: Copied! <pre># You can set the style of the table\ndf.style.highlight_max()\n</pre> # You can set the style of the table df.style.highlight_max() Out[31]: age height is_teacher Xiaomeng 32 160.000000 True Siyi 25 nan False Matt 22 nan False <p>Pandas handles missing data very elegantly, keeping track of it through all calculations.</p> <p>A wide range of statistical functions are available on both Series and DataFrames.</p> In\u00a0[32]: Copied! <pre>df.min()\n</pre> df.min() Out[32]: <pre>age              22\nheight        160.0\nis_teacher    False\ndtype: object</pre> In\u00a0[33]: Copied! <pre>df.mean()\n</pre> df.mean() Out[33]: <pre>age            26.333333\nheight        160.000000\nis_teacher      0.333333\ndtype: float64</pre> In\u00a0[34]: Copied! <pre>df.count()\n</pre> df.count() Out[34]: <pre>age           3\nheight        1\nis_teacher    3\ndtype: int64</pre> In\u00a0[35]: Copied! <pre>df.std()\n</pre> df.std() Out[35]: <pre>age           5.131601\nheight             NaN\nis_teacher    0.577350\ndtype: float64</pre> In\u00a0[36]: Copied! <pre>df.describe()\n</pre> df.describe() Out[36]: age height count 3.000000 1.0 mean 26.333333 160.0 std 5.131601 NaN min 22.000000 160.0 25% 23.500000 160.0 50% 25.000000 160.0 75% 28.500000 160.0 max 32.000000 160.0 <p>We can get a single column as a Series using python's getitem syntax on the DataFrame object.</p> In\u00a0[37]: Copied! <pre>df['height']\n</pre> df['height'] Out[37]: <pre>Xiaomeng    160.0\nSiyi          NaN\nMatt          NaN\nName: height, dtype: float64</pre> <p>...or using attribute syntax.</p> In\u00a0[38]: Copied! <pre>df.height\n</pre> df.height Out[38]: <pre>Xiaomeng    160.0\nSiyi          NaN\nMatt          NaN\nName: height, dtype: float64</pre> <p>Indexing works very similar to series</p> In\u00a0[39]: Copied! <pre>df.loc['Xiaomeng']\n</pre> df.loc['Xiaomeng'] Out[39]: <pre>age              32\nheight        160.0\nis_teacher     True\nName: Xiaomeng, dtype: object</pre> In\u00a0[40]: Copied! <pre>df.iloc[2]\n</pre> df.iloc[2] Out[40]: <pre>age              22\nheight          NaN\nis_teacher    False\nName: Matt, dtype: object</pre> <p>But we can also specify the column we want to access</p> In\u00a0[41]: Copied! <pre>df.loc['Xiaomeng', 'age']\n</pre> df.loc['Xiaomeng', 'age'] Out[41]: <pre>32</pre> In\u00a0[42]: Copied! <pre>df.iloc[:2, 0]\n</pre> df.iloc[:2, 0] Out[42]: <pre>Xiaomeng    32\nSiyi        25\nName: age, dtype: int64</pre> <p>If we make a calculation using columns from the DataFrame, it will keep the same index:</p> <p>Which we can easily add as another column to the DataFrame:</p> In\u00a0[43]: Copied! <pre>2023 - df['age']\n</pre> 2023 - df['age'] Out[43]: <pre>Xiaomeng    1991\nSiyi        1998\nMatt        2001\nName: age, dtype: int64</pre> In\u00a0[44]: Copied! <pre>df['year'] = 2023 - df['age']\ndf\n</pre> df['year'] = 2023 - df['age'] df Out[44]: age height is_teacher year Xiaomeng 32 160.0 True 1991 Siyi 25 NaN False 1998 Matt 22 NaN False 2001 In\u00a0[45]: Copied! <pre># Modify values\ndf.loc['Siyi', 'height'] = 165\n</pre> # Modify values df.loc['Siyi', 'height'] = 165  In\u00a0[46]: Copied! <pre># Don't run it many times, it will keep adding values.\u00a0\ndf.loc['Xiaomeng', 'age'] += 1\ndf\n</pre> # Don't run it many times, it will keep adding values.\u00a0 df.loc['Xiaomeng', 'age'] += 1 df Out[46]: age height is_teacher year Xiaomeng 33 160.0 True 1991 Siyi 25 165.0 False 1998 Matt 22 NaN False 2001 In\u00a0[47]: Copied! <pre>df.loc['Kerry'] = [25, np.NaN, False, 1998]\n</pre> df.loc['Kerry'] = [25, np.NaN, False, 1998]  In\u00a0[48]: Copied! <pre>df\n</pre> df Out[48]: age height is_teacher year Xiaomeng 33 160.0 True 1991 Siyi 25 165.0 False 1998 Matt 22 NaN False 2001 Kerry 25 NaN False 1998 In\u00a0[49]: Copied! <pre>education = pd.Series(['PhD', 'masters', 'bachelor','PhD'],\n                     index=['Xiaomeng', 'Siyi', 'Matt', 'Lisa'],\n                     name='education')\neducation\n</pre> education = pd.Series(['PhD', 'masters', 'bachelor','PhD'],                      index=['Xiaomeng', 'Siyi', 'Matt', 'Lisa'],                      name='education') education Out[49]: <pre>Xiaomeng         PhD\nSiyi         masters\nMatt        bachelor\nLisa             PhD\nName: education, dtype: object</pre> In\u00a0[50]: Copied! <pre># returns a new DataFrame\ndf_join = df.join(education)\ndf_join\n</pre> # returns a new DataFrame df_join = df.join(education) df_join Out[50]: age height is_teacher year education Xiaomeng 33 160.0 True 1991 PhD Siyi 25 165.0 False 1998 masters Matt 22 NaN False 2001 bachelor Kerry 25 NaN False 1998 NaN In\u00a0[52]: Copied! <pre>df_join_right = df.join(education, how = 'right')\ndf_join_right\n</pre> df_join_right = df.join(education, how = 'right') df_join_right Out[52]: age height is_teacher year education Xiaomeng 33.0 160.0 True 1991.0 PhD Siyi 25.0 165.0 False 1998.0 masters Matt 22.0 NaN False 2001.0 bachelor Lisa NaN NaN NaN NaN PhD In\u00a0[53]: Copied! <pre>df_combined = pd.concat([df_join, df_join_right])\n</pre> df_combined = pd.concat([df_join, df_join_right]) In\u00a0[54]: Copied! <pre>df_combined\n</pre> df_combined Out[54]: age height is_teacher year education Xiaomeng 33.0 160.0 True 1991.0 PhD Siyi 25.0 165.0 False 1998.0 masters Matt 22.0 NaN False 2001.0 bachelor Kerry 25.0 NaN False 1998.0 NaN Xiaomeng 33.0 160.0 True 1991.0 PhD Siyi 25.0 165.0 False 1998.0 masters Matt 22.0 NaN False 2001.0 bachelor Lisa NaN NaN NaN NaN PhD In\u00a0[55]: Copied! <pre>df_combined.drop_duplicates()\n</pre> df_combined.drop_duplicates() Out[55]: age height is_teacher year education Xiaomeng 33.0 160.0 True 1991.0 PhD Siyi 25.0 165.0 False 1998.0 masters Matt 22.0 NaN False 2001.0 bachelor Kerry 25.0 NaN False 1998.0 NaN Lisa NaN NaN NaN NaN PhD In\u00a0[56]: Copied! <pre>### This is equivalent to:\ndf.join(education, how = 'outer')\n</pre> ### This is equivalent to: df.join(education, how = 'outer') Out[56]: age height is_teacher year education Kerry 25.0 NaN False 1998.0 NaN Lisa NaN NaN NaN NaN PhD Matt 22.0 NaN False 2001.0 bachelor Siyi 25.0 165.0 False 1998.0 masters Xiaomeng 33.0 160.0 True 1991.0 PhD <p>As you can see, pd.read_csv() has quite a few parameters. Don't be overwhelmed \u2013 most of these are optional arguments that allow you to specify exactly how your data file is structured and which part(s) you want to import. In particular, the sep parameter allows the user to specify the type of delimiter used in the file. The default is a comma, but you can actually pass other common delimiters (such as sep='\\t', which is a tab) to import other delimited files. The only required argument is a string specifying the filepath of your file.</p> In\u00a0[\u00a0]: Copied! <pre>pd.read_csv?\n</pre> pd.read_csv? In\u00a0[66]: Copied! <pre>df = pd.read_csv('../Assignments/Assignment_3/Millbrook_NY_daily_weather.csv')\n</pre> df = pd.read_csv('../Assignments/Assignment_3/Millbrook_NY_daily_weather.csv') In\u00a0[67]: Copied! <pre># Show the first five rows. \ndf.head()\n</pre> # Show the first five rows.  df.head() Out[67]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 0 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 1 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 3 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 4 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN <p>5 rows \u00d7 29 columns</p> In\u00a0[68]: Copied! <pre># Show the first five rows. \ndf.tail()\n</pre> # Show the first five rows.  df.tail() Out[68]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 2552 2022-12-27 64756 2.622 -73.74 41.79 -0.8 -8.0 -4.4 -3.8 0.0 ... NaN NaN 0.164 0.157 -0.4 -0.2 0.5 2.2 4.0 NaN 2553 2022-12-28 64756 2.622 -73.74 41.79 7.4 -6.1 0.7 1.3 0.0 ... NaN NaN 0.162 0.156 -0.4 -0.3 0.4 2.1 3.8 NaN 2554 2022-12-29 64756 2.622 -73.74 41.79 10.7 -1.8 4.4 5.0 0.0 ... NaN NaN 0.159 0.155 -0.3 -0.3 0.3 1.9 3.7 NaN 2555 2022-12-30 64756 2.622 -73.74 41.79 16.6 4.9 10.7 10.3 0.0 ... NaN NaN 0.159 0.154 -0.2 -0.2 0.3 1.8 3.6 NaN 2556 2022-12-31 64756 2.622 -73.74 41.79 13.2 2.7 7.9 10.2 5.0 ... NaN NaN 0.160 0.153 -0.1 -0.2 0.3 1.8 3.4 NaN <p>5 rows \u00d7 29 columns</p> In\u00a0[69]: Copied! <pre># Both df.head() and df.tail() can also accept an integer argument, e.g. df.head(n), where the first n rows will be printed.\n\n\ndf.head(10)\n</pre> # Both df.head() and df.tail() can also accept an integer argument, e.g. df.head(n), where the first n rows will be printed.   df.head(10) Out[69]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 0 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 1 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 3 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 4 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN 5 2016-01-06 64756 2.422 -73.74 41.79 5.0 -16.4 -5.7 -5.9 0.0 ... NaN 0.186 0.146 0.137 -0.1 0.4 1.7 3.6 6.2 NaN 6 2016-01-07 64756 2.422 -73.74 41.79 4.6 -11.7 -3.6 -4.8 0.0 ... NaN 0.183 0.144 NaN -0.2 0.2 1.4 3.2 5.8 NaN 7 2016-01-08 64756 2.422 -73.74 41.79 6.9 -11.8 -2.5 -2.0 0.0 ... NaN 0.180 0.144 0.137 -0.3 0.0 1.1 2.8 5.5 NaN 8 2016-01-09 64756 2.422 -73.74 41.79 6.6 -0.1 3.2 4.1 0.0 ... NaN 0.179 0.141 0.136 -0.1 0.1 1.0 2.6 5.2 NaN 9 2016-01-10 64756 2.422 -73.74 41.79 15.7 3.4 9.5 9.0 24.2 ... NaN 0.204 0.149 0.134 0.6 0.5 1.1 2.4 4.9 NaN <p>10 rows \u00d7 29 columns</p> In\u00a0[70]: Copied! <pre>df.describe()\n</pre> df.describe() Out[70]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 count 2557.0 2557.000000 2557.00 2.557000e+03 2545.000000 2545.000000 2545.000000 2545.000000 2547.000000 2545.000000 ... 2173.000000 2281.000000 2545.000000 2427.000000 2545.000000 2545.000000 2542.000000 2545.000000 2544.000000 0.0 mean 64756.0 2.549059 -73.74 4.179000e+01 15.973635 4.037642 10.003733 10.130059 3.216726 12.908444 ... 0.189869 0.192877 0.150320 0.156753 12.382318 12.353084 12.155901 12.077367 11.994340 NaN std 0.0 0.518602 0.00 7.106817e-15 10.648586 9.568906 9.865217 9.721821 8.131592 8.015033 ... 0.071355 0.073708 0.029615 0.022373 9.531614 9.468884 8.960360 8.190971 7.334731 NaN min 64756.0 -9.000000 -73.74 4.179000e+01 -12.300000 -26.000000 -18.400000 -19.200000 0.000000 0.030000 ... 0.029000 0.030000 0.070000 0.023000 -1.800000 -1.600000 -0.500000 0.500000 1.400000 NaN 25% 64756.0 2.422000 -73.74 4.179000e+01 6.900000 -3.100000 2.000000 2.100000 0.000000 6.070000 ... 0.141000 0.144000 0.133000 0.145000 2.700000 2.800000 3.125000 3.800000 4.700000 NaN 50% 64756.0 2.622000 -73.74 4.179000e+01 16.900000 3.900000 10.200000 10.500000 0.000000 11.820000 ... 0.216000 0.211000 0.157000 0.160000 12.300000 12.200000 12.000000 12.000000 11.900000 NaN 75% 64756.0 2.622000 -73.74 4.179000e+01 25.200000 11.900000 18.700000 18.800000 2.150000 19.450000 ... 0.244000 0.246000 0.170000 0.170000 21.800000 21.700000 21.075000 20.100000 19.100000 NaN max 64756.0 2.622000 -73.74 4.179000e+01 36.500000 23.400000 28.900000 28.400000 133.400000 31.250000 ... 0.359000 0.335000 0.223000 0.218000 28.600000 28.500000 27.100000 25.400000 23.500000 NaN <p>8 rows \u00d7 27 columns</p> In\u00a0[71]: Copied! <pre>#  Basic information about the DataFrame\ndf.info()\n</pre> #  Basic information about the DataFrame df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2557 entries, 0 to 2556\nData columns (total 29 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   LST_DATE                 2557 non-null   object \n 1   WBANNO                   2557 non-null   int64  \n 2   CRX_VN                   2557 non-null   float64\n 3   LONGITUDE                2557 non-null   float64\n 4   LATITUDE                 2557 non-null   float64\n 5   T_DAILY_MAX              2545 non-null   float64\n 6   T_DAILY_MIN              2545 non-null   float64\n 7   T_DAILY_MEAN             2545 non-null   float64\n 8   T_DAILY_AVG              2545 non-null   float64\n 9   P_DAILY_CALC             2547 non-null   float64\n 10  SOLARAD_DAILY            2545 non-null   float64\n 11  SUR_TEMP_DAILY_TYPE      2557 non-null   object \n 12  SUR_TEMP_DAILY_MAX       2545 non-null   float64\n 13  SUR_TEMP_DAILY_MIN       2545 non-null   float64\n 14  SUR_TEMP_DAILY_AVG       2545 non-null   float64\n 15  RH_DAILY_MAX             2545 non-null   float64\n 16  RH_DAILY_MIN             2545 non-null   float64\n 17  RH_DAILY_AVG             2545 non-null   float64\n 18  SOIL_MOISTURE_5_DAILY    2164 non-null   float64\n 19  SOIL_MOISTURE_10_DAILY   2173 non-null   float64\n 20  SOIL_MOISTURE_20_DAILY   2281 non-null   float64\n 21  SOIL_MOISTURE_50_DAILY   2545 non-null   float64\n 22  SOIL_MOISTURE_100_DAILY  2427 non-null   float64\n 23  SOIL_TEMP_5_DAILY        2545 non-null   float64\n 24  SOIL_TEMP_10_DAILY       2545 non-null   float64\n 25  SOIL_TEMP_20_DAILY       2542 non-null   float64\n 26  SOIL_TEMP_50_DAILY       2545 non-null   float64\n 27  SOIL_TEMP_100_DAILY      2544 non-null   float64\n 28  Unnamed: 28              0 non-null      float64\ndtypes: float64(26), int64(1), object(2)\nmemory usage: 579.4+ KB\n</pre> In\u00a0[75]: Copied! <pre>## Note that the SUR_TEMP_DAILY_TYPE doesn't have numerical values, we need to remove this column\n\n#del df['SUR_TEMP_DAILY_TYPE']\n\ndf = df.drop('SUR_TEMP_DAILY_TYPE', axis = 1)\n</pre> ## Note that the SUR_TEMP_DAILY_TYPE doesn't have numerical values, we need to remove this column  #del df['SUR_TEMP_DAILY_TYPE']  df = df.drop('SUR_TEMP_DAILY_TYPE', axis = 1) In\u00a0[76]: Copied! <pre>df.info()\n</pre> df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2557 entries, 0 to 2556\nData columns (total 28 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   LST_DATE                 2557 non-null   object \n 1   WBANNO                   2557 non-null   int64  \n 2   CRX_VN                   2557 non-null   float64\n 3   LONGITUDE                2557 non-null   float64\n 4   LATITUDE                 2557 non-null   float64\n 5   T_DAILY_MAX              2545 non-null   float64\n 6   T_DAILY_MIN              2545 non-null   float64\n 7   T_DAILY_MEAN             2545 non-null   float64\n 8   T_DAILY_AVG              2545 non-null   float64\n 9   P_DAILY_CALC             2547 non-null   float64\n 10  SOLARAD_DAILY            2545 non-null   float64\n 11  SUR_TEMP_DAILY_MAX       2545 non-null   float64\n 12  SUR_TEMP_DAILY_MIN       2545 non-null   float64\n 13  SUR_TEMP_DAILY_AVG       2545 non-null   float64\n 14  RH_DAILY_MAX             2545 non-null   float64\n 15  RH_DAILY_MIN             2545 non-null   float64\n 16  RH_DAILY_AVG             2545 non-null   float64\n 17  SOIL_MOISTURE_5_DAILY    2164 non-null   float64\n 18  SOIL_MOISTURE_10_DAILY   2173 non-null   float64\n 19  SOIL_MOISTURE_20_DAILY   2281 non-null   float64\n 20  SOIL_MOISTURE_50_DAILY   2545 non-null   float64\n 21  SOIL_MOISTURE_100_DAILY  2427 non-null   float64\n 22  SOIL_TEMP_5_DAILY        2545 non-null   float64\n 23  SOIL_TEMP_10_DAILY       2545 non-null   float64\n 24  SOIL_TEMP_20_DAILY       2542 non-null   float64\n 25  SOIL_TEMP_50_DAILY       2545 non-null   float64\n 26  SOIL_TEMP_100_DAILY      2544 non-null   float64\n 27  Unnamed: 28              0 non-null      float64\ndtypes: float64(26), int64(1), object(1)\nmemory usage: 559.5+ KB\n</pre> In\u00a0[77]: Copied! <pre># Return the column names\ndf.columns\n</pre> # Return the column names df.columns Out[77]: <pre>Index(['LST_DATE', 'WBANNO', 'CRX_VN', 'LONGITUDE', 'LATITUDE', 'T_DAILY_MAX',\n       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_MAX', 'SUR_TEMP_DAILY_MIN',\n       'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX', 'RH_DAILY_MIN', 'RH_DAILY_AVG',\n       'SOIL_MOISTURE_5_DAILY', 'SOIL_MOISTURE_10_DAILY',\n       'SOIL_MOISTURE_20_DAILY', 'SOIL_MOISTURE_50_DAILY',\n       'SOIL_MOISTURE_100_DAILY', 'SOIL_TEMP_5_DAILY', 'SOIL_TEMP_10_DAILY',\n       'SOIL_TEMP_20_DAILY', 'SOIL_TEMP_50_DAILY', 'SOIL_TEMP_100_DAILY',\n       'Unnamed: 28'],\n      dtype='object')</pre> In\u00a0[78]: Copied! <pre># Return the index range (number of rows)\n\ndf.index\n</pre> # Return the index range (number of rows)  df.index Out[78]: <pre>RangeIndex(start=0, stop=2557, step=1)</pre> In\u00a0[79]: Copied! <pre># Return the DataFrame shape\ndf.shape\n</pre> # Return the DataFrame shape df.shape Out[79]: <pre>(2557, 28)</pre> In\u00a0[80]: Copied! <pre># Return the DataFrame values as a Numpy array\n\ndf.values\n</pre> # Return the DataFrame values as a Numpy array  df.values Out[80]: <pre>array([['2016-01-01', 64756, 2.422, ..., 6.0, 7.6, nan],\n       ['2016-01-02', 64756, 2.422, ..., 5.7, 7.4, nan],\n       ['2016-01-03', 64756, 2.422, ..., 5.2, 7.2, nan],\n       ...,\n       ['2022-12-29', 64756, 2.622, ..., 1.9, 3.7, nan],\n       ['2022-12-30', 64756, 2.622, ..., 1.8, 3.6, nan],\n       ['2022-12-31', 64756, 2.622, ..., 1.8, 3.4, nan]], dtype=object)</pre> <p>df.iloc acts just like the index operator works with arrays.</p> In\u00a0[81]: Copied! <pre># Using iloc\n\ndf.iloc[5,5]\n</pre> # Using iloc  df.iloc[5,5] Out[81]: <pre>5.0</pre> <p>In addition to indexing a single value, df.iloc can be used to select multiple rows and columns via slicing: df.iloc[row_start:row_end:row_step, col_start:col_end:col_step].</p> In\u00a0[83]: Copied! <pre># Select first three rows, and last 12 columns\ndf.iloc[:3,12:]\n</pre> # Select first three rows, and last 12 columns df.iloc[:3,12:]  Out[83]: SUR_TEMP_DAILY_MIN SUR_TEMP_DAILY_AVG RH_DAILY_MAX RH_DAILY_MIN RH_DAILY_AVG SOIL_MOISTURE_5_DAILY SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 0 -4.2 0.7 90.5 51.7 69.1 0.256 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 1 -7.8 -1.4 77.7 44.8 57.4 0.248 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2 -5.7 -0.4 72.7 48.7 61.0 0.243 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN In\u00a0[84]: Copied! <pre># First 5 columns, every 40th row\ndf.iloc[::40,:5]\n</pre> # First 5 columns, every 40th row df.iloc[::40,:5] Out[84]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE 0 2016-01-01 64756 2.422 -73.74 41.79 40 2016-02-10 64756 2.422 -73.74 41.79 80 2016-03-21 64756 2.422 -73.74 41.79 120 2016-04-30 64756 2.422 -73.74 41.79 160 2016-06-09 64756 2.422 -73.74 41.79 ... ... ... ... ... ... 2360 2022-06-18 64756 2.622 -73.74 41.79 2400 2022-07-28 64756 2.622 -73.74 41.79 2440 2022-09-06 64756 2.622 -73.74 41.79 2480 2022-10-16 64756 2.622 -73.74 41.79 2520 2022-11-25 64756 2.622 -73.74 41.79 <p>64 rows \u00d7 5 columns</p> <p>When indexing a single row, df.loc (like df.iloc) transforms the row into a Series, with the column names as the index:</p> In\u00a0[85]: Copied! <pre># Index a row\ndf.iloc[1]\n</pre> # Index a row df.iloc[1] Out[85]: <pre>LST_DATE                   2016-01-02\nWBANNO                          64756\nCRX_VN                          2.422\nLONGITUDE                      -73.74\nLATITUDE                        41.79\nT_DAILY_MAX                       2.9\nT_DAILY_MIN                      -3.6\nT_DAILY_MEAN                     -0.4\nT_DAILY_AVG                      -0.3\nP_DAILY_CALC                      0.0\nSOLARAD_DAILY                    6.25\nSUR_TEMP_DAILY_MAX                8.7\nSUR_TEMP_DAILY_MIN               -7.8\nSUR_TEMP_DAILY_AVG               -1.4\nRH_DAILY_MAX                     77.7\nRH_DAILY_MIN                     44.8\nRH_DAILY_AVG                     57.4\nSOIL_MOISTURE_5_DAILY           0.248\nSOIL_MOISTURE_10_DAILY          0.227\nSOIL_MOISTURE_20_DAILY          0.199\nSOIL_MOISTURE_50_DAILY          0.152\nSOIL_MOISTURE_100_DAILY         0.144\nSOIL_TEMP_5_DAILY                 2.8\nSOIL_TEMP_10_DAILY                3.1\nSOIL_TEMP_20_DAILY                4.2\nSOIL_TEMP_50_DAILY                5.7\nSOIL_TEMP_100_DAILY               7.4\nUnnamed: 28                       NaN\nName: 1, dtype: object</pre> <p>In addition to df.iloc, rows of a DataFrame can be accessed using df.loc, which \"locates\" rows based on their labels. Unless you have set a custom index (which we will see later), the row \"labels\" are the same as the integer index.</p> In\u00a0[86]: Copied! <pre>df.loc[1]\n</pre> df.loc[1] Out[86]: <pre>LST_DATE                   2016-01-02\nWBANNO                          64756\nCRX_VN                          2.422\nLONGITUDE                      -73.74\nLATITUDE                        41.79\nT_DAILY_MAX                       2.9\nT_DAILY_MIN                      -3.6\nT_DAILY_MEAN                     -0.4\nT_DAILY_AVG                      -0.3\nP_DAILY_CALC                      0.0\nSOLARAD_DAILY                    6.25\nSUR_TEMP_DAILY_MAX                8.7\nSUR_TEMP_DAILY_MIN               -7.8\nSUR_TEMP_DAILY_AVG               -1.4\nRH_DAILY_MAX                     77.7\nRH_DAILY_MIN                     44.8\nRH_DAILY_AVG                     57.4\nSOIL_MOISTURE_5_DAILY           0.248\nSOIL_MOISTURE_10_DAILY          0.227\nSOIL_MOISTURE_20_DAILY          0.199\nSOIL_MOISTURE_50_DAILY          0.152\nSOIL_MOISTURE_100_DAILY         0.144\nSOIL_TEMP_5_DAILY                 2.8\nSOIL_TEMP_10_DAILY                3.1\nSOIL_TEMP_20_DAILY                4.2\nSOIL_TEMP_50_DAILY                5.7\nSOIL_TEMP_100_DAILY               7.4\nUnnamed: 28                       NaN\nName: 1, dtype: object</pre> In\u00a0[87]: Copied! <pre># Select multiple rows by position\ndf.iloc[100:200]\n</pre> # Select multiple rows by position df.iloc[100:200] Out[87]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 100 2016-04-10 64756 2.422 -73.74 41.79 9.7 -3.1 3.3 3.5 0.0 ... 0.222 0.197 0.151 0.133 6.6 6.3 6.1 6.2 6.6 NaN 101 2016-04-11 64756 2.422 -73.74 41.79 12.7 4.3 8.5 8.1 1.4 ... 0.218 0.194 0.150 0.134 7.3 7.1 6.8 6.5 6.6 NaN 102 2016-04-12 64756 2.422 -73.74 41.79 13.0 -0.9 6.0 8.4 12.5 ... 0.250 0.210 0.154 0.135 9.0 8.6 7.7 6.9 6.7 NaN 103 2016-04-13 64756 2.422 -73.74 41.79 12.6 -3.1 4.7 5.1 0.0 ... 0.236 0.207 0.156 0.137 8.5 8.2 7.8 7.3 6.9 NaN 104 2016-04-14 64756 2.422 -73.74 41.79 15.1 -0.2 7.5 7.3 0.0 ... 0.224 0.199 0.153 0.142 9.3 9.0 8.3 7.5 7.1 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 195 2016-07-14 64756 2.422 -73.74 41.79 30.4 21.6 26.0 24.5 4.2 ... 0.070 0.053 0.099 NaN 25.9 25.7 24.3 22.6 20.9 NaN 196 2016-07-15 64756 2.422 -73.74 41.79 31.5 18.9 25.2 25.3 0.0 ... 0.067 0.053 0.099 NaN 26.7 26.3 24.5 22.7 21.0 NaN 197 2016-07-16 64756 2.422 -73.74 41.79 30.4 16.3 23.4 23.1 0.0 ... 0.062 0.052 0.099 NaN 26.5 26.2 24.7 23.0 21.2 NaN 198 2016-07-17 64756 2.422 -73.74 41.79 30.7 16.7 23.7 23.5 0.0 ... 0.057 0.050 0.097 NaN 27.3 27.0 25.0 23.1 21.3 NaN 199 2016-07-18 64756 2.422 -73.74 41.79 33.4 15.5 24.4 22.8 4.4 ... 0.052 0.047 0.096 NaN 26.2 26.1 24.9 23.3 21.5 NaN <p>100 rows \u00d7 28 columns</p> <p>Slicing using df.loc is similar to df.iloc, with the exception that the stop value is inclusive:</p> In\u00a0[88]: Copied! <pre>df.loc[100:200]\n</pre> df.loc[100:200] Out[88]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 100 2016-04-10 64756 2.422 -73.74 41.79 9.7 -3.1 3.3 3.5 0.0 ... 0.222 0.197 0.151 0.133 6.6 6.3 6.1 6.2 6.6 NaN 101 2016-04-11 64756 2.422 -73.74 41.79 12.7 4.3 8.5 8.1 1.4 ... 0.218 0.194 0.150 0.134 7.3 7.1 6.8 6.5 6.6 NaN 102 2016-04-12 64756 2.422 -73.74 41.79 13.0 -0.9 6.0 8.4 12.5 ... 0.250 0.210 0.154 0.135 9.0 8.6 7.7 6.9 6.7 NaN 103 2016-04-13 64756 2.422 -73.74 41.79 12.6 -3.1 4.7 5.1 0.0 ... 0.236 0.207 0.156 0.137 8.5 8.2 7.8 7.3 6.9 NaN 104 2016-04-14 64756 2.422 -73.74 41.79 15.1 -0.2 7.5 7.3 0.0 ... 0.224 0.199 0.153 0.142 9.3 9.0 8.3 7.5 7.1 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 196 2016-07-15 64756 2.422 -73.74 41.79 31.5 18.9 25.2 25.3 0.0 ... 0.067 0.053 0.099 NaN 26.7 26.3 24.5 22.7 21.0 NaN 197 2016-07-16 64756 2.422 -73.74 41.79 30.4 16.3 23.4 23.1 0.0 ... 0.062 0.052 0.099 NaN 26.5 26.2 24.7 23.0 21.2 NaN 198 2016-07-17 64756 2.422 -73.74 41.79 30.7 16.7 23.7 23.5 0.0 ... 0.057 0.050 0.097 NaN 27.3 27.0 25.0 23.1 21.3 NaN 199 2016-07-18 64756 2.422 -73.74 41.79 33.4 15.5 24.4 22.8 4.4 ... 0.052 0.047 0.096 NaN 26.2 26.1 24.9 23.3 21.5 NaN 200 2016-07-19 64756 2.422 -73.74 41.79 27.1 12.0 19.6 20.3 0.0 ... 0.051 0.046 0.095 NaN 25.2 25.2 24.3 23.1 21.6 NaN <p>101 rows \u00d7 28 columns</p> <p>In addition to integer indexing with df.iloc, columns can be accessed in two ways: dot notation . or square brackets []. The former takes advantage of the fact that the columns are effectively \"attributes\" of the DataFrame and returns a Series:</p> In\u00a0[89]: Copied! <pre>df.T_DAILY_MEAN\n</pre> df.T_DAILY_MEAN Out[89]: <pre>0        1.5\n1       -0.4\n2        1.6\n3       -6.9\n4      -10.3\n        ... \n2552    -4.4\n2553     0.7\n2554     4.4\n2555    10.7\n2556     7.9\nName: T_DAILY_MEAN, Length: 2557, dtype: float64</pre> In\u00a0[90]: Copied! <pre># Indexing a DataFrame column. Returns a Series\n\ndf['T_DAILY_MEAN']\n</pre> # Indexing a DataFrame column. Returns a Series  df['T_DAILY_MEAN'] Out[90]: <pre>0        1.5\n1       -0.4\n2        1.6\n3       -6.9\n4      -10.3\n        ... \n2552    -4.4\n2553     0.7\n2554     4.4\n2555    10.7\n2556     7.9\nName: T_DAILY_MEAN, Length: 2557, dtype: float64</pre> <p>Using single brackets, the result is a Series. However, using double brackets, it is possible to return the column as a DataFrame:</p> In\u00a0[91]: Copied! <pre># Indexing a column as a DataFrame\n\ndf[['T_DAILY_MEAN']]\n</pre> # Indexing a column as a DataFrame  df[['T_DAILY_MEAN']] Out[91]: T_DAILY_MEAN 0 1.5 1 -0.4 2 1.6 3 -6.9 4 -10.3 ... ... 2552 -4.4 2553 0.7 2554 4.4 2555 10.7 2556 7.9 <p>2557 rows \u00d7 1 columns</p> In\u00a0[92]: Copied! <pre># Indexing multiple columns\n\ndf[['T_DAILY_MAX','T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG']]\n</pre> # Indexing multiple columns  df[['T_DAILY_MAX','T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG']] Out[92]: T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG 0 3.4 -0.5 1.5 1.3 1 2.9 -3.6 -0.4 -0.3 2 5.1 -1.8 1.6 1.1 3 0.5 -14.4 -6.9 -7.5 4 -5.2 -15.5 -10.3 -11.7 ... ... ... ... ... 2552 -0.8 -8.0 -4.4 -3.8 2553 7.4 -6.1 0.7 1.3 2554 10.7 -1.8 4.4 5.0 2555 16.6 4.9 10.7 10.3 2556 13.2 2.7 7.9 10.2 <p>2557 rows \u00d7 4 columns</p> <p>Like the data we are working with in this exercise, many environmental datasets include timed records. The standard datetime library is the primary way of manipulating dates and times in Python, but there are additional third-party packages that provide additional support.</p> <p>A few worth exploring are dateutil, an extension of the datetime library useful for parsing timestamps, and pytz, which provides a smooth way of tackling time zones.</p> <p>Though we will not review datetime objects in depth here, it is useful to understand the basics of how to deal with datetime objects in Python as you will no doubt encounter them in the future.</p> <p>For now, we will focus on a few pandas functions built on the datetime library to handle datetime objects.</p> <p>The pd.date_range() function allows you to build a DatetimeIndex with a fixed frequency. This can be done by specifying a start date and an end date as follows:</p> In\u00a0[93]: Copied! <pre>pd.date_range('4/1/2017','4/30/2017')\n</pre> pd.date_range('4/1/2017','4/30/2017') Out[93]: <pre>DatetimeIndex(['2017-04-01', '2017-04-02', '2017-04-03', '2017-04-04',\n               '2017-04-05', '2017-04-06', '2017-04-07', '2017-04-08',\n               '2017-04-09', '2017-04-10', '2017-04-11', '2017-04-12',\n               '2017-04-13', '2017-04-14', '2017-04-15', '2017-04-16',\n               '2017-04-17', '2017-04-18', '2017-04-19', '2017-04-20',\n               '2017-04-21', '2017-04-22', '2017-04-23', '2017-04-24',\n               '2017-04-25', '2017-04-26', '2017-04-27', '2017-04-28',\n               '2017-04-29', '2017-04-30'],\n              dtype='datetime64[ns]', freq='D')</pre> In\u00a0[94]: Copied! <pre># Specify start and end, monthly frequency\n\npd.date_range('4/1/2017','4/30/2018', freq = 'M')\n</pre> # Specify start and end, monthly frequency  pd.date_range('4/1/2017','4/30/2018', freq = 'M') Out[94]: <pre>DatetimeIndex(['2017-04-30', '2017-05-31', '2017-06-30', '2017-07-31',\n               '2017-08-31', '2017-09-30', '2017-10-31', '2017-11-30',\n               '2017-12-31', '2018-01-31', '2018-02-28', '2018-03-31',\n               '2018-04-30'],\n              dtype='datetime64[ns]', freq='M')</pre> In\u00a0[96]: Copied! <pre># Specify start and end, 5min frequency\n# datetime64 is 64-bit integer, which represents an offset from 1970-01-01T00:00:00\n\npd.date_range('4/1/2017','4/30/2018', freq = '5min')\n</pre> # Specify start and end, 5min frequency # datetime64 is 64-bit integer, which represents an offset from 1970-01-01T00:00:00  pd.date_range('4/1/2017','4/30/2018', freq = '5min') Out[96]: <pre>DatetimeIndex(['2017-04-01 00:00:00', '2017-04-01 00:05:00',\n               '2017-04-01 00:10:00', '2017-04-01 00:15:00',\n               '2017-04-01 00:20:00', '2017-04-01 00:25:00',\n               '2017-04-01 00:30:00', '2017-04-01 00:35:00',\n               '2017-04-01 00:40:00', '2017-04-01 00:45:00',\n               ...\n               '2018-04-29 23:15:00', '2018-04-29 23:20:00',\n               '2018-04-29 23:25:00', '2018-04-29 23:30:00',\n               '2018-04-29 23:35:00', '2018-04-29 23:40:00',\n               '2018-04-29 23:45:00', '2018-04-29 23:50:00',\n               '2018-04-29 23:55:00', '2018-04-30 00:00:00'],\n              dtype='datetime64[ns]', length=113473, freq='5T')</pre> In\u00a0[97]: Copied! <pre>df.columns\n</pre> df.columns Out[97]: <pre>Index(['LST_DATE', 'WBANNO', 'CRX_VN', 'LONGITUDE', 'LATITUDE', 'T_DAILY_MAX',\n       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_MAX', 'SUR_TEMP_DAILY_MIN',\n       'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX', 'RH_DAILY_MIN', 'RH_DAILY_AVG',\n       'SOIL_MOISTURE_5_DAILY', 'SOIL_MOISTURE_10_DAILY',\n       'SOIL_MOISTURE_20_DAILY', 'SOIL_MOISTURE_50_DAILY',\n       'SOIL_MOISTURE_100_DAILY', 'SOIL_TEMP_5_DAILY', 'SOIL_TEMP_10_DAILY',\n       'SOIL_TEMP_20_DAILY', 'SOIL_TEMP_50_DAILY', 'SOIL_TEMP_100_DAILY',\n       'Unnamed: 28'],\n      dtype='object')</pre> In\u00a0[98]: Copied! <pre>df['LST_DATE']\n</pre> df['LST_DATE'] Out[98]: <pre>0       2016-01-01\n1       2016-01-02\n2       2016-01-03\n3       2016-01-04\n4       2016-01-05\n           ...    \n2552    2022-12-27\n2553    2022-12-28\n2554    2022-12-29\n2555    2022-12-30\n2556    2022-12-31\nName: LST_DATE, Length: 2557, dtype: object</pre> <p>While the values certainly resemble datetime objects, they are stored in pandas as \"objects,\" which basically means that pandas doesn't recognize the data type \u2013 it doesn't know how to handle them. Using the pd.to_datetime() function, we can convert this column to datetime objects:</p> In\u00a0[99]: Copied! <pre>pd.to_datetime(df['LST_DATE'])\n</pre> pd.to_datetime(df['LST_DATE']) Out[99]: <pre>0      2016-01-01\n1      2016-01-02\n2      2016-01-03\n3      2016-01-04\n4      2016-01-05\n          ...    \n2552   2022-12-27\n2553   2022-12-28\n2554   2022-12-29\n2555   2022-12-30\n2556   2022-12-31\nName: LST_DATE, Length: 2557, dtype: datetime64[ns]</pre> In\u00a0[100]: Copied! <pre># Set the LST_DATE as datetime object, you can also do so by setting the parse_dates when read in the csv data. \ndf['LST_DATE'] = pd.to_datetime(df['LST_DATE'])\n</pre> # Set the LST_DATE as datetime object, you can also do so by setting the parse_dates when read in the csv data.  df['LST_DATE'] = pd.to_datetime(df['LST_DATE']) In\u00a0[101]: Copied! <pre># Set the Date column as index:\n\ndf = df.set_index('LST_DATE')\n</pre> # Set the Date column as index:  df = df.set_index('LST_DATE') In\u00a0[102]: Copied! <pre># Now it's more intuitive to interpret the data:\n\ndf['T_DAILY_MEAN']\n</pre> # Now it's more intuitive to interpret the data:  df['T_DAILY_MEAN'] Out[102]: <pre>LST_DATE\n2016-01-01     1.5\n2016-01-02    -0.4\n2016-01-03     1.6\n2016-01-04    -6.9\n2016-01-05   -10.3\n              ... \n2022-12-27    -4.4\n2022-12-28     0.7\n2022-12-29     4.4\n2022-12-30    10.7\n2022-12-31     7.9\nName: T_DAILY_MEAN, Length: 2557, dtype: float64</pre> In\u00a0[103]: Copied! <pre>df['T_DAILY_MEAN'].plot()\n</pre> df['T_DAILY_MEAN'].plot() Out[103]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[104]: Copied! <pre># Reset the index\ndf = df.reset_index()\n</pre> # Reset the index df = df.reset_index() In\u00a0[105]: Copied! <pre># X axis is not labeled with date\ndf['T_DAILY_MEAN'].plot()\n</pre> # X axis is not labeled with date df['T_DAILY_MEAN'].plot() Out[105]: <pre>&lt;Axes: &gt;</pre> In\u00a0[106]: Copied! <pre>df = df.set_index('LST_DATE')\n</pre> df = df.set_index('LST_DATE') <p>Now that we have a DatetimeIndex, we can access specific attributes of the datetime objects like the year, day, hour, etc. To do this, we add the desired time period using dot notation: df.index.attribute. For a full list of attributes, see the pd.DatetimeIndex documentation. For example:</p> In\u00a0[107]: Copied! <pre># Get the hour of each record\n\ndf.index.hour\n</pre> # Get the hour of each record  df.index.hour Out[107]: <pre>Index([0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       ...\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n      dtype='int32', name='LST_DATE', length=2557)</pre> In\u00a0[108]: Copied! <pre># Get the year of each record, and assign this to a new column\n\ndf['year'] = df.index.year\n</pre> # Get the year of each record, and assign this to a new column  df['year'] = df.index.year  In\u00a0[109]: Copied! <pre>df\n</pre> df Out[109]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 year LST_DATE 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 1.69 ... 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 2016 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 6.25 ... 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2016 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 5.69 ... 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 2016 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 9.17 ... 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 2016 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 9.34 ... 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN 2016 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 64756 2.622 -73.74 41.79 -0.8 -8.0 -4.4 -3.8 0.0 4.00 ... NaN 0.164 0.157 -0.4 -0.2 0.5 2.2 4.0 NaN 2022 2022-12-28 64756 2.622 -73.74 41.79 7.4 -6.1 0.7 1.3 0.0 7.73 ... NaN 0.162 0.156 -0.4 -0.3 0.4 2.1 3.8 NaN 2022 2022-12-29 64756 2.622 -73.74 41.79 10.7 -1.8 4.4 5.0 0.0 6.66 ... NaN 0.159 0.155 -0.3 -0.3 0.3 1.9 3.7 NaN 2022 2022-12-30 64756 2.622 -73.74 41.79 16.6 4.9 10.7 10.3 0.0 5.39 ... NaN 0.159 0.154 -0.2 -0.2 0.3 1.8 3.6 NaN 2022 2022-12-31 64756 2.622 -73.74 41.79 13.2 2.7 7.9 10.2 5.0 1.25 ... NaN 0.160 0.153 -0.1 -0.2 0.3 1.8 3.4 NaN 2022 <p>2557 rows \u00d7 28 columns</p> In\u00a0[110]: Copied! <pre># Get the unique year values\ndf.index.year.unique()\n</pre> # Get the unique year values df.index.year.unique() Out[110]: <pre>Index([2016, 2017, 2018, 2019, 2020, 2021, 2022], dtype='int32', name='LST_DATE')</pre> In\u00a0[113]: Copied! <pre>df['T_DAILY_MAX'].plot()\n</pre> df['T_DAILY_MAX'].plot() Out[113]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[114]: Copied! <pre>fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(14,14))\n\ndf['T_DAILY_MAX'].plot(ax=ax[0,0])\ndf['P_DAILY_CALC'].plot(ax=ax[0,1])\ndf[['SOIL_MOISTURE_5_DAILY','SOIL_MOISTURE_10_DAILY','SOIL_MOISTURE_20_DAILY']].boxplot(ax=ax[1,0])\nax[1, 0].set_xticklabels(ax[1, 0].get_xticklabels(), rotation=90);\ndf[['T_DAILY_MAX','T_DAILY_MIN']].plot(ax=ax[1,1])\n</pre> fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(14,14))  df['T_DAILY_MAX'].plot(ax=ax[0,0]) df['P_DAILY_CALC'].plot(ax=ax[0,1]) df[['SOIL_MOISTURE_5_DAILY','SOIL_MOISTURE_10_DAILY','SOIL_MOISTURE_20_DAILY']].boxplot(ax=ax[1,0]) ax[1, 0].set_xticklabels(ax[1, 0].get_xticklabels(), rotation=90); df[['T_DAILY_MAX','T_DAILY_MIN']].plot(ax=ax[1,1])    Out[114]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[116]: Copied! <pre># monthly reampler object\nrs_obj = df.resample('M')\nrs_obj\n</pre> # monthly reampler object rs_obj = df.resample('M') rs_obj Out[116]: <pre>&lt;pandas.core.resample.DatetimeIndexResampler object at 0x182eb5ac0&gt;</pre> In\u00a0[117]: Copied! <pre>rs_obj.mean()\n</pre> rs_obj.mean() Out[117]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 year LST_DATE 2016-01-31 64756.0 2.422 -73.74 41.79 3.503226 -7.193548 -1.858065 -1.761290 1.106452 6.740000 ... 0.198903 0.146742 0.138700 0.487097 0.674194 1.429032 2.632258 4.593548 NaN 2016.0 2016-02-29 64756.0 2.422 -73.74 41.79 5.848276 -6.382759 -0.262069 0.072414 4.920690 8.379310 ... 0.202136 0.150586 0.139520 1.158621 1.158621 1.344828 1.810345 2.827586 NaN 2016.0 2016-03-31 64756.0 2.422 -73.74 41.79 13.122581 -0.638710 6.251613 6.393548 0.890323 14.435484 ... 0.186258 0.144839 0.134581 6.529032 6.370968 5.987097 5.593548 5.267742 NaN 2016.0 2016-04-30 64756.0 2.422 -73.74 41.79 14.613333 0.840000 7.726667 8.300000 2.033333 17.865000 ... 0.179200 0.142267 0.133700 10.166667 9.926667 9.410000 8.773333 8.076667 NaN 2016.0 2016-05-31 64756.0 2.422 -73.74 41.79 21.058065 8.051613 14.577419 14.751613 2.812903 17.959355 ... 0.176935 0.141516 0.135032 16.796774 16.448387 15.416129 14.083871 12.445161 NaN 2016.0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-08-31 64756.0 2.622 -73.74 41.79 31.280645 16.145161 23.709677 23.235484 0.938710 19.360323 ... 0.072581 0.081000 0.113581 26.316129 26.054839 25.116129 23.645161 22.390323 NaN 2022.0 2022-09-30 64756.0 2.622 -73.74 41.79 23.266667 10.700000 16.970000 16.823333 4.263333 14.341333 ... 0.200300 0.121967 0.108500 20.686667 20.650000 20.593333 20.896667 20.746667 NaN 2022.0 2022-10-31 64756.0 2.622 -73.74 41.79 17.025806 3.867742 10.441935 10.351613 2.580645 10.186774 ... 0.260903 0.161194 0.133742 13.241935 13.177419 13.483871 14.574194 15.383871 NaN 2022.0 2022-11-30 64756.0 2.622 -73.74 41.79 12.380000 0.453333 6.420000 6.910000 2.956667 7.440000 ... 0.268000 0.164967 0.152633 8.196667 8.230000 8.882759 10.240000 11.470000 NaN 2022.0 2022-12-31 64756.0 2.622 -73.74 41.79 5.051613 -4.961290 0.038710 0.467742 3.751613 5.166452 ... 0.279500 0.172452 0.165065 2.070968 2.183871 2.709677 4.341935 5.867742 NaN 2022.0 <p>84 rows \u00d7 28 columns</p> <p>We can chain all of that together</p> In\u00a0[118]: Copied! <pre>df_mm = df.resample('M').mean()\ndf_mm[['T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_MAX']].plot()\n</pre> df_mm = df.resample('M').mean() df_mm[['T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_MAX']].plot() Out[118]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>In addition to manipulating individual columns, you can apply a function to an entire Series or DataFrame using the pandas function df.apply(). For example, consider our original DataFrame df, which consists of temperature values in \u00b0C:</p> In\u00a0[121]: Copied! <pre>def convert_CtoF(degC):\n\"\"\" Converts a temperature to from Celsius to Fahrenheit\n\n    Parameters\n    ----------\n        degC : float\n            Temperature value in \u00b0C\n\n    Returns\n    -------\n        degF : float\n            Temperature value in \u00b0F\n    \"\"\"\n\n    degF = (degC *(9/5)) + 32\n\n    return degF\n</pre> def convert_CtoF(degC):     \"\"\" Converts a temperature to from Celsius to Fahrenheit      Parameters     ----------         degC : float             Temperature value in \u00b0C      Returns     -------         degF : float             Temperature value in \u00b0F     \"\"\"      degF = (degC *(9/5)) + 32      return degF In\u00a0[122]: Copied! <pre>df['T_DAILY_MEAN'].apply(convert_CtoF)\n</pre> df['T_DAILY_MEAN'].apply(convert_CtoF) Out[122]: <pre>LST_DATE\n2016-01-01    34.70\n2016-01-02    31.28\n2016-01-03    34.88\n2016-01-04    19.58\n2016-01-05    13.46\n              ...  \n2022-12-27    24.08\n2022-12-28    33.26\n2022-12-29    39.92\n2022-12-30    51.26\n2022-12-31    46.22\nName: T_DAILY_MEAN, Length: 2557, dtype: float64</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_6_Pandas_Basics/#lecture-6-pandas-basics","title":"Lecture 6: Pandas Basics\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#pandas-data-structures-series","title":"Pandas Data Structures: Series\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#indexing","title":"Indexing\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#pandas-data-structures-dataframe","title":"Pandas Data Structures: DataFrame\u00b6","text":"<p>There is a lot more to Series, but they are limit to a single \"column\". A more useful Pandas data structure is the DataFrame. A DataFrame is basically a bunch of series that share the same index. It's a lot like a table in a spreadsheet.</p> <p>Below we create a DataFrame.</p>"},{"location":"Lecture_6_Pandas_Basics/#statistics","title":"Statistics\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#add-new-rows","title":"Add new rows\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#merge-with-new-series","title":"Merge with new series\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#using-concat-to-append-new-rows","title":"Using concat to append new rows\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#working-with-real-data-in-pandas","title":"Working with real data in Pandas\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#importing-read_csv","title":"Importing: read_csv()\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#examine-the-dataframe","title":"Examine the dataframe\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#indexing","title":"Indexing\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#indexing-columns","title":"Indexing columns\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#working-with-datetime-objects","title":"Working with Datetime objects\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#dealing-with-existing-timestamps","title":"Dealing with existing timestamps\u00b6","text":""},{"location":"Lecture_6_Pandas_Basics/#plotting-values","title":"Plotting Values\u00b6","text":"<p>We can now quickly make plots of the data</p>"},{"location":"Lecture_6_Pandas_Basics/#resampling","title":"Resampling\u00b6","text":"<p>Since pandas understands time, we can use it to do resampling.</p>"},{"location":"Lecture_6_Pandas_Basics/#applying-functions","title":"Applying Functions\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/","title":"Lecture 7: Advaned Pandas","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n</pre> import pandas as pd import numpy as np from matplotlib import pyplot as plt <p>Download wildfire data <code>Spatial_Database_Big_Wildfires_US_all.csv</code> from Canvas, and upload the data to your current working directory.</p> In\u00a0[27]: Copied! <pre>df = pd.read_csv('Spatial_Database_Big_Wildfires_US_all.csv', parse_dates=['DISCOVERY_DATE'])\n</pre> df = pd.read_csv('Spatial_Database_Big_Wildfires_US_all.csv', parse_dates=['DISCOVERY_DATE'])  In\u00a0[28]: Copied! <pre>df.head()\n</pre> df.head() Out[28]: FOD_ID FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME 0 17 FS-1418878 FED FS-FIRESTAT USCAENF Eldorado National Forest NaN POWER POWER NaN ... 295.0 16823.0 G 38.523333 -120.211667 USFS CA 5 6005.0 Amador County 1 18 FS-1418881 FED FS-FIRESTAT USCAENF Eldorado National Forest BHA3 FREDS FREDS NaN ... 291.0 7700.0 G 38.780000 -120.260000 USFS CA 17 6017.0 El Dorado County 2 40 FS-1418920 FED FS-FIRESTAT USNCNCF National Forests in North Carolina BKC8 AUSTIN CREEK NaN NaN ... 44.0 125.0 D 36.001667 -81.590000 MISSING/NOT SPECIFIED NC 27 37027.0 Caldwell County 3 119 FS-1419153 FED FS-FIRESTAT USNENBF Nebraska National Forest BEW8 THOMPSON BUTTE NaN NaN ... 198.0 119.0 D 43.899167 -102.954722 USFS SD 103 46103.0 Pennington County 4 120 FS-1419156 FED FS-FIRESTAT USNENBF Nebraska National Forest BEW8 CHARLES DRAW NaN NaN ... 197.0 119.0 D 43.892778 -102.948056 USFS SD 103 46103.0 Pennington County <p>5 rows \u00d7 28 columns</p> In\u00a0[29]: Copied! <pre>df.columns\n</pre> df.columns Out[29]: <pre>Index(['FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n       'NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME', 'FIRE_CODE',\n       'FIRE_NAME', 'MTBS_FIRE_NAME', 'COMPLEX_NAME', 'FIRE_YEAR',\n       'DISCOVERY_DATE', 'DISCOVERY_DOY', 'DISCOVERY_TIME',\n       'NWCG_CAUSE_CLASSIFICATION', 'NWCG_GENERAL_CAUSE',\n       'NWCG_CAUSE_AGE_CATEGORY', 'CONT_DATE', 'CONT_DOY', 'FIRE_SIZE',\n       'FIRE_SIZE_CLASS', 'LATITUDE', 'LONGITUDE', 'OWNER_DESCR', 'STATE',\n       'COUNTY', 'FIPS_CODE', 'FIPS_NAME'],\n      dtype='object')</pre> In\u00a0[30]: Copied! <pre>df = df.set_index('FOD_ID')\n</pre> df = df.set_index('FOD_ID') In\u00a0[31]: Copied! <pre>df[['DISCOVERY_DATE','DISCOVERY_DOY','DISCOVERY_TIME' ]]\n</pre> df[['DISCOVERY_DATE','DISCOVERY_DOY','DISCOVERY_TIME' ]] Out[31]: DISCOVERY_DATE DISCOVERY_DOY DISCOVERY_TIME FOD_ID 17 2004-10-06 280 1415.0 18 2004-10-13 287 1618.0 40 2005-02-12 43 1520.0 119 2005-07-16 197 1715.0 120 2005-07-16 197 1730.0 ... ... ... ... 400732975 2019-08-09 221 2134.0 400732976 2020-03-01 61 1330.0 400732977 2020-05-13 134 1300.0 400732982 2020-08-17 230 755.0 400732984 2020-11-20 325 1110.0 <p>60713 rows \u00d7 3 columns</p> In\u00a0[32]: Copied! <pre>df\n</pre> df Out[32]: FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 17 FS-1418878 FED FS-FIRESTAT USCAENF Eldorado National Forest NaN POWER POWER NaN 2004 ... 295.0 16823.0 G 38.523333 -120.211667 USFS CA 5 6005.0 Amador County 18 FS-1418881 FED FS-FIRESTAT USCAENF Eldorado National Forest BHA3 FREDS FREDS NaN 2004 ... 291.0 7700.0 G 38.780000 -120.260000 USFS CA 17 6017.0 El Dorado County 40 FS-1418920 FED FS-FIRESTAT USNCNCF National Forests in North Carolina BKC8 AUSTIN CREEK NaN NaN 2005 ... 44.0 125.0 D 36.001667 -81.590000 MISSING/NOT SPECIFIED NC 27 37027.0 Caldwell County 119 FS-1419153 FED FS-FIRESTAT USNENBF Nebraska National Forest BEW8 THOMPSON BUTTE NaN NaN 2005 ... 198.0 119.0 D 43.899167 -102.954722 USFS SD 103 46103.0 Pennington County 120 FS-1419156 FED FS-FIRESTAT USNENBF Nebraska National Forest BEW8 CHARLES DRAW NaN NaN 2005 ... 197.0 119.0 D 43.892778 -102.948056 USFS SD 103 46103.0 Pennington County ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 400732975 ICS209_2019_10805427 INTERAGCY IA-ICS209 USORMAF Malheur National Forest MMY5 204 COW 204 COW NaN 2019 ... NaN 9668.0 G 44.285050 -118.459800 USFS OR Baker 41001.0 Baker County 400732976 ICS209_2020_11699713 INTERAGCY IA-ICS209 USOKCNA Cherokee Nation Tribe NaN CAMERA NaN NaN 2020 ... NaN 401.0 E 36.303830 -94.903820 UNDEFINED FEDERAL OK Delaware 40041.0 Delaware County 400732977 ICS209_2020_11703752 INTERAGCY IA-ICS209 USFLFLS Florida Forest Service NaN 22ND AVE SE NaN NaN 2020 ... NaN 1000.0 F 26.191111 -81.523889 Private FL Collier 12021.0 Collier County 400732982 ICS209_2020_11831809 INTERAGCY IA-ICS209 USWAMCR Mid Columbia National Wildlife Refuge Complex NaN TAYLOR POND TAYLOR POND NaN 2020 ... 233.0 24892.0 G 46.670340 -120.114500 UNDEFINED FEDERAL WA Yakima 53077.0 Yakima County 400732984 ICS209_2020_11977822 INTERAGCY IA-ICS209 USVAVAF George Washington &amp; Jefferson National Forests NaN MIDDLE MOUNTAIN NaN NaN 2020 ... 327.0 105.0 D 38.578900 -79.148450 UNDEFINED FEDERAL VA Rockingham 51165.0 Rockingham County <p>60713 rows \u00d7 27 columns</p> In\u00a0[33]: Copied! <pre>df.groupby('STATE').FPA_ID.count().nlargest(10).plot(kind='bar', figsize=(12,6))\n</pre> df.groupby('STATE').FPA_ID.count().nlargest(10).plot(kind='bar', figsize=(12,6)) Out[33]: <pre>&lt;Axes: xlabel='STATE'&gt;</pre> In\u00a0[34]: Copied! <pre>df.groupby(df.STATE)\n</pre> df.groupby(df.STATE) Out[34]: <pre>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x17f832520&gt;</pre> <p>There is a shortcut for doing this with dataframes: you just pass the column name:</p> In\u00a0[35]: Copied! <pre>df.groupby('STATE')\n</pre> df.groupby('STATE') Out[35]: <pre>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x17f7c5340&gt;</pre> In\u00a0[36]: Copied! <pre>gb = df.groupby('STATE')\ngb\n</pre> gb = df.groupby('STATE') gb Out[36]: <pre>&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x17f832490&gt;</pre> <p>The length tells us how many groups were found:</p> In\u00a0[37]: Copied! <pre>len(gb)\n</pre> len(gb) Out[37]: <pre>50</pre> <p>All of the groups are available as a dictionary via the <code>.groups</code> attribute:</p> In\u00a0[38]: Copied! <pre>groups = gb.groups\nlen(groups)\n</pre> groups = gb.groups len(groups) Out[38]: <pre>50</pre> In\u00a0[39]: Copied! <pre>groups['NJ']\n</pre> groups['NJ'] Out[39]: <pre>Index([   247140,    384407,    578890,    579164,    579296,    580135,\n          580956,    581165,    582330,    582680,\n       ...\n       400271442, 400389794, 400482043, 400528139, 400531379, 400587134,\n       400594776, 400602511, 400613352, 400632920],\n      dtype='int64', name='FOD_ID', length=111)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[40]: Copied! <pre>list(groups.keys())\n</pre> list(groups.keys()) Out[40]: <pre>['AK',\n 'AL',\n 'AR',\n 'AZ',\n 'CA',\n 'CO',\n 'CT',\n 'DE',\n 'FL',\n 'GA',\n 'HI',\n 'IA',\n 'ID',\n 'IL',\n 'IN',\n 'KS',\n 'KY',\n 'LA',\n 'MA',\n 'MD',\n 'ME',\n 'MI',\n 'MN',\n 'MO',\n 'MS',\n 'MT',\n 'NC',\n 'ND',\n 'NE',\n 'NH',\n 'NJ',\n 'NM',\n 'NV',\n 'NY',\n 'OH',\n 'OK',\n 'OR',\n 'PA',\n 'PR',\n 'SC',\n 'SD',\n 'TN',\n 'TX',\n 'UT',\n 'VA',\n 'VT',\n 'WA',\n 'WI',\n 'WV',\n 'WY']</pre> In\u00a0[41]: Copied! <pre>for key, group in gb:\n    display(group.head())\n    print(f'The key is \"{key}\"')\n    break\n</pre> for key, group in gb:     display(group.head())     print(f'The key is \"{key}\"')     break FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 6689 FS-1431539 FED FS-FIRESTAT USAKTNF Tongass National Forest BRD1 MUSKEG NaN NaN 2005 ... 126.0 305.0 E 59.087222 -135.441389 STATE OR PRIVATE AK 220 2220.0 Sitka City and Borough 109456 FS-334441 FED FS-FIRESTAT USAKTNF Tongass National Forest NaN MILL NaN NaN 1998 ... 189.0 118.0 D 55.681667 -132.615000 STATE OR PRIVATE AK NaN NaN NaN 147361 FS-374211 FED FS-FIRESTAT USAKCGF Chugach National Forest NaN KENAI LAKE KENAI LAKE NaN 2001 ... 188.0 3260.0 F 60.410278 -149.473611 USFS AK NaN NaN NaN 174677 W-374459 FED DOI-WFMI USAKAKA Alaska Regional Office B391 B391 532391 NaN 1995 ... 226.0 2850.0 F 66.832700 -160.736100 TRIBAL AK NaN NaN NaN 213301 W-36457 FED DOI-WFMI USAKAKD Alaska Fire Service A029 203029 NaN NaN 1992 ... 126.0 170.0 D 57.065900 -154.085700 BIA AK NaN NaN NaN <p>5 rows \u00d7 27 columns</p> <pre>The key is \"AK\"\n</pre> <p>And you can get a specific group by key.</p> In\u00a0[42]: Copied! <pre>gb.get_group('NJ')\n</pre> gb.get_group('NJ') Out[42]: FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 247140 W-234848 FED DOI-WFMI USPADWP Delaware Water Gap National Recreation Area NaN WORTHINGTO WORTHINGTO NaN 1999 ... 102.0 623.0 E 40.995895 -75.120000 NPS NJ NaN NaN NaN 384407 FWS-2007NJERRDFR2 FED FWS-FMIS USNJERR Edwin B. Forsythe National Wildlife Refuge DFR2 NJ NJFFS WF ASSIST WARREN GROVE WARREN GROVE NaN 2007 ... 141.0 17050.0 G 39.707500 -74.309722 STATE NJ NaN NaN NaN 578890 SFO-2006NJDEPA032704 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN NaN NaN 2006 ... NaN 104.0 D 40.304400 -74.201100 PRIVATE NJ Middlesex 34023.0 Middlesex County 579164 SFO-2006NJDEPB012703 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN RARITAN CENTER NaN NaN 2006 ... NaN 450.0 E 40.296100 -74.214000 PRIVATE NJ Middlesex 34023.0 Middlesex County 579296 SFO-2006NJDEPB032108 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN SUNRISE LAKE NaN NaN 2006 ... NaN 136.0 D 39.482800 -74.510900 STATE NJ Burlington 34005.0 Burlington County ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 400587134 SFO-2020NJDEPA03-200223155509 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN NaN NaN 2020 ... NaN 103.0 D 40.970480 -75.117710 MISSING/NOT SPECIFIED NJ Warren 34041.0 Warren County 400594776 SFO-2020NJDEPC03-200409234633 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN SPLIT DITCH NaN 2020 ... NaN 1518.0 F 39.312640 -75.090240 MISSING/NOT SPECIFIED NJ Cumberland 34011.0 Cumberland County 400602511 SFO-2020NJDEPC06-200519235337 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN BIG TIMBER NaN 2020 ... NaN 2107.0 F 39.651250 -74.892050 MISSING/NOT SPECIFIED NJ Camden 34007.0 Camden County 400613352 SFO-2020NJDEPB09-200709201959 NONFED ST-NASF USNJNJS New Jersey Forest Fire Service NaN NaN NaN NaN 2020 ... NaN 204.0 D 40.111570 -74.412330 MISSING/NOT SPECIFIED NJ Ocean 34029.0 Ocean County 400632920 ICS209_2019_10720324 INTERAGCY IA-ICS209 USNJNJS New Jersey Forest Fire Service NaN SPRING HILL FIRE SPRING HILL FIRE NaN 2019 ... NaN 11638.0 G 39.770000 -74.450000 MISSING/NOT SPECIFIED NJ Burlington 34005.0 Burlington County <p>111 rows \u00d7 27 columns</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>By default, the operation is applied to every column. That's usually not what we want. We can use both <code>.</code> or <code>[]</code> syntax to select a specific column to operate on. Then we get back a series.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[43]: Copied! <pre># Find out the biggest fire size in each state. \ngb.FIRE_SIZE.aggregate(np.max)\n</pre> # Find out the biggest fire size in each state.  gb.FIRE_SIZE.aggregate(np.max) Out[43]: <pre>STATE\nAK    606945.0\nAL      4394.0\nAR      8294.0\nAZ    538049.0\nCA    589368.0\nCO    208913.0\nCT      1300.0\nDE      2000.0\nFL    158000.0\nGA    309200.0\nHI     25000.0\nIA      4000.0\nID    367785.0\nIL      1475.0\nIN      1549.0\nKS     55000.0\nKY     10000.0\nLA     12877.0\nMA       800.0\nMD      3208.0\nME      1092.0\nMI     21069.0\nMN     92682.0\nMO      4761.0\nMS      5717.0\nMT    270723.3\nNC     45294.0\nND     51627.0\nNE     74500.0\nNH       329.0\nNJ     19225.0\nNM    297845.0\nNV    416821.2\nNY      5050.0\nOH      2865.0\nOK    662700.0\nOR    558198.3\nPA      7949.2\nPR      2702.0\nSC     19130.0\nSD     83508.0\nTN     17140.0\nTX    479549.0\nUT    357185.0\nVA     16021.0\nVT       270.0\nWA    255575.0\nWI      7499.4\nWV      5832.0\nWY    176878.0\nName: FIRE_SIZE, dtype: float64</pre> In\u00a0[44]: Copied! <pre>gb.max( numeric_only=True)\n</pre> gb.max( numeric_only=True) Out[44]: FIRE_YEAR DISCOVERY_DOY DISCOVERY_TIME CONT_DOY FIRE_SIZE LATITUDE LONGITUDE FIPS_CODE STATE AK 2020 363 2359.0 365.0 606945.0 70.138100 -132.333333 2290.0 AL 2020 365 2356.0 362.0 4394.0 34.999182 -85.102382 1133.0 AR 2020 365 2330.0 365.0 8294.0 36.499280 -90.531700 5149.0 AZ 2020 362 2359.0 362.0 538049.0 37.050000 -109.020278 4027.0 CA 2020 365 2356.0 366.0 589368.0 41.998889 -114.250800 6115.0 CO 2020 350 2330.0 365.0 208913.0 41.000000 -102.067461 8125.0 CT 2017 316 2201.0 144.0 1300.0 41.781171 -72.475777 9009.0 DE 2005 107 1400.0 103.0 2000.0 39.250000 -75.305800 NaN FL 2020 366 2359.0 365.0 158000.0 30.991900 -80.090000 12133.0 GA 2020 365 2326.0 365.0 309200.0 34.986715 -80.973820 13321.0 HI 2020 361 2337.0 366.0 25000.0 22.135260 -154.903534 15009.0 IA 2020 359 2328.0 359.0 4000.0 43.483347 -90.425753 19195.0 ID 2020 337 2358.0 349.0 367785.0 48.993611 -111.050000 16087.0 IL 2020 350 2248.0 350.0 1475.0 42.400000 -87.804337 17197.0 IN 2020 322 2112.0 322.0 1549.0 41.615600 -85.245469 18137.0 KS 2020 365 2345.0 365.0 55000.0 39.999700 -94.612500 20209.0 KY 2020 358 2359.0 360.0 10000.0 38.717621 -81.990090 21237.0 LA 2020 366 2350.0 364.0 12877.0 32.998195 -89.708889 22127.0 MA 2016 320 1700.0 320.0 800.0 42.719058 -70.524722 25027.0 MD 2020 365 2341.0 365.0 3208.0 39.705251 -75.330750 24047.0 ME 2020 330 2141.0 330.0 1092.0 47.333333 -67.012675 23031.0 MI 2020 309 2100.0 309.0 21069.0 47.420000 -82.835379 26165.0 MN 2020 354 2359.0 347.0 92682.0 48.998941 -90.031667 27171.0 MO 2020 365 2358.0 360.0 4761.0 40.593912 -89.508361 29229.0 MS 2020 365 2330.0 365.0 5717.0 35.034700 -88.166400 28163.0 MT 2020 354 2351.0 365.0 270723.3 48.999200 -104.005700 30111.0 NC 2020 361 2345.0 363.0 45294.0 36.548333 -75.563890 37199.0 ND 2020 353 2350.0 353.0 51627.0 48.995400 -96.867199 38105.0 NE 2020 365 2359.0 365.0 74500.0 43.042806 -95.590920 31175.0 NH 2016 319 1530.0 320.0 329.0 44.071389 -71.197222 33005.0 NJ 2020 353 2300.0 350.0 19225.0 41.187500 -74.063100 34041.0 NM 2020 365 2340.0 365.0 297845.0 37.030278 -102.970000 35061.0 NV 2020 364 2345.0 365.0 416821.2 41.996190 -114.046212 32510.0 NY 2020 324 2339.0 327.0 5050.0 44.876262 -72.708313 36113.0 OH 2020 320 2000.0 323.0 2865.0 41.680000 -81.195625 39163.0 OK 2020 365 2359.0 366.0 662700.0 36.999700 -93.649444 40295.0 OR 2020 352 2358.0 366.0 558198.3 46.066000 -116.516111 41071.0 PA 2020 333 2228.0 334.0 7949.2 41.774440 -74.311800 42129.0 PR 2018 365 2145.0 239.0 2702.0 18.425734 -65.325278 72147.0 SC 2020 365 2300.0 346.0 19130.0 35.150000 -78.766700 45091.0 SD 2020 365 2315.0 365.0 83508.0 45.989340 -96.476360 46137.0 TN 2020 364 2353.0 366.0 17140.0 36.614350 -81.703333 47185.0 TX 2020 365 2330.0 366.0 479549.0 36.615150 -93.541944 48507.0 UT 2020 340 2359.0 356.0 357185.0 41.994444 -109.050700 49057.0 VA 2020 362 2345.0 348.0 16021.0 39.166800 -75.648060 51810.0 VT 2015 142 1220.0 143.0 270.0 43.948333 -72.320833 50027.0 WA 2020 327 2355.0 365.0 255575.0 48.999900 -116.943056 53077.0 WI 2020 345 2153.0 335.0 7499.4 46.583333 -87.629000 55141.0 WV 2020 364 2359.0 365.0 5832.0 39.411365 -78.643929 54109.0 WY 2020 352 2337.0 352.0 176878.0 45.138658 -104.068800 56045.0 In\u00a0[45]: Copied! <pre>gb.FIRE_SIZE.aggregate(np.max).nlargest(10)\n</pre> gb.FIRE_SIZE.aggregate(np.max).nlargest(10) Out[45]: <pre>STATE\nOK    662700.0\nAK    606945.0\nCA    589368.0\nOR    558198.3\nAZ    538049.0\nTX    479549.0\nNV    416821.2\nID    367785.0\nUT    357185.0\nGA    309200.0\nName: FIRE_SIZE, dtype: float64</pre> <p>There are shortcuts for common aggregation functions:</p> In\u00a0[46]: Copied! <pre>gb.FIRE_SIZE.max().nlargest(10)\n</pre> gb.FIRE_SIZE.max().nlargest(10) Out[46]: <pre>STATE\nOK    662700.0\nAK    606945.0\nCA    589368.0\nOR    558198.3\nAZ    538049.0\nTX    479549.0\nNV    416821.2\nID    367785.0\nUT    357185.0\nGA    309200.0\nName: FIRE_SIZE, dtype: float64</pre> In\u00a0[47]: Copied! <pre>gb.FIRE_SIZE.mean().nlargest(10)\n</pre> gb.FIRE_SIZE.mean().nlargest(10) Out[47]: <pre>STATE\nAK    16440.375603\nNV     6138.109191\nOR     5595.310524\nWA     5071.806130\nID     4657.836385\nCA     4086.919845\nMT     3571.759463\nAZ     3084.376006\nUT     2874.009960\nCO     2809.130881\nName: FIRE_SIZE, dtype: float64</pre> <p>We can also apply multiple functions at once:</p> In\u00a0[48]: Copied! <pre>gb.FIRE_SIZE.aggregate([np.max, np.mean])\n</pre> gb.FIRE_SIZE.aggregate([np.max, np.mean]) Out[48]: max mean STATE AK 606945.0 16440.375603 AL 4394.0 270.382601 AR 8294.0 332.404468 AZ 538049.0 3084.376006 CA 589368.0 4086.919845 CO 208913.0 2809.130881 CT 1300.0 285.846154 DE 2000.0 705.000000 FL 158000.0 1273.882815 GA 309200.0 1447.480901 HI 25000.0 1499.055450 IA 4000.0 307.217379 ID 367785.0 4657.836385 IL 1475.0 279.925000 IN 1549.0 287.605128 KS 55000.0 1432.532363 KY 10000.0 365.679315 LA 12877.0 616.683622 MA 800.0 298.357143 MD 3208.0 498.654240 ME 1092.0 275.581250 MI 21069.0 1021.730381 MN 92682.0 849.779631 MO 4761.0 290.755380 MS 5717.0 294.757127 MT 270723.3 3571.759463 NC 45294.0 726.763361 ND 51627.0 691.042681 NE 74500.0 1785.755841 NH 329.0 233.250000 NJ 19225.0 1247.720721 NM 297845.0 2738.802666 NV 416821.2 6138.109191 NY 5050.0 510.412069 OH 2865.0 295.750000 OK 662700.0 1124.858015 OR 558198.3 5595.310524 PA 7949.2 580.139743 PR 2702.0 350.566406 SC 19130.0 342.640423 SD 83508.0 1091.602361 TN 17140.0 394.399034 TX 479549.0 1584.134866 UT 357185.0 2874.009960 VA 16021.0 616.936929 VT 270.0 175.666667 WA 255575.0 5071.806130 WI 7499.4 425.588632 WV 5832.0 372.253441 WY 176878.0 2761.473651 In\u00a0[49]: Copied! <pre>gb.FIRE_SIZE.aggregate([np.median, np.mean]).nlargest(10, 'mean').plot(kind='bar')\n</pre> gb.FIRE_SIZE.aggregate([np.median, np.mean]).nlargest(10, 'mean').plot(kind='bar') Out[49]: <pre>&lt;Axes: xlabel='STATE'&gt;</pre> In\u00a0[50]: Copied! <pre>df.columns\n</pre> df.columns Out[50]: <pre>Index(['FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM',\n       'NWCG_REPORTING_UNIT_ID', 'NWCG_REPORTING_UNIT_NAME', 'FIRE_CODE',\n       'FIRE_NAME', 'MTBS_FIRE_NAME', 'COMPLEX_NAME', 'FIRE_YEAR',\n       'DISCOVERY_DATE', 'DISCOVERY_DOY', 'DISCOVERY_TIME',\n       'NWCG_CAUSE_CLASSIFICATION', 'NWCG_GENERAL_CAUSE',\n       'NWCG_CAUSE_AGE_CATEGORY', 'CONT_DATE', 'CONT_DOY', 'FIRE_SIZE',\n       'FIRE_SIZE_CLASS', 'LATITUDE', 'LONGITUDE', 'OWNER_DESCR', 'STATE',\n       'COUNTY', 'FIPS_CODE', 'FIPS_NAME'],\n      dtype='object')</pre> In\u00a0[51]: Copied! <pre>df['NWCG_CAUSE_CLASSIFICATION'].unique()\n</pre> df['NWCG_CAUSE_CLASSIFICATION'].unique() Out[51]: <pre>array(['Human', 'Natural', 'Missing data/not specified/undetermined'],\n      dtype=object)</pre> In\u00a0[52]: Copied! <pre>df['NWCG_GENERAL_CAUSE'].unique()\n</pre> df['NWCG_GENERAL_CAUSE'].unique() Out[52]: <pre>array(['Equipment and vehicle use',\n       'Power generation/transmission/distribution',\n       'Debris and open burning', 'Natural',\n       'Missing data/not specified/undetermined',\n       'Recreation and ceremony', 'Smoking',\n       'Railroad operations and maintenance', 'Arson/incendiarism',\n       'Fireworks', 'Other causes', 'Misuse of fire by a minor',\n       'Firearms and explosives use'], dtype=object)</pre> In\u00a0[53]: Copied! <pre>df.groupby('NWCG_GENERAL_CAUSE').count()['FPA_ID'].nlargest(10).plot(kind = 'bar')\n</pre> df.groupby('NWCG_GENERAL_CAUSE').count()['FPA_ID'].nlargest(10).plot(kind = 'bar') Out[53]: <pre>&lt;Axes: xlabel='NWCG_GENERAL_CAUSE'&gt;</pre> In\u00a0[54]: Copied! <pre>df.groupby('NWCG_CAUSE_CLASSIFICATION').count()['FPA_ID'].nlargest().plot(kind = 'bar')\n</pre> df.groupby('NWCG_CAUSE_CLASSIFICATION').count()['FPA_ID'].nlargest().plot(kind = 'bar') Out[54]: <pre>&lt;Axes: xlabel='NWCG_CAUSE_CLASSIFICATION'&gt;</pre> In\u00a0[55]: Copied! <pre>df.groupby('FIRE_YEAR').FPA_ID.count().plot()\n</pre> df.groupby('FIRE_YEAR').FPA_ID.count().plot() Out[55]: <pre>&lt;Axes: xlabel='FIRE_YEAR'&gt;</pre> In\u00a0[59]: Copied! <pre>gb = df.groupby('STATE')\n\ndf_CA = gb.get_group('CA')\n</pre> gb = df.groupby('STATE')  df_CA = gb.get_group('CA') In\u00a0[60]: Copied! <pre>df_CA.groupby('FIRE_YEAR').FIRE_SIZE.sum().plot()\n</pre> df_CA.groupby('FIRE_YEAR').FIRE_SIZE.sum().plot() Out[60]: <pre>&lt;Axes: xlabel='FIRE_YEAR'&gt;</pre> In\u00a0[61]: Copied! <pre>gb = df.groupby(['STATE','FIRE_YEAR'])\nlen(gb)\n</pre> gb = df.groupby(['STATE','FIRE_YEAR']) len(gb) Out[61]: <pre>1231</pre> In\u00a0[62]: Copied! <pre>list(gb.groups.keys())[:100:10]\n</pre> list(gb.groups.keys())[:100:10] Out[62]: <pre>[('AK', 1992),\n ('AK', 2002),\n ('AK', 2012),\n ('AL', 1993),\n ('AL', 2003),\n ('AL', 2013),\n ('AR', 1994),\n ('AR', 2004),\n ('AR', 2014),\n ('AZ', 1995)]</pre> In\u00a0[63]: Copied! <pre>gb.FIRE_SIZE.sum()\n</pre> gb.FIRE_SIZE.sum() Out[63]: <pre>STATE  FIRE_YEAR\nAK     1992         141007.000\n       1993         684669.800\n       1994         259901.600\n       1995          42526.000\n       1996         596706.400\n                       ...    \nWY     2016         254804.700\n       2017         118803.020\n       2018         220718.000\n       2019          41022.200\n       2020         285791.255\nName: FIRE_SIZE, Length: 1231, dtype: float64</pre> In\u00a0[64]: Copied! <pre>### Select group with multiple index must use tuple!\ngb.get_group(('CA', 2003))\n</pre> ### Select group with multiple index must use tuple! gb.get_group(('CA', 2003)) Out[64]: FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 157551 FS-385211 FED FS-FIRESTAT USCAINF Inyo National Forest NaN DEXTER DEXTER WFU NaN 2003 ... 286.0 2515.0 F 37.831389 -118.795000 USFS CA NaN NaN NaN 158728 FS-386431 FED FS-FIRESTAT USCAPNF Plumas National Forest 4300 ROWLAND NaN NaN 2003 ... 163.0 114.0 D 39.951389 -120.068889 USFS CA NaN NaN NaN 159533 FS-387254 FED FS-FIRESTAT USCASTF Stanislaus National Forest 7648 MUDD MUD WFU MUD COMPLEX 2003 ... 300.0 4102.0 F 38.424722 -119.961111 USFS CA NaN NaN NaN 159534 FS-387255 FED FS-FIRESTAT USCASTF Stanislaus National Forest 5555 WHITT WHITT MUD COMPLEX 2003 ... 300.0 1014.0 F 38.378056 -119.999722 USFS CA NaN NaN NaN 160202 FS-388122 FED FS-FIRESTAT USCALPF Los Padres National Forest 2996 DEL VENTURI NaN NaN 2003 ... 225.0 861.0 E 36.071111 -121.390000 MISSING/NOT SPECIFIED CA NaN NaN NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 15000827 ICS209_2003_CA-KRN-37559 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN HILLSIDE UNNAMED NaN 2003 ... 198.0 835.0 E 35.168056 -118.468056 MISSING/NOT SPECIFIED CA KERN 6029.0 Kern County 15000828 ICS209_2003_CA-KRN-38766 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN MERCURY UNNAMED NaN 2003 ... 203.0 340.0 E 35.200556 -118.518611 MISSING/NOT SPECIFIED CA KERN 6029.0 Kern County 15000829 ICS209_2003_CA-LAC-03004054 INTERAGCY IA-ICS209 USCALAC Los Angeles County Fire Department NaN AIRPORT NaN NaN 2003 ... 8.0 245.0 D 33.407778 -118.402500 MISSING/NOT SPECIFIED CA LOS ANGELES 6037.0 Los Angeles County 201940026 ICS209_2003-CA-KRN-0333259 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN TEJON TEJON NaN 2003 ... 183.0 1155.0 F 34.871389 -118.882778 MISSING/NOT SPECIFIED CA Kern 6029.0 Kern County 400280041 ICS209_2003_CA-KRN-33853 INTERAGCY IA-ICS209 USCAKRN Kern County Fire Department NaN GRAPEVINE GRAPEVINE NaN 2003 ... NaN 1830.0 F 34.916944 -118.918333 MISSING/NOT SPECIFIED CA Kern 6029.0 Kern County <p>210 rows \u00d7 27 columns</p> In\u00a0[65]: Copied! <pre>gb.get_group(('CA', 2003)).describe()\n</pre> gb.get_group(('CA', 2003)).describe() Out[65]: FIRE_YEAR DISCOVERY_DATE DISCOVERY_DOY DISCOVERY_TIME CONT_DOY FIRE_SIZE LATITUDE LONGITUDE FIPS_CODE count 210.0 210 210.000000 210.000000 198.000000 210.000000 210.000000 210.000000 116.000000 mean 2003.0 2003-08-04 13:42:51.428571392 216.571429 1317.295238 223.934343 4823.423333 37.258685 -120.151254 6052.965517 min 2003.0 2003-01-06 00:00:00 6.000000 10.000000 7.000000 101.000000 32.566700 -124.091100 6001.000000 25% 2003.0 2003-07-05 00:00:00 186.000000 1129.000000 185.000000 200.000000 35.580192 -121.577778 6029.000000 50% 2003.0 2003-07-30 12:00:00 211.500000 1348.500000 216.000000 360.000000 37.188207 -120.191944 6045.000000 75% 2003.0 2003-09-03 00:00:00 246.000000 1532.250000 255.000000 1224.500000 39.145239 -118.755139 6073.000000 max 2003.0 2003-11-28 00:00:00 332.000000 2320.000000 365.000000 280059.000000 41.998333 -114.660556 6113.000000 std 0.0 NaN 50.829739 418.434515 59.655787 22885.276576 2.302258 1.918151 30.874763 In\u00a0[66]: Copied! <pre>### Find out the largest fire in CA, 2020\ndf.loc[gb['FIRE_SIZE'].idxmax().loc['CA',2020]]\n</pre> ### Find out the largest fire in CA, 2020 df.loc[gb['FIRE_SIZE'].idxmax().loc['CA',2020]] Out[66]: <pre>FPA_ID                           IRW-2020-CAMNF-000730\nSOURCE_SYSTEM_TYPE                           INTERAGCY\nSOURCE_SYSTEM                                 IA-IRWIN\nNWCG_REPORTING_UNIT_ID                         USCAMNF\nNWCG_REPORTING_UNIT_NAME     Mendocino National Forest\nFIRE_CODE                                         NFP4\nFIRE_NAME                                          DOE\nMTBS_FIRE_NAME                          AUGUST COMPLEX\nCOMPLEX_NAME                            AUGUST COMPLEX\nFIRE_YEAR                                         2020\nDISCOVERY_DATE                     2020-08-16 00:00:00\nDISCOVERY_DOY                                      229\nDISCOVERY_TIME                                     NaN\nNWCG_CAUSE_CLASSIFICATION                      Natural\nNWCG_GENERAL_CAUSE                             Natural\nNWCG_CAUSE_AGE_CATEGORY                            NaN\nCONT_DATE                                   11/11/2020\nCONT_DOY                                         316.0\nFIRE_SIZE                                     589368.0\nFIRE_SIZE_CLASS                                      G\nLATITUDE                                     39.765255\nLONGITUDE                                  -122.672914\nOWNER_DESCR                                       USFS\nSTATE                                               CA\nCOUNTY                                           Glenn\nFIPS_CODE                                       6021.0\nFIPS_NAME                                 Glenn County\nName: 400629554, dtype: object</pre> In\u00a0[57]: Copied! <pre>df.groupby(['FIRE_YEAR','NWCG_CAUSE_CLASSIFICATION']).FPA_ID.count().unstack('NWCG_CAUSE_CLASSIFICATION').plot(kind = 'bar', stacked = True)\n</pre> df.groupby(['FIRE_YEAR','NWCG_CAUSE_CLASSIFICATION']).FPA_ID.count().unstack('NWCG_CAUSE_CLASSIFICATION').plot(kind = 'bar', stacked = True) Out[57]: <pre>&lt;Axes: xlabel='FIRE_YEAR'&gt;</pre> In\u00a0[56]: Copied! <pre>df.groupby(['FIRE_YEAR','NWCG_CAUSE_CLASSIFICATION']).FPA_ID.count().plot(kind = 'bar')\n</pre> df.groupby(['FIRE_YEAR','NWCG_CAUSE_CLASSIFICATION']).FPA_ID.count().plot(kind = 'bar') Out[56]: <pre>&lt;Axes: xlabel='FIRE_YEAR,NWCG_CAUSE_CLASSIFICATION'&gt;</pre> In\u00a0[70]: Copied! <pre>df.groupby('NWCG_GENERAL_CAUSE').aggregate(total_size = ('FIRE_SIZE', 'sum'))\n</pre>  df.groupby('NWCG_GENERAL_CAUSE').aggregate(total_size = ('FIRE_SIZE', 'sum')) Out[70]: total_size NWCG_GENERAL_CAUSE Arson/incendiarism 8.403065e+06 Debris and open burning 5.211647e+06 Equipment and vehicle use 9.101695e+06 Firearms and explosives use 6.280094e+05 Fireworks 5.020915e+05 Missing data/not specified/undetermined 3.140607e+07 Misuse of fire by a minor 3.598069e+05 Natural 1.044037e+08 Other causes 4.257120e+05 Power generation/transmission/distribution 3.368717e+06 Railroad operations and maintenance 7.531811e+05 Recreation and ceremony 4.408299e+06 Smoking 7.751060e+05 In\u00a0[71]: Copied! <pre>df.groupby('NWCG_GENERAL_CAUSE').aggregate(total_incidents = ('FPA_ID', 'count'))\n</pre> df.groupby('NWCG_GENERAL_CAUSE').aggregate(total_incidents = ('FPA_ID', 'count')) Out[71]: total_incidents NWCG_GENERAL_CAUSE Arson/incendiarism 10056 Debris and open burning 7299 Equipment and vehicle use 5165 Firearms and explosives use 283 Fireworks 433 Missing data/not specified/undetermined 14204 Misuse of fire by a minor 345 Natural 18802 Other causes 117 Power generation/transmission/distribution 1322 Railroad operations and maintenance 858 Recreation and ceremony 1237 Smoking 592 In\u00a0[72]: Copied! <pre># Applying different functions to dataframe columns\ndf.groupby(['NWCG_GENERAL_CAUSE']).aggregate({'FIRE_SIZE':'sum', 'FPA_ID':'count'})\n</pre> # Applying different functions to dataframe columns df.groupby(['NWCG_GENERAL_CAUSE']).aggregate({'FIRE_SIZE':'sum', 'FPA_ID':'count'}) Out[72]: FIRE_SIZE FPA_ID NWCG_GENERAL_CAUSE Arson/incendiarism 8.403065e+06 10056 Debris and open burning 5.211647e+06 7299 Equipment and vehicle use 9.101695e+06 5165 Firearms and explosives use 6.280094e+05 283 Fireworks 5.020915e+05 433 Missing data/not specified/undetermined 3.140607e+07 14204 Misuse of fire by a minor 3.598069e+05 345 Natural 1.044037e+08 18802 Other causes 4.257120e+05 117 Power generation/transmission/distribution 3.368717e+06 1322 Railroad operations and maintenance 7.531811e+05 858 Recreation and ceremony 4.408299e+06 1237 Smoking 7.751060e+05 592 In\u00a0[73]: Copied! <pre># Take the 1st row from each group\ndf.groupby(['FIRE_YEAR']).nth(10)\n</pre> # Take the 1st row from each group df.groupby(['FIRE_YEAR']).nth(10) Out[73]: FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM NWCG_REPORTING_UNIT_ID NWCG_REPORTING_UNIT_NAME FIRE_CODE FIRE_NAME MTBS_FIRE_NAME COMPLEX_NAME FIRE_YEAR ... CONT_DOY FIRE_SIZE FIRE_SIZE_CLASS LATITUDE LONGITUDE OWNER_DESCR STATE COUNTY FIPS_CODE FIPS_NAME FOD_ID 745 FS-1420517 FED FS-FIRESTAT USMTCGF Custer Gallatin National Forest BK2U LAMPKIN NaN NaN 2005 ... 89.0 236.0 D 45.744722 -104.180000 USFS MT 11 30011.0 Carter County 7175 FS-1432509 FED FS-FIRESTAT USMSMNF National Forests in Mississippi B76Z OP-6 NaN NaN 2006 ... 13.0 200.0 D 31.091944 -89.079167 USFS MS 111 28111.0 Perry County 18178 FS-1447814 FED FS-FIRESTAT USGACHF Chattahoochee-Oconee National Forest C67F FORESTRY TRAIL NaN NaN 2007 ... 83.0 117.0 D 34.573333 -85.168889 STATE OR PRIVATE GA 55 13055.0 Chattooga County 26970 FS-1458681 FED FS-FIRESTAT USMOMTF Mark Twain National Forest D4LW BOWLING PIN NaN NaN 2008 ... 84.0 113.0 D 37.748611 -90.998889 STATE OR PRIVATE MO 221 29221.0 Washington County 34327 FS-1475293 FED FS-FIRESTAT USNMCIF Cibola National Forest ER0H ELENA ELENA NaN 2009 ... 70.0 2400.0 F 35.636944 -99.819167 STATE OR PRIVATE OK 129 40129.0 Roger Mills County 43014 FS-256761 FED FS-FIRESTAT USMTKNF Kootenai National Forest NaN THREE GOATS NaN NaN 1992 ... 222.0 209.0 D 48.401667 -116.080000 USFS ID NaN NaN NaN 54983 FS-279512 FED FS-FIRESTAT USNMCIF Cibola National Forest NaN NaN NaN NaN 1993 ... 175.0 106.0 D 34.133333 -107.951667 USFS NM NaN NaN NaN 61790 FS-286434 FED FS-FIRESTAT USMTBRF Bitterroot National Forest NaN LITTLE CLEARWATER BITTER-NEZ COMPLEX (MAGRUDER) BITTER-NEZ COMPLEX 1994 ... 297.0 785.0 E 45.710000 -114.838333 USFS ID NaN NaN NaN 77216 FS-301978 FED FS-FIRESTAT USCORGF Rio Grande National Forest NaN JOHN NaN NaN 1995 ... 211.0 201.0 D 37.066667 -105.816667 USFS CO NaN NaN NaN 85678 FS-310483 FED FS-FIRESTAT USLAKIF Kisatchie National Forest NaN 085 SIMMONS ROAD NaN NaN 1996 ... 75.0 124.0 D 31.650000 -92.533333 USFS LA NaN NaN NaN 97767 FS-322642 FED FS-FIRESTAT USSCFMF Francis Marion &amp; Sumter National Forests NaN BUCK HALL NaN NaN 1997 ... 91.0 151.0 D 33.033333 -79.550000 USFS SC NaN NaN NaN 105736 FS-330703 FED FS-FIRESTAT USFLFNF National Forests in Florida 5422 OAK OAK NaN 1998 ... 198.0 20100.0 G 30.340000 -82.506667 USFS FL NaN NaN NaN 115178 FS-340214 FED FS-FIRESTAT USCASTF Stanislaus National Forest 7687 PILOT PILOT NaN 1999 ... 242.0 4028.0 F 37.823056 -120.017500 STATE OR PRIVATE CA NaN NaN NaN 125447 FS-350535 FED FS-FIRESTAT USAZCOF Coconino National Forest 2300 GULF NaN NaN 2000 ... 203.0 1000.0 F 34.583889 -111.467500 USFS AZ 5 4005.0 Coconino County 137257 FS-363242 FED FS-FIRESTAT USFLFNF National Forests in Florida 5220 HARMS ROAD/TLH SUPPO NaN NaN 2001 ... 67.0 209.0 D 30.037222 -84.498056 STATE OR PRIVATE FL 129 12129.0 Wakulla County 147261 FS-374101 FED FS-FIRESTAT USKYDBF Daniel Boone National Forest 4563 CANE CREEK CANE CREEK NaN 2002 ... 102.0 990.0 E 36.778889 -84.315000 USFS KY 235 21235.0 Whitley County 157440 FS-385097 FED FS-FIRESTAT USMIHIF Hiawatha National Forest NaN LOVEGROVE NaN NaN 2003 ... 119.0 172.0 D 46.145833 -84.954167 STATE OR PRIVATE MI NaN NaN NaN 166506 FS-394950 FED FS-FIRESTAT USAZTNF Tonto National Forest A02B WEBBER WEBBER NaN 2004 ... 115.0 4311.0 F 34.426111 -111.367500 USFS AZ 7 4007.0 Gila County 1326854 SFO-2010-CACDFTUU000251 NONFED ST-CACDF USCATUU Tulare Unit NaN CURVE NaN NaN 2010 ... NaN 108.0 D 36.031944 -118.858056 MISSING/NOT SPECIFIED CA TULARE 6107.0 Tulare County 20020200 FS-1493543 FED FS-FIRESTAT USMOMTF Mark Twain National Forest F1CR BETHEL NaN NaN 2011 ... 71.0 433.0 E 36.788611 -92.763333 USFS MO NaN NaN NaN 201430181 FS-1509564 FED FS-FIRESTAT USMTBRF Bitterroot National Forest EKS4 BURNT STRIP BURNT STRIP NaN 2012 ... 296.0 3570.0 F 45.847778 -114.646667 USFS ID 049 16049.0 Idaho County 201760265 FS-1519193 FED FS-FIRESTAT USCATNF Tahoe National Forest HU11 AMERICAN AMERICAN NaN 2013 ... 281.0 27440.0 G 39.118889 -120.646111 USFS CA 061 6061.0 Placer County 300000132 FS-1527353 FED FS-FIRESTAT USIDNCF Nez Perce - Clearwater National Forests JDT1 ELEVATOR ELEVATOR MOUNTAIN SELWAY COMPLEX 2014 ... 297.0 4227.0 F 45.970833 -114.818056 USFS ID Idaho 16049.0 Idaho County 300200527 FS-6352433 FED FS-FIRESTAT USIDIPF Idaho Panhandle National Forest J114 GRASSY MOUNTAIN NaN GRIZZLY COMPLEX 2015 ... NaN 860.0 E 47.785000 -116.205278 USFS ID 079 16079.0 Shoshone County 400000402 FS-6738266 FED FS-FIRESTAT USWYMRF Medicine Bow-Routt National Forests, Thunder B... KL7H BROADWAY BROADWAY NaN 2016 ... NaN 2121.0 F 41.041389 -106.762778 USFS WY 007 56007.0 Carbon County 400006154 FS-6824721 FED FS-FIRESTAT USMTFNF Flathead National Forest EKS8 DOLLY VARDEN NaN NaN 2017 ... NaN 424.0 E 48.012222 -113.178333 USFS MT 029 30029.0 Flathead County 400300244 FS-6885846 FED FS-FIRESTAT USWYMRF Medicine Bow-Routt National Forests, Thunder B... L24P GLENDO FIRE NaN NaN 2018 ... 223.0 137.1 D 42.446667 -105.241667 PRIVATE WY 031 56031.0 Platte County 400500130 FS-6954521 FED FS-FIRESTAT USNMGNF Gila National Forest MDB3 BLACK BLACK NaN 2019 ... 227.0 1235.0 F 33.163611 -107.905278 USFS NM 017 35017.0 Grant County 400510712 W-736893 FED DOI-WFMI USOKANA Anadarko Agency MZY5 WEST CACHE NaN NaN 2020 ... 8.0 170.0 D 34.612610 -98.650800 PRIVATE OK NaN NaN NaN <p>29 rows \u00d7 27 columns</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[74]: Copied! <pre>df = pd.read_csv('../Assignments/Assignment_3/Millbrook_NY_daily_weather.csv')\n</pre> df = pd.read_csv('../Assignments/Assignment_3/Millbrook_NY_daily_weather.csv') In\u00a0[75]: Copied! <pre>df.head()\n</pre> df.head() Out[75]: LST_DATE WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 0 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 1 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 3 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 4 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN <p>5 rows \u00d7 29 columns</p> In\u00a0[76]: Copied! <pre>df.describe()\n</pre> df.describe() Out[76]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 count 2557.0 2557.000000 2557.00 2.557000e+03 2545.000000 2545.000000 2545.000000 2545.000000 2547.000000 2545.000000 ... 2173.000000 2281.000000 2545.000000 2427.000000 2545.000000 2545.000000 2542.000000 2545.000000 2544.000000 0.0 mean 64756.0 2.549059 -73.74 4.179000e+01 15.973635 4.037642 10.003733 10.130059 3.216726 12.908444 ... 0.189869 0.192877 0.150320 0.156753 12.382318 12.353084 12.155901 12.077367 11.994340 NaN std 0.0 0.518602 0.00 7.106817e-15 10.648586 9.568906 9.865217 9.721821 8.131592 8.015033 ... 0.071355 0.073708 0.029615 0.022373 9.531614 9.468884 8.960360 8.190971 7.334731 NaN min 64756.0 -9.000000 -73.74 4.179000e+01 -12.300000 -26.000000 -18.400000 -19.200000 0.000000 0.030000 ... 0.029000 0.030000 0.070000 0.023000 -1.800000 -1.600000 -0.500000 0.500000 1.400000 NaN 25% 64756.0 2.422000 -73.74 4.179000e+01 6.900000 -3.100000 2.000000 2.100000 0.000000 6.070000 ... 0.141000 0.144000 0.133000 0.145000 2.700000 2.800000 3.125000 3.800000 4.700000 NaN 50% 64756.0 2.622000 -73.74 4.179000e+01 16.900000 3.900000 10.200000 10.500000 0.000000 11.820000 ... 0.216000 0.211000 0.157000 0.160000 12.300000 12.200000 12.000000 12.000000 11.900000 NaN 75% 64756.0 2.622000 -73.74 4.179000e+01 25.200000 11.900000 18.700000 18.800000 2.150000 19.450000 ... 0.244000 0.246000 0.170000 0.170000 21.800000 21.700000 21.075000 20.100000 19.100000 NaN max 64756.0 2.622000 -73.74 4.179000e+01 36.500000 23.400000 28.900000 28.400000 133.400000 31.250000 ... 0.359000 0.335000 0.223000 0.218000 28.600000 28.500000 27.100000 25.400000 23.500000 NaN <p>8 rows \u00d7 27 columns</p> In\u00a0[77]: Copied! <pre>df.columns\n</pre> df.columns Out[77]: <pre>Index(['LST_DATE', 'WBANNO', 'CRX_VN', 'LONGITUDE', 'LATITUDE', 'T_DAILY_MAX',\n       'T_DAILY_MIN', 'T_DAILY_MEAN', 'T_DAILY_AVG', 'P_DAILY_CALC',\n       'SOLARAD_DAILY', 'SUR_TEMP_DAILY_TYPE', 'SUR_TEMP_DAILY_MAX',\n       'SUR_TEMP_DAILY_MIN', 'SUR_TEMP_DAILY_AVG', 'RH_DAILY_MAX',\n       'RH_DAILY_MIN', 'RH_DAILY_AVG', 'SOIL_MOISTURE_5_DAILY',\n       'SOIL_MOISTURE_10_DAILY', 'SOIL_MOISTURE_20_DAILY',\n       'SOIL_MOISTURE_50_DAILY', 'SOIL_MOISTURE_100_DAILY',\n       'SOIL_TEMP_5_DAILY', 'SOIL_TEMP_10_DAILY', 'SOIL_TEMP_20_DAILY',\n       'SOIL_TEMP_50_DAILY', 'SOIL_TEMP_100_DAILY', 'Unnamed: 28'],\n      dtype='object')</pre> In\u00a0[78]: Copied! <pre>df['LST_DATE'] = pd.to_datetime(df['LST_DATE'])\n</pre> df['LST_DATE'] = pd.to_datetime(df['LST_DATE']) In\u00a0[79]: Copied! <pre>df = df.drop(columns = ['SUR_TEMP_DAILY_TYPE'])\n</pre> df = df.drop(columns = ['SUR_TEMP_DAILY_TYPE']) In\u00a0[80]: Copied! <pre>df = df.set_index('LST_DATE')\n</pre> df = df.set_index('LST_DATE') In\u00a0[81]: Copied! <pre>df\n</pre> df Out[81]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 1.69 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 6.25 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 5.69 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 9.17 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 9.34 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 64756 2.622 -73.74 41.79 -0.8 -8.0 -4.4 -3.8 0.0 4.00 ... NaN NaN 0.164 0.157 -0.4 -0.2 0.5 2.2 4.0 NaN 2022-12-28 64756 2.622 -73.74 41.79 7.4 -6.1 0.7 1.3 0.0 7.73 ... NaN NaN 0.162 0.156 -0.4 -0.3 0.4 2.1 3.8 NaN 2022-12-29 64756 2.622 -73.74 41.79 10.7 -1.8 4.4 5.0 0.0 6.66 ... NaN NaN 0.159 0.155 -0.3 -0.3 0.3 1.9 3.7 NaN 2022-12-30 64756 2.622 -73.74 41.79 16.6 4.9 10.7 10.3 0.0 5.39 ... NaN NaN 0.159 0.154 -0.2 -0.2 0.3 1.8 3.6 NaN 2022-12-31 64756 2.622 -73.74 41.79 13.2 2.7 7.9 10.2 5.0 1.25 ... NaN NaN 0.160 0.153 -0.1 -0.2 0.3 1.8 3.4 NaN <p>2557 rows \u00d7 27 columns</p> <p>This timeseries has daily resolution, and the daily plots are somewhat noisy.</p> In\u00a0[82]: Copied! <pre>df.T_DAILY_MEAN.plot()\n</pre> df.T_DAILY_MEAN.plot() Out[82]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>A common way to analyze such data in climate science is to create a \"climatology,\" which contains the average values in each month or day of the year. We can do this easily with groupby. Recall that df.index is a pandas DateTimeIndex object.</p> In\u00a0[83]: Copied! <pre>monthly_climatology = df.groupby(df.index.month).mean(numeric_only=True)\nmonthly_climatology\n</pre> monthly_climatology = df.groupby(df.index.month).mean(numeric_only=True) monthly_climatology Out[83]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 1 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.442130 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2 64756.0 2.564424 -73.74 41.79 4.866162 -5.901010 -0.519192 -0.220202 3.449495 8.359444 ... 0.250415 0.219145 0.163520 0.165425 0.557071 0.518687 0.707071 1.256566 2.156061 NaN 3 64756.0 2.564857 -73.74 41.79 9.015668 -2.634101 3.184793 3.370046 2.426728 12.813917 ... 0.240800 0.224130 0.168618 0.166180 3.385714 3.270507 3.157604 3.182488 3.337788 NaN 4 64756.0 2.564857 -73.74 41.79 14.930476 1.948095 8.438095 8.733810 3.217143 14.977381 ... 0.229071 0.235376 0.165395 0.165433 9.685714 9.460476 8.950000 8.119524 7.199524 NaN 5 64756.0 2.564857 -73.74 41.79 20.996774 8.094009 14.548848 14.772811 3.182949 17.912673 ... 0.208286 0.221042 0.156848 0.161083 16.721198 16.471889 15.606019 14.184793 12.509217 NaN 6 64756.0 2.564857 -73.74 41.79 25.874286 12.033810 18.952857 19.285714 2.290000 21.610095 ... 0.138119 0.162114 0.136386 0.153190 22.399524 22.177619 21.112381 19.530476 17.661429 NaN 7 64756.0 2.564857 -73.74 41.79 29.040092 15.894470 22.465899 22.322120 3.880184 20.864101 ... 0.106465 0.113350 0.118535 0.139206 25.527189 25.406912 24.316204 22.814286 21.129630 NaN 8 64756.0 2.297069 -73.74 41.79 28.139048 15.543810 21.838571 21.615714 3.969048 18.131429 ... 0.134129 0.128214 0.122652 0.136627 24.912857 24.918095 24.244762 23.358571 22.286190 NaN 9 64756.0 2.564857 -73.74 41.79 23.720096 11.202871 17.460287 17.344019 3.948804 14.033301 ... 0.144627 0.151890 0.127550 0.141841 20.640191 20.736364 20.594258 20.666986 20.554067 NaN 10 64756.0 2.590664 -73.74 41.79 17.773488 5.738140 11.753023 11.740465 3.637963 9.193674 ... 0.190428 0.187633 0.141386 0.144750 14.663256 14.799070 15.074419 15.892558 16.645581 NaN 11 64756.0 2.593429 -73.74 41.79 10.377512 -1.277990 4.547368 4.720574 3.301905 6.567895 ... 0.234833 0.237167 0.166742 0.161895 7.128708 7.302392 7.955288 9.385167 10.990909 NaN 12 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.055760 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN <p>12 rows \u00d7 27 columns</p> <p>Each row in this new dataframe respresents the average values for the months (1=January, 2=February, etc.)</p> <p>We can apply more customized aggregations, as with any groupby operation. Below we keep the mean of the mean, max of the max, and min of the min for the temperature measurements.</p> In\u00a0[84]: Copied! <pre>monthly_T_climatology = df.groupby(df.index.month).aggregate({'T_DAILY_MEAN': 'mean',\n                                                              'T_DAILY_MAX': 'max',\n                                                              'T_DAILY_MIN': 'min'})\nmonthly_T_climatology\n</pre> monthly_T_climatology = df.groupby(df.index.month).aggregate({'T_DAILY_MEAN': 'mean',                                                               'T_DAILY_MAX': 'max',                                                               'T_DAILY_MIN': 'min'}) monthly_T_climatology Out[84]: T_DAILY_MEAN T_DAILY_MAX T_DAILY_MIN LST_DATE 1 -2.678241 19.8 -26.0 2 -0.519192 24.9 -24.7 3 3.184793 26.8 -17.4 4 8.438095 30.6 -11.3 5 14.548848 33.4 -3.1 6 18.952857 34.5 1.5 7 22.465899 36.2 8.2 8 21.838571 36.5 6.0 9 17.460287 32.7 -1.6 10 11.753023 29.9 -5.9 11 4.547368 24.4 -15.9 12 -0.217512 17.9 -21.8 In\u00a0[85]: Copied! <pre>monthly_T_climatology.plot(marker='o')\n</pre> monthly_T_climatology.plot(marker='o') Out[85]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>If we want to do it on a finer scale, we can group by day of year.</p> In\u00a0[86]: Copied! <pre>daily_T_climatology = df.groupby(df.index.dayofyear).aggregate({'T_DAILY_MEAN': 'mean',\n                                                            'T_DAILY_MAX': 'max',\n                                                            'T_DAILY_MIN': 'min'})\ndaily_T_climatology.plot(marker='.')\n</pre> daily_T_climatology = df.groupby(df.index.dayofyear).aggregate({'T_DAILY_MEAN': 'mean',                                                             'T_DAILY_MAX': 'max',                                                             'T_DAILY_MIN': 'min'}) daily_T_climatology.plot(marker='.') Out[86]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>A common mode of analysis in climate science is to remove the climatology from a signal to focus only on the \"anomaly\" values. This can be accomplished with transformation.</p> In\u00a0[87]: Copied! <pre>def standardize(x):\n    return (x - x.mean())/x.std()\n\nanomaly = df.groupby(df.index.month).transform(standardize)\n</pre> def standardize(x):     return (x - x.mean())/x.std()  anomaly = df.groupby(df.index.month).transform(standardize)  In\u00a0[88]: Copied! <pre>anomaly.plot(y='T_DAILY_MEAN')\n</pre> anomaly.plot(y='T_DAILY_MEAN') Out[88]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[89]: Copied! <pre>anomaly\n</pre> anomaly Out[89]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 2016-01-01 NaN -1.577491 NaN NaN 0.208563 1.082782 0.727292 0.654996 -0.398067 -1.242257 ... -0.992876 -0.857404 -0.607020 -1.209148 3.178622 3.416310 3.829867 3.857182 3.970999 NaN 2016-01-02 NaN -1.577491 NaN NaN 0.121662 0.606696 0.396565 0.374943 -0.398067 0.186367 ... -1.244252 -1.019588 -0.794239 -1.392266 2.009687 2.285460 2.996505 3.569060 3.783166 NaN 2016-01-03 NaN -1.577491 NaN NaN 0.504027 0.883133 0.744698 0.619989 -0.398067 0.010922 ... -1.411835 -1.116899 -0.856646 -1.575385 1.842696 2.024495 2.626121 3.088858 3.595334 NaN 2016-01-04 NaN -1.577491 NaN NaN -0.295464 -1.051924 -0.734867 -0.885294 -0.398067 1.101187 ... -1.537523 -1.181773 -1.043866 -1.697463 1.091238 1.415576 2.255738 2.800736 3.313586 NaN 2016-01-05 NaN -1.577491 NaN NaN -1.286137 -1.220858 -1.326693 -1.620432 -0.398067 1.154447 ... -1.830794 -1.279083 -1.043866 -1.758503 0.005798 0.371715 1.329779 2.224493 3.031838 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 NaN 0.407307 NaN NaN -0.963856 -0.556494 -0.802459 -0.738821 -0.464967 -0.249287 ... NaN NaN -0.529551 -1.086642 -1.375941 -1.382812 -1.435337 -1.298599 -1.289971 NaN 2022-12-28 NaN 0.407307 NaN NaN 0.530772 -0.213428 0.176035 0.238415 -0.464967 1.203695 ... NaN NaN -0.670202 -1.168774 -1.375941 -1.436291 -1.494016 -1.360778 -1.424874 NaN 2022-12-29 NaN 0.407307 NaN NaN 1.132268 0.562984 0.885923 0.947390 -0.464967 0.786888 ... NaN NaN -0.881180 -1.250906 -1.324114 -1.436291 -1.552695 -1.485136 -1.492325 NaN 2022-12-30 NaN 0.407307 NaN NaN 2.207671 1.772744 2.094651 1.962948 -0.464967 0.292173 ... NaN NaN -0.881180 -1.333038 -1.272286 -1.382812 -1.552695 -1.547315 -1.559777 NaN 2022-12-31 NaN 0.407307 NaN NaN 1.587947 1.375509 1.557438 1.943787 0.279886 -1.320521 ... NaN NaN -0.810854 -1.415170 -1.220458 -1.382812 -1.552695 -1.547315 -1.694679 NaN <p>2557 rows \u00d7 27 columns</p> In\u00a0[90]: Copied! <pre>anomaly\n</pre> anomaly Out[90]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 2016-01-01 NaN -1.577491 NaN NaN 0.208563 1.082782 0.727292 0.654996 -0.398067 -1.242257 ... -0.992876 -0.857404 -0.607020 -1.209148 3.178622 3.416310 3.829867 3.857182 3.970999 NaN 2016-01-02 NaN -1.577491 NaN NaN 0.121662 0.606696 0.396565 0.374943 -0.398067 0.186367 ... -1.244252 -1.019588 -0.794239 -1.392266 2.009687 2.285460 2.996505 3.569060 3.783166 NaN 2016-01-03 NaN -1.577491 NaN NaN 0.504027 0.883133 0.744698 0.619989 -0.398067 0.010922 ... -1.411835 -1.116899 -0.856646 -1.575385 1.842696 2.024495 2.626121 3.088858 3.595334 NaN 2016-01-04 NaN -1.577491 NaN NaN -0.295464 -1.051924 -0.734867 -0.885294 -0.398067 1.101187 ... -1.537523 -1.181773 -1.043866 -1.697463 1.091238 1.415576 2.255738 2.800736 3.313586 NaN 2016-01-05 NaN -1.577491 NaN NaN -1.286137 -1.220858 -1.326693 -1.620432 -0.398067 1.154447 ... -1.830794 -1.279083 -1.043866 -1.758503 0.005798 0.371715 1.329779 2.224493 3.031838 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 NaN 0.407307 NaN NaN -0.963856 -0.556494 -0.802459 -0.738821 -0.464967 -0.249287 ... NaN NaN -0.529551 -1.086642 -1.375941 -1.382812 -1.435337 -1.298599 -1.289971 NaN 2022-12-28 NaN 0.407307 NaN NaN 0.530772 -0.213428 0.176035 0.238415 -0.464967 1.203695 ... NaN NaN -0.670202 -1.168774 -1.375941 -1.436291 -1.494016 -1.360778 -1.424874 NaN 2022-12-29 NaN 0.407307 NaN NaN 1.132268 0.562984 0.885923 0.947390 -0.464967 0.786888 ... NaN NaN -0.881180 -1.250906 -1.324114 -1.436291 -1.552695 -1.485136 -1.492325 NaN 2022-12-30 NaN 0.407307 NaN NaN 2.207671 1.772744 2.094651 1.962948 -0.464967 0.292173 ... NaN NaN -0.881180 -1.333038 -1.272286 -1.382812 -1.552695 -1.547315 -1.559777 NaN 2022-12-31 NaN 0.407307 NaN NaN 1.587947 1.375509 1.557438 1.943787 0.279886 -1.320521 ... NaN NaN -0.810854 -1.415170 -1.220458 -1.382812 -1.552695 -1.547315 -1.694679 NaN <p>2557 rows \u00d7 27 columns</p> <p>Note that the transform is different from apply.</p> In\u00a0[91]: Copied! <pre>df.groupby(df.index.month).transform('mean')\n</pre> df.groupby(df.index.month).transform('mean') Out[91]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 2016-01-01 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.44213 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2016-01-02 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.44213 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2016-01-03 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.44213 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2016-01-04 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.44213 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2016-01-05 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.44213 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.05576 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN 2022-12-28 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.05576 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN 2022-12-29 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.05576 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN 2022-12-30 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.05576 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN 2022-12-31 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.05576 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN <p>2557 rows \u00d7 27 columns</p> In\u00a0[92]: Copied! <pre>df.groupby(df.index.month).apply('mean')\n</pre> df.groupby(df.index.month).apply('mean') Out[92]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 1 64756.0 2.564857 -73.74 41.79 2.200000 -7.550463 -2.678241 -2.442130 2.217130 5.655139 ... 0.256699 0.230433 0.164727 0.166809 0.393056 0.472685 0.963889 1.983796 3.371759 NaN 2 64756.0 2.564424 -73.74 41.79 4.866162 -5.901010 -0.519192 -0.220202 3.449495 8.359444 ... 0.250415 0.219145 0.163520 0.165425 0.557071 0.518687 0.707071 1.256566 2.156061 NaN 3 64756.0 2.564857 -73.74 41.79 9.015668 -2.634101 3.184793 3.370046 2.426728 12.813917 ... 0.240800 0.224130 0.168618 0.166180 3.385714 3.270507 3.157604 3.182488 3.337788 NaN 4 64756.0 2.564857 -73.74 41.79 14.930476 1.948095 8.438095 8.733810 3.217143 14.977381 ... 0.229071 0.235376 0.165395 0.165433 9.685714 9.460476 8.950000 8.119524 7.199524 NaN 5 64756.0 2.564857 -73.74 41.79 20.996774 8.094009 14.548848 14.772811 3.182949 17.912673 ... 0.208286 0.221042 0.156848 0.161083 16.721198 16.471889 15.606019 14.184793 12.509217 NaN 6 64756.0 2.564857 -73.74 41.79 25.874286 12.033810 18.952857 19.285714 2.290000 21.610095 ... 0.138119 0.162114 0.136386 0.153190 22.399524 22.177619 21.112381 19.530476 17.661429 NaN 7 64756.0 2.564857 -73.74 41.79 29.040092 15.894470 22.465899 22.322120 3.880184 20.864101 ... 0.106465 0.113350 0.118535 0.139206 25.527189 25.406912 24.316204 22.814286 21.129630 NaN 8 64756.0 2.297069 -73.74 41.79 28.139048 15.543810 21.838571 21.615714 3.969048 18.131429 ... 0.134129 0.128214 0.122652 0.136627 24.912857 24.918095 24.244762 23.358571 22.286190 NaN 9 64756.0 2.564857 -73.74 41.79 23.720096 11.202871 17.460287 17.344019 3.948804 14.033301 ... 0.144627 0.151890 0.127550 0.141841 20.640191 20.736364 20.594258 20.666986 20.554067 NaN 10 64756.0 2.590664 -73.74 41.79 17.773488 5.738140 11.753023 11.740465 3.637963 9.193674 ... 0.190428 0.187633 0.141386 0.144750 14.663256 14.799070 15.074419 15.892558 16.645581 NaN 11 64756.0 2.593429 -73.74 41.79 10.377512 -1.277990 4.547368 4.720574 3.301905 6.567895 ... 0.234833 0.237167 0.166742 0.161895 7.128708 7.302392 7.955288 9.385167 10.990909 NaN 12 64756.0 2.593429 -73.74 41.79 4.488018 -4.917972 -0.217512 0.055760 3.121198 4.639954 ... 0.254506 0.242934 0.171530 0.170230 2.254839 2.385714 2.946083 4.288479 5.912442 NaN <p>12 rows \u00d7 27 columns</p> In\u00a0[93]: Copied! <pre>df.resample('M').mean().plot(y='T_DAILY_MEAN', marker='o')\n</pre> df.resample('M').mean().plot(y='T_DAILY_MEAN', marker='o')  Out[93]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> <p>Just like with groupby, we can apply any aggregation function to our resample operation.</p> In\u00a0[94]: Copied! <pre>df.resample('M').max().plot(y='T_DAILY_MAX', marker='o')\n</pre> df.resample('M').max().plot(y='T_DAILY_MAX', marker='o')  Out[94]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[98]: Copied! <pre>df.rolling(30, center=True).T_DAILY_MEAN.mean().plot()\ndf.rolling(30, center=True, win_type='triang').T_DAILY_MEAN.mean().plot()\n</pre> df.rolling(30, center=True).T_DAILY_MEAN.mean().plot() df.rolling(30, center=True, win_type='triang').T_DAILY_MEAN.mean().plot() Out[98]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[99]: Copied! <pre>df.loc[(df.T_DAILY_MEAN.isnull())]\n</pre> df.loc[(df.T_DAILY_MEAN.isnull())] Out[99]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 2017-10-04 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2018-10-13 64756 2.622 -73.74 41.79 NaN NaN NaN NaN 4.6 NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-10 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-11 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-12 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-13 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-14 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-15 64756 -9.000 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-08-16 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2019-09-25 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2021-01-04 64756 2.622 -73.74 41.79 NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 2021-11-16 64756 2.622 -73.74 41.79 NaN NaN NaN NaN 0.0 NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN <p>12 rows \u00d7 27 columns</p> In\u00a0[102]: Copied! <pre>df_roll = df.rolling(30, center=True).T_DAILY_MEAN.mean()\n</pre> df_roll = df.rolling(30, center=True).T_DAILY_MEAN.mean() In\u00a0[103]: Copied! <pre>list(df_roll.loc[df_roll.isnull()].index)\n</pre> list(df_roll.loc[df_roll.isnull()].index) Out[103]: <pre>[Timestamp('2016-01-01 00:00:00'),\n Timestamp('2016-01-02 00:00:00'),\n Timestamp('2016-01-03 00:00:00'),\n Timestamp('2016-01-04 00:00:00'),\n Timestamp('2016-01-05 00:00:00'),\n Timestamp('2016-01-06 00:00:00'),\n Timestamp('2016-01-07 00:00:00'),\n Timestamp('2016-01-08 00:00:00'),\n Timestamp('2016-01-09 00:00:00'),\n Timestamp('2016-01-10 00:00:00'),\n Timestamp('2016-01-11 00:00:00'),\n Timestamp('2016-01-12 00:00:00'),\n Timestamp('2016-01-13 00:00:00'),\n Timestamp('2016-01-14 00:00:00'),\n Timestamp('2016-01-15 00:00:00'),\n Timestamp('2017-09-20 00:00:00'),\n Timestamp('2017-09-21 00:00:00'),\n Timestamp('2017-09-22 00:00:00'),\n Timestamp('2017-09-23 00:00:00'),\n Timestamp('2017-09-24 00:00:00'),\n Timestamp('2017-09-25 00:00:00'),\n Timestamp('2017-09-26 00:00:00'),\n Timestamp('2017-09-27 00:00:00'),\n Timestamp('2017-09-28 00:00:00'),\n Timestamp('2017-09-29 00:00:00'),\n Timestamp('2017-09-30 00:00:00'),\n Timestamp('2017-10-01 00:00:00'),\n Timestamp('2017-10-02 00:00:00'),\n Timestamp('2017-10-03 00:00:00'),\n Timestamp('2017-10-04 00:00:00'),\n Timestamp('2017-10-05 00:00:00'),\n Timestamp('2017-10-06 00:00:00'),\n Timestamp('2017-10-07 00:00:00'),\n Timestamp('2017-10-08 00:00:00'),\n Timestamp('2017-10-09 00:00:00'),\n Timestamp('2017-10-10 00:00:00'),\n Timestamp('2017-10-11 00:00:00'),\n Timestamp('2017-10-12 00:00:00'),\n Timestamp('2017-10-13 00:00:00'),\n Timestamp('2017-10-14 00:00:00'),\n Timestamp('2017-10-15 00:00:00'),\n Timestamp('2017-10-16 00:00:00'),\n Timestamp('2017-10-17 00:00:00'),\n Timestamp('2017-10-18 00:00:00'),\n Timestamp('2017-10-19 00:00:00'),\n Timestamp('2018-09-29 00:00:00'),\n Timestamp('2018-09-30 00:00:00'),\n Timestamp('2018-10-01 00:00:00'),\n Timestamp('2018-10-02 00:00:00'),\n Timestamp('2018-10-03 00:00:00'),\n Timestamp('2018-10-04 00:00:00'),\n Timestamp('2018-10-05 00:00:00'),\n Timestamp('2018-10-06 00:00:00'),\n Timestamp('2018-10-07 00:00:00'),\n Timestamp('2018-10-08 00:00:00'),\n Timestamp('2018-10-09 00:00:00'),\n Timestamp('2018-10-10 00:00:00'),\n Timestamp('2018-10-11 00:00:00'),\n Timestamp('2018-10-12 00:00:00'),\n Timestamp('2018-10-13 00:00:00'),\n Timestamp('2018-10-14 00:00:00'),\n Timestamp('2018-10-15 00:00:00'),\n Timestamp('2018-10-16 00:00:00'),\n Timestamp('2018-10-17 00:00:00'),\n Timestamp('2018-10-18 00:00:00'),\n Timestamp('2018-10-19 00:00:00'),\n Timestamp('2018-10-20 00:00:00'),\n Timestamp('2018-10-21 00:00:00'),\n Timestamp('2018-10-22 00:00:00'),\n Timestamp('2018-10-23 00:00:00'),\n Timestamp('2018-10-24 00:00:00'),\n Timestamp('2018-10-25 00:00:00'),\n Timestamp('2018-10-26 00:00:00'),\n Timestamp('2018-10-27 00:00:00'),\n Timestamp('2018-10-28 00:00:00'),\n Timestamp('2019-07-27 00:00:00'),\n Timestamp('2019-07-28 00:00:00'),\n Timestamp('2019-07-29 00:00:00'),\n Timestamp('2019-07-30 00:00:00'),\n Timestamp('2019-07-31 00:00:00'),\n Timestamp('2019-08-01 00:00:00'),\n Timestamp('2019-08-02 00:00:00'),\n Timestamp('2019-08-03 00:00:00'),\n Timestamp('2019-08-04 00:00:00'),\n Timestamp('2019-08-05 00:00:00'),\n Timestamp('2019-08-06 00:00:00'),\n Timestamp('2019-08-07 00:00:00'),\n Timestamp('2019-08-08 00:00:00'),\n Timestamp('2019-08-09 00:00:00'),\n Timestamp('2019-08-10 00:00:00'),\n Timestamp('2019-08-11 00:00:00'),\n Timestamp('2019-08-12 00:00:00'),\n Timestamp('2019-08-13 00:00:00'),\n Timestamp('2019-08-14 00:00:00'),\n Timestamp('2019-08-15 00:00:00'),\n Timestamp('2019-08-16 00:00:00'),\n Timestamp('2019-08-17 00:00:00'),\n Timestamp('2019-08-18 00:00:00'),\n Timestamp('2019-08-19 00:00:00'),\n Timestamp('2019-08-20 00:00:00'),\n Timestamp('2019-08-21 00:00:00'),\n Timestamp('2019-08-22 00:00:00'),\n Timestamp('2019-08-23 00:00:00'),\n Timestamp('2019-08-24 00:00:00'),\n Timestamp('2019-08-25 00:00:00'),\n Timestamp('2019-08-26 00:00:00'),\n Timestamp('2019-08-27 00:00:00'),\n Timestamp('2019-08-28 00:00:00'),\n Timestamp('2019-08-29 00:00:00'),\n Timestamp('2019-08-30 00:00:00'),\n Timestamp('2019-08-31 00:00:00'),\n Timestamp('2019-09-11 00:00:00'),\n Timestamp('2019-09-12 00:00:00'),\n Timestamp('2019-09-13 00:00:00'),\n Timestamp('2019-09-14 00:00:00'),\n Timestamp('2019-09-15 00:00:00'),\n Timestamp('2019-09-16 00:00:00'),\n Timestamp('2019-09-17 00:00:00'),\n Timestamp('2019-09-18 00:00:00'),\n Timestamp('2019-09-19 00:00:00'),\n Timestamp('2019-09-20 00:00:00'),\n Timestamp('2019-09-21 00:00:00'),\n Timestamp('2019-09-22 00:00:00'),\n Timestamp('2019-09-23 00:00:00'),\n Timestamp('2019-09-24 00:00:00'),\n Timestamp('2019-09-25 00:00:00'),\n Timestamp('2019-09-26 00:00:00'),\n Timestamp('2019-09-27 00:00:00'),\n Timestamp('2019-09-28 00:00:00'),\n Timestamp('2019-09-29 00:00:00'),\n Timestamp('2019-09-30 00:00:00'),\n Timestamp('2019-10-01 00:00:00'),\n Timestamp('2019-10-02 00:00:00'),\n Timestamp('2019-10-03 00:00:00'),\n Timestamp('2019-10-04 00:00:00'),\n Timestamp('2019-10-05 00:00:00'),\n Timestamp('2019-10-06 00:00:00'),\n Timestamp('2019-10-07 00:00:00'),\n Timestamp('2019-10-08 00:00:00'),\n Timestamp('2019-10-09 00:00:00'),\n Timestamp('2019-10-10 00:00:00'),\n Timestamp('2020-12-21 00:00:00'),\n Timestamp('2020-12-22 00:00:00'),\n Timestamp('2020-12-23 00:00:00'),\n Timestamp('2020-12-24 00:00:00'),\n Timestamp('2020-12-25 00:00:00'),\n Timestamp('2020-12-26 00:00:00'),\n Timestamp('2020-12-27 00:00:00'),\n Timestamp('2020-12-28 00:00:00'),\n Timestamp('2020-12-29 00:00:00'),\n Timestamp('2020-12-30 00:00:00'),\n Timestamp('2020-12-31 00:00:00'),\n Timestamp('2021-01-01 00:00:00'),\n Timestamp('2021-01-02 00:00:00'),\n Timestamp('2021-01-03 00:00:00'),\n Timestamp('2021-01-04 00:00:00'),\n Timestamp('2021-01-05 00:00:00'),\n Timestamp('2021-01-06 00:00:00'),\n Timestamp('2021-01-07 00:00:00'),\n Timestamp('2021-01-08 00:00:00'),\n Timestamp('2021-01-09 00:00:00'),\n Timestamp('2021-01-10 00:00:00'),\n Timestamp('2021-01-11 00:00:00'),\n Timestamp('2021-01-12 00:00:00'),\n Timestamp('2021-01-13 00:00:00'),\n Timestamp('2021-01-14 00:00:00'),\n Timestamp('2021-01-15 00:00:00'),\n Timestamp('2021-01-16 00:00:00'),\n Timestamp('2021-01-17 00:00:00'),\n Timestamp('2021-01-18 00:00:00'),\n Timestamp('2021-01-19 00:00:00'),\n Timestamp('2021-11-02 00:00:00'),\n Timestamp('2021-11-03 00:00:00'),\n Timestamp('2021-11-04 00:00:00'),\n Timestamp('2021-11-05 00:00:00'),\n Timestamp('2021-11-06 00:00:00'),\n Timestamp('2021-11-07 00:00:00'),\n Timestamp('2021-11-08 00:00:00'),\n Timestamp('2021-11-09 00:00:00'),\n Timestamp('2021-11-10 00:00:00'),\n Timestamp('2021-11-11 00:00:00'),\n Timestamp('2021-11-12 00:00:00'),\n Timestamp('2021-11-13 00:00:00'),\n Timestamp('2021-11-14 00:00:00'),\n Timestamp('2021-11-15 00:00:00'),\n Timestamp('2021-11-16 00:00:00'),\n Timestamp('2021-11-17 00:00:00'),\n Timestamp('2021-11-18 00:00:00'),\n Timestamp('2021-11-19 00:00:00'),\n Timestamp('2021-11-20 00:00:00'),\n Timestamp('2021-11-21 00:00:00'),\n Timestamp('2021-11-22 00:00:00'),\n Timestamp('2021-11-23 00:00:00'),\n Timestamp('2021-11-24 00:00:00'),\n Timestamp('2021-11-25 00:00:00'),\n Timestamp('2021-11-26 00:00:00'),\n Timestamp('2021-11-27 00:00:00'),\n Timestamp('2021-11-28 00:00:00'),\n Timestamp('2021-11-29 00:00:00'),\n Timestamp('2021-11-30 00:00:00'),\n Timestamp('2021-12-01 00:00:00'),\n Timestamp('2022-12-18 00:00:00'),\n Timestamp('2022-12-19 00:00:00'),\n Timestamp('2022-12-20 00:00:00'),\n Timestamp('2022-12-21 00:00:00'),\n Timestamp('2022-12-22 00:00:00'),\n Timestamp('2022-12-23 00:00:00'),\n Timestamp('2022-12-24 00:00:00'),\n Timestamp('2022-12-25 00:00:00'),\n Timestamp('2022-12-26 00:00:00'),\n Timestamp('2022-12-27 00:00:00'),\n Timestamp('2022-12-28 00:00:00'),\n Timestamp('2022-12-29 00:00:00'),\n Timestamp('2022-12-30 00:00:00'),\n Timestamp('2022-12-31 00:00:00')]</pre> In\u00a0[104]: Copied! <pre>df.rolling('30D', center=True).T_DAILY_MEAN.mean().plot()\n</pre> df.rolling('30D', center=True).T_DAILY_MEAN.mean().plot()  Out[104]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[105]: Copied! <pre>df\n</pre> df Out[105]: WBANNO CRX_VN LONGITUDE LATITUDE T_DAILY_MAX T_DAILY_MIN T_DAILY_MEAN T_DAILY_AVG P_DAILY_CALC SOLARAD_DAILY ... SOIL_MOISTURE_10_DAILY SOIL_MOISTURE_20_DAILY SOIL_MOISTURE_50_DAILY SOIL_MOISTURE_100_DAILY SOIL_TEMP_5_DAILY SOIL_TEMP_10_DAILY SOIL_TEMP_20_DAILY SOIL_TEMP_50_DAILY SOIL_TEMP_100_DAILY Unnamed: 28 LST_DATE 2016-01-01 64756 2.422 -73.74 41.79 3.4 -0.5 1.5 1.3 0.0 1.69 ... 0.233 0.204 0.155 0.147 4.2 4.4 5.1 6.0 7.6 NaN 2016-01-02 64756 2.422 -73.74 41.79 2.9 -3.6 -0.4 -0.3 0.0 6.25 ... 0.227 0.199 0.152 0.144 2.8 3.1 4.2 5.7 7.4 NaN 2016-01-03 64756 2.422 -73.74 41.79 5.1 -1.8 1.6 1.1 0.0 5.69 ... 0.223 0.196 0.151 0.141 2.6 2.8 3.8 5.2 7.2 NaN 2016-01-04 64756 2.422 -73.74 41.79 0.5 -14.4 -6.9 -7.5 0.0 9.17 ... 0.220 0.194 0.148 0.139 1.7 2.1 3.4 4.9 6.9 NaN 2016-01-05 64756 2.422 -73.74 41.79 -5.2 -15.5 -10.3 -11.7 0.0 9.34 ... 0.213 0.191 0.148 0.138 0.4 0.9 2.4 4.3 6.6 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2022-12-27 64756 2.622 -73.74 41.79 -0.8 -8.0 -4.4 -3.8 0.0 4.00 ... NaN NaN 0.164 0.157 -0.4 -0.2 0.5 2.2 4.0 NaN 2022-12-28 64756 2.622 -73.74 41.79 7.4 -6.1 0.7 1.3 0.0 7.73 ... NaN NaN 0.162 0.156 -0.4 -0.3 0.4 2.1 3.8 NaN 2022-12-29 64756 2.622 -73.74 41.79 10.7 -1.8 4.4 5.0 0.0 6.66 ... NaN NaN 0.159 0.155 -0.3 -0.3 0.3 1.9 3.7 NaN 2022-12-30 64756 2.622 -73.74 41.79 16.6 4.9 10.7 10.3 0.0 5.39 ... NaN NaN 0.159 0.154 -0.2 -0.2 0.3 1.8 3.6 NaN 2022-12-31 64756 2.622 -73.74 41.79 13.2 2.7 7.9 10.2 5.0 1.25 ... NaN NaN 0.160 0.153 -0.1 -0.2 0.3 1.8 3.4 NaN <p>2557 rows \u00d7 27 columns</p> In\u00a0[106]: Copied! <pre>df_sub = df.loc['2017-01-01':'2017-12-31']\n</pre> df_sub = df.loc['2017-01-01':'2017-12-31'] In\u00a0[107]: Copied! <pre>df_sub['SOIL_MOISTURE_10_DAILY'].plot()\n</pre> df_sub['SOIL_MOISTURE_10_DAILY'].plot() Out[107]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[110]: Copied! <pre># Fill values forward\n\ndf_sub.ffill()['SOIL_MOISTURE_10_DAILY'].plot()\n\n# Fill values backward\n\ndf_sub.bfill()['SOIL_MOISTURE_10_DAILY'].plot()\n</pre> # Fill values forward  df_sub.ffill()['SOIL_MOISTURE_10_DAILY'].plot()  # Fill values backward  df_sub.bfill()['SOIL_MOISTURE_10_DAILY'].plot() Out[110]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[114]: Copied! <pre>df_sub.fillna(method = 'ffill', limit = 3)['SOIL_MOISTURE_10_DAILY'].plot()\n</pre> df_sub.fillna(method = 'ffill', limit = 3)['SOIL_MOISTURE_10_DAILY'].plot() Out[114]: <pre>&lt;Axes: xlabel='LST_DATE'&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_7_Pandas_Advanced/#lecture-7-advaned-pandas","title":"Lecture 7: Advaned Pandas\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#groupby-methods","title":"Groupby methods\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#an-example","title":"An Example:\u00b6","text":"<p>Question: Find out the top 10 states with largest number of wildfires.</p> <p>This is an example of a \"one-liner\" that you can accomplish with groupby.</p>"},{"location":"Lecture_7_Pandas_Advanced/#what-happened","title":"What Happened?\u00b6","text":"<p>Let's break apart this operation a bit. The workflow with <code>groubpy</code> can be divided into three general steps:</p> <ol> <li><p>Split: Partition the data into different groups based on some criterion.</p> </li> <li><p>Apply: Do some caclulation within each group. Different types of \"apply\" steps might be</p> <ul> <li> Aggregation: Get the mean or max within the group. </li> <li> Transformation: Normalize all the values within a group. </li> <li> Filtration: Eliminate some groups based on a criterion. </li> </ul> </li> <li><p>Combine: Put the results back together into a single object.</p> </li> </ol>"},{"location":"Lecture_7_Pandas_Advanced/#the-groupby-method","title":"The <code>groupby</code> method\u00b6","text":"<p>Both <code>Series</code> and <code>DataFrame</code> objects have a groupby method. It accepts a variety of arguments, but the simplest way to think about it is that you pass another series, whose unique values are used to split the original object into different groups.</p>"},{"location":"Lecture_7_Pandas_Advanced/#the-groubby-object","title":"The <code>GroubBy</code> object\u00b6","text":"<p>When we call, <code>groupby</code> we get back a <code>GroupBy</code> object:</p>"},{"location":"Lecture_7_Pandas_Advanced/#iterating-and-selecting-groups","title":"Iterating and selecting groups\u00b6","text":"<p>You can loop through the groups if you want.</p>"},{"location":"Lecture_7_Pandas_Advanced/#aggregation","title":"Aggregation\u00b6","text":"<p>Now that we know how to create a <code>GroupBy</code> object, let's learn how to do aggregation on it.</p> <p>One way us to use the <code>.aggregate</code> method, which accepts another function as its argument. The result is automatically combined into a new dataframe with the group key as the index.</p>"},{"location":"Lecture_7_Pandas_Advanced/#groupby-multiple-index","title":"Groupby multiple index\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#named-aggregation","title":"Named aggregation\u00b6","text":"<ul> <li>The keywords are the output column names</li> <li>The values are tuples whose first element is the column to select and the second element is the aggregation to apply to that column.</li> </ul>"},{"location":"Lecture_7_Pandas_Advanced/#filtration","title":"Filtration\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#time-grouping-with-the-weather-data","title":"Time grouping with the weather data\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#calculating-anomalies","title":"Calculating anomalies\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#resampling","title":"Resampling\u00b6","text":"<p>Another common operation is to change the resolution of a dataset by resampling in time. Pandas exposes this through the resample function. The resample periods are specified using pandas offset index syntax.</p> <p>Below we resample the dataset by taking the mean over each month.</p>"},{"location":"Lecture_7_Pandas_Advanced/#rolling-operations","title":"Rolling Operations\u00b6","text":""},{"location":"Lecture_7_Pandas_Advanced/#filling-missing-data","title":"Filling missing data\u00b6","text":""},{"location":"Lecture_8_Xarray/","title":"Lecture 8: Xarray for multidimensional gridded data","text":"<p>Here is an example of how we might structure a dataset for a weather forecast:</p> <p>You'll notice multiple data variables (temperature, precipitation), coordinate variables (latitude, longitude), and dimensions (x, y, t). We'll cover how these fit into Xarray's data structures below.</p> <p>Xarray doesn\u2019t just keep track of labels on arrays \u2013 it uses them to provide a powerful and concise interface. For example:</p> <ul> <li><p>Apply operations over dimensions by name: <code>x.sum('time')</code>.</p> </li> <li><p>Select values by label (or logical location) instead of integer location: <code>x.loc['2014-01-01']</code> or <code>x.sel(time='2014-01-01')</code>.</p> </li> <li><p>Mathematical operations (e.g., <code>x - y</code>) vectorize across multiple dimensions (array broadcasting) based on dimension names, not shape.</p> </li> <li><p>Easily use the split-apply-combine paradigm with groupby: <code>x.groupby('time.dayofyear').mean()</code>.</p> </li> <li><p>Database-like alignment based on coordinate labels that smoothly handles missing values: <code>x, y = xr.align(x, y, join='outer')</code>.</p> </li> <li><p>Keep track of arbitrary metadata in the form of a Python dictionary: <code>x.attrs</code>.</p> </li> </ul> <p>The N-dimensional nature of xarray\u2019s data structures makes it suitable for dealing with multi-dimensional scientific data, and its use of dimension names instead of axis labels (<code>dim='time'</code> instead of <code>axis=0</code>) makes such arrays much more manageable than the raw numpy ndarray: with xarray, you don\u2019t need to keep track of the order of an array\u2019s dimensions or insert dummy dimensions of size 1 to align arrays (e.g., using np.newaxis).</p> <p>The immediate payoff of using xarray is that you\u2019ll write less code. The long-term payoff is that you\u2019ll understand what you were thinking when you come back to look at it weeks or months later.</p> In\u00a0[1]: Copied! <pre># First import xarray \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\n</pre> # First import xarray  import matplotlib.pyplot as plt import numpy as np import xarray as xr In\u00a0[2]: Copied! <pre>ds = xr.tutorial.load_dataset(\"air_temperature\")\nds\n</pre> ds = xr.tutorial.load_dataset(\"air_temperature\") ds Out[2]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 241.2 242.5 243.5 ... 296.5 296.2 295.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 2920</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32241.2 242.5 243.5 ... 296.2 295.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>We can access \"layers\" of the Dataset (individual DataArrays) with dictionary syntax</p> In\u00a0[3]: Copied! <pre>ds[\"air\"]\n</pre> ds[\"air\"] Out[3]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 53)&gt;\narray([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 53</li></ul><ul><li>241.2 242.5 243.5 244.0 244.1 243.9 ... 297.4 297.2 296.5 296.2 295.7<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]</li></ul> <p>We can save some typing by using the \"attribute\" or \"dot\" notation. This won't work for variable names that clash with built-in method names (for example, <code>mean</code>).</p> In\u00a0[4]: Copied! <pre>ds.air\n</pre> ds.air Out[4]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 53)&gt;\narray([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 53</li></ul><ul><li>241.2 242.5 243.5 244.0 244.1 243.9 ... 297.4 297.2 296.5 296.2 295.7<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]</li></ul> In\u00a0[5]: Copied! <pre>da = ds[\"air\"]\nda\n</pre> da = ds[\"air\"] da Out[5]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 53)&gt;\narray([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 53</li></ul><ul><li>241.2 242.5 243.5 244.0 244.1 243.9 ... 297.4 297.2 296.5 296.2 295.7<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (11)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]</li></ul> <p>We can also access the data array directly:</p> In\u00a0[6]: Copied! <pre>ds.air.data\n</pre> ds.air.data   Out[6]: <pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n        ...,\n        [296.4    , 295.9    , 296.19998, ..., 295.4    , 295.1    ,\n         294.79   ],\n        [296.19998, 296.69998, 296.79   , ..., 295.6    , 295.5    ,\n         295.1    ],\n        [296.29   , 297.19998, 297.4    , ..., 296.4    , 296.4    ,\n         296.6    ]],\n\n       [[242.29999, 242.2    , 242.29999, ..., 234.29999, 236.09999,\n         238.7    ],\n        [244.59999, 244.39   , 244.     , ..., 230.29999, 232.     ,\n         235.7    ],\n        [256.19998, 255.5    , 254.2    , ..., 231.2    , 233.2    ,\n         238.2    ],\n        ...,\n        [295.6    , 295.4    , 295.4    , ..., 296.29   , 295.29   ,\n         295.     ],\n        [296.19998, 296.5    , 296.29   , ..., 296.4    , 296.     ,\n         295.6    ],\n        [296.4    , 296.29   , 296.4    , ..., 297.     , 297.     ,\n         296.79   ]],\n\n       ...,\n\n       [[243.48999, 242.98999, 242.09   , ..., 244.18999, 244.48999,\n         244.89   ],\n        [249.09   , 248.98999, 248.59   , ..., 240.59   , 241.29   ,\n         242.68999],\n        [262.69   , 262.19   , 261.69   , ..., 239.39   , 241.68999,\n         245.18999],\n        ...,\n        [294.79   , 295.29   , 297.49   , ..., 295.49   , 295.38998,\n         294.69   ],\n        [296.79   , 297.88998, 298.29   , ..., 295.49   , 295.49   ,\n         294.79   ],\n        [298.19   , 299.19   , 298.79   , ..., 296.09   , 295.79   ,\n         295.79   ]],\n\n       [[245.79   , 244.79   , 243.48999, ..., 243.29   , 243.98999,\n         244.79   ],\n        [249.89   , 249.29   , 248.48999, ..., 241.29   , 242.48999,\n         244.29   ],\n        [262.38998, 261.79   , 261.29   , ..., 240.48999, 243.09   ,\n         246.89   ],\n        ...,\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre> In\u00a0[7]: Copied! <pre>ds.air.dims\n</pre> ds.air.dims Out[7]: <pre>('time', 'lat', 'lon')</pre> In\u00a0[8]: Copied! <pre>ds.air.coords\n</pre> ds.air.coords Out[8]: <pre>Coordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00</pre> In\u00a0[9]: Copied! <pre>ds.air.attrs\n</pre> ds.air.attrs Out[9]: <pre>{'long_name': '4xDaily Air temperature at sigma level 995',\n 'units': 'degK',\n 'precision': 2,\n 'GRIB_id': 11,\n 'GRIB_name': 'TMP',\n 'var_desc': 'Air temperature',\n 'dataset': 'NMC Reanalysis',\n 'level_desc': 'Surface',\n 'statistic': 'Individual Obs',\n 'parent_stat': 'Other',\n 'actual_range': array([185.16, 322.1 ], dtype='&gt;f4')}</pre> In\u00a0[10]: Copied! <pre># assign your own attributes!\nds.air.attrs[\"new_attr\"] = \"xarray\"\nds.air.attrs\n</pre> # assign your own attributes! ds.air.attrs[\"new_attr\"] = \"xarray\" ds.air.attrs Out[10]: <pre>{'long_name': '4xDaily Air temperature at sigma level 995',\n 'units': 'degK',\n 'precision': 2,\n 'GRIB_id': 11,\n 'GRIB_name': 'TMP',\n 'var_desc': 'Air temperature',\n 'dataset': 'NMC Reanalysis',\n 'level_desc': 'Surface',\n 'statistic': 'Individual Obs',\n 'parent_stat': 'Other',\n 'actual_range': array([185.16, 322.1 ], dtype='&gt;f4'),\n 'new_attr': 'xarray'}</pre> In\u00a0[11]: Copied! <pre>## Without Xarray, let's try to use matplotlib to plot the data\n\ntemp = ds.air.data\nplt.pcolormesh(temp[0,:,:])\n</pre> ## Without Xarray, let's try to use matplotlib to plot the data  temp = ds.air.data plt.pcolormesh(temp[0,:,:]) Out[11]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1945afee0&gt;</pre> In\u00a0[12]: Copied! <pre>### Add Lat and Lon\n\ntemp = ds.air.data\nlat = ds.air.lat.data\nlon = ds.air.lon.data\nplt.pcolormesh(lon, lat, temp[0,:,:])\n</pre> ### Add Lat and Lon  temp = ds.air.data lat = ds.air.lat.data lon = ds.air.lon.data plt.pcolormesh(lon, lat, temp[0,:,:]) Out[12]: <pre>&lt;matplotlib.collections.QuadMesh at 0x1947868b0&gt;</pre> In\u00a0[13]: Copied! <pre>temp.mean(axis=1)  ## what did I just do? I can't tell by looking at this line.\n</pre> temp.mean(axis=1)  ## what did I just do? I can't tell by looking at this line.  Out[13]: <pre>array([[279.39798, 279.6664 , 279.66122, ..., 279.9508 , 280.31522,\n        280.6624 ],\n       [279.05722, 279.538  , 279.7296 , ..., 279.77563, 280.27002,\n        280.79764],\n       [279.0104 , 279.2808 , 279.5508 , ..., 279.682  , 280.19763,\n        280.81403],\n       ...,\n       [279.63   , 279.934  , 280.534  , ..., 279.802  , 280.346  ,\n        280.77798],\n       [279.398  , 279.66602, 280.31796, ..., 279.766  , 280.34198,\n        280.834  ],\n       [279.27   , 279.354  , 279.88202, ..., 279.42596, 279.96997,\n        280.48196]], dtype=float32)</pre> In\u00a0[14]: Copied! <pre>ds.air.isel(time=0).plot()\n</pre> ds.air.isel(time=0).plot()  Out[14]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194849940&gt;</pre> In\u00a0[15]: Copied! <pre>ds.air.mean(dim=\"time\").plot()\n</pre> ds.air.mean(dim=\"time\").plot()  Out[15]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194942490&gt;</pre> In\u00a0[16]: Copied! <pre>da[:, 20, 40]\n</pre> da[:, 20, 40] Out[16]: <pre>&lt;xarray.DataArray 'air' (time: 2920)&gt;\narray([295.  , 294.4 , 294.5 , ..., 297.29, 297.79, 297.99], dtype=float32)\nCoordinates:\n    lat      float32 25.0\n    lon      float32 300.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li></ul><ul><li>295.0 294.4 294.5 295.4 295.2 294.4 ... 297.7 297.3 297.3 297.8 298.0<pre>array([295.  , 294.4 , 294.5 , ..., 297.29, 297.79, 297.99], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3225.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(25., dtype=float32)</pre></li><li>lon()float32300.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(300., dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[17]: Copied! <pre>da[0,0,0]\n</pre> da[0,0,0] Out[17]: <pre>&lt;xarray.DataArray 'air' ()&gt;\narray(241.2, dtype=float32)\nCoordinates:\n    lat      float32 75.0\n    lon      float32 200.0\n    time     datetime64[ns] 2013-01-01\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>241.2<pre>array(241.2, dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3275.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(75., dtype=float32)</pre></li><li>lon()float32200.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(200., dtype=float32)</pre></li><li>time()datetime64[ns]2013-01-01standard_name :timelong_name :Time<pre>array('2013-01-01T00:00:00.000000000', dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (0)<ul></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> <p>Remembering the axis order can be challenging even with 2D arrays:</p> <ul> <li>is <code>np_array[0,3]</code> the first row and third column or first column and third row?</li> <li>or did I store these samples by row or by column when I saved the data?!.</li> </ul> <p>The difficulty is compounded with added dimensions.</p> <p>Xarray objects eliminate much of the mental overhead by allowing indexing using dimension names instead of axes numbers:</p> In\u00a0[18]: Copied! <pre>da.isel(lat=0, lon=0).plot();\n</pre> da.isel(lat=0, lon=0).plot(); <p>Slicing is also possible similarly:</p> In\u00a0[19]: Copied! <pre>da.isel(time=slice(0, 20), lat=0, lon=0).plot();\n</pre> da.isel(time=slice(0, 20), lat=0, lon=0).plot(); <pre><code>{note}\nUsing the `isel` method, the user can choose/slice the specific elements from a Dataset or DataArray.\n</code></pre> <p>So far, we have explored positional indexing, which relies on knowing the exact indices. But, what if you wanted to select data specifically for a particular latitude? It becomes challenging to determine the corresponding indices in such cases. Xarray reduce this complexity by introducing label-based indexing.</p> <p>For example, let's select all data for Lat 25 \u00b0N and Lon 210 \u00b0E using <code>sel</code> :</p> In\u00a0[20]: hide-output Copied! <pre>da.sel(lat=25, lon=210).plot();\n</pre> da.sel(lat=25, lon=210).plot(); <p>Similarly we can do slicing or filter a range using the <code>.slice</code> function:</p> In\u00a0[21]: Copied! <pre># demonstrate slicing\nda.sel(lon=slice(210, 215))\n</pre> # demonstrate slicing da.sel(lon=slice(210, 215)) Out[21]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 3)&gt;\narray([[[244.09999, 243.89   , 243.59999],\n        [243.39   , 242.39   , 241.7    ],\n        [246.     , 244.39   , 243.09999],\n        ...,\n        [295.5    , 294.     , 293.6    ],\n        [296.1    , 295.1    , 294.6    ],\n        [296.9    , 296.4    , 296.     ]],\n\n       [[243.59999, 243.79999, 244.     ],\n        [243.7    , 243.29999, 242.79999],\n        [249.29999, 247.5    , 245.5    ],\n        ...,\n        [295.1    , 294.1    , 293.79   ],\n        [296.1    , 295.6    , 295.1    ],\n        [297.1    , 296.69998, 296.4    ]],\n\n       [[242.89   , 243.59999, 244.5    ],\n        [242.79999, 242.39   , 242.29999],\n        [250.2    , 248.09999, 246.29999],\n        ...,\n...\n        ...,\n        [297.99   , 297.49   , 297.29   ],\n        [298.59   , 298.49   , 298.19   ],\n        [299.29   , 298.99   , 298.59   ]],\n\n       [[240.29   , 238.89   , 237.79   ],\n        [245.68999, 243.98999, 242.29   ],\n        [259.38998, 257.69   , 255.48999],\n        ...,\n        [297.79   , 297.49   , 297.49   ],\n        [298.29   , 298.09   , 297.79   ],\n        [298.79   , 298.69   , 298.49   ]],\n\n       [[241.09   , 240.09   , 239.39   ],\n        [245.09   , 243.09   , 241.09   ],\n        [257.79   , 254.98999, 251.98999],\n        ...,\n        [297.29   , 297.29   , 297.38998],\n        [298.19   , 298.09   , 297.79   ],\n        [298.88998, 298.69   , 298.38998]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 210.0 212.5 215.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 3</li></ul><ul><li>244.1 243.9 243.6 243.4 242.4 241.7 ... 298.1 297.8 298.9 298.7 298.4<pre>array([[[244.09999, 243.89   , 243.59999],\n        [243.39   , 242.39   , 241.7    ],\n        [246.     , 244.39   , 243.09999],\n        ...,\n        [295.5    , 294.     , 293.6    ],\n        [296.1    , 295.1    , 294.6    ],\n        [296.9    , 296.4    , 296.     ]],\n\n       [[243.59999, 243.79999, 244.     ],\n        [243.7    , 243.29999, 242.79999],\n        [249.29999, 247.5    , 245.5    ],\n        ...,\n        [295.1    , 294.1    , 293.79   ],\n        [296.1    , 295.6    , 295.1    ],\n        [297.1    , 296.69998, 296.4    ]],\n\n       [[242.89   , 243.59999, 244.5    ],\n        [242.79999, 242.39   , 242.29999],\n        [250.2    , 248.09999, 246.29999],\n        ...,\n...\n        ...,\n        [297.99   , 297.49   , 297.29   ],\n        [298.59   , 298.49   , 298.19   ],\n        [299.29   , 298.99   , 298.59   ]],\n\n       [[240.29   , 238.89   , 237.79   ],\n        [245.68999, 243.98999, 242.29   ],\n        [259.38998, 257.69   , 255.48999],\n        ...,\n        [297.79   , 297.49   , 297.49   ],\n        [298.29   , 298.09   , 297.79   ],\n        [298.79   , 298.69   , 298.49   ]],\n\n       [[241.09   , 240.09   , 239.39   ],\n        [245.09   , 243.09   , 241.09   ],\n        [257.79   , 254.98999, 251.98999],\n        ...,\n        [297.29   , 297.29   , 297.38998],\n        [298.19   , 298.09   , 297.79   ],\n        [298.88998, 298.69   , 298.38998]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32210.0 212.5 215.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([210. , 212.5, 215. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([210.0, 212.5, 215.0], dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[22]: Copied! <pre># demonstrate slicing\nda.sel(lat=slice(25, 50))\n</pre> # demonstrate slicing da.sel(lat=slice(25, 50)) Out[22]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 0, lon: 53)&gt;\narray([], shape=(2920, 0, 53), dtype=float32)\nCoordinates:\n  * lat      (lat) float32 \n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 0</li><li>lon: 53</li></ul><ul><li><pre>array([], shape=(2920, 0, 53), dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float32standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([], dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[23]: Copied! <pre># demonstrate slicing\nda.sel(lat=slice(50, 25), lon=slice(210, 215))\n</pre> # demonstrate slicing da.sel(lat=slice(50, 25), lon=slice(210, 215)) Out[23]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 11, lon: 3)&gt;\narray([[[279.5    , 280.1    , 280.6    ],\n        [279.4    , 280.29   , 281.29   ],\n        [280.29   , 282.     , 283.29   ],\n        ...,\n        [294.5    , 294.9    , 293.5    ],\n        [295.4    , 294.69998, 293.19998],\n        [295.4    , 294.     , 292.9    ]],\n\n       [[278.4    , 279.19998, 280.6    ],\n        [279.1    , 279.69998, 280.79   ],\n        [280.1    , 280.6    , 281.69998],\n        ...,\n        [294.     , 294.5    , 294.19998],\n        [295.29   , 294.79   , 293.6    ],\n        [295.6    , 294.29   , 292.9    ]],\n\n       [[277.5    , 277.6    , 278.79   ],\n        [278.79   , 278.29   , 279.1    ],\n        [280.5    , 279.6    , 279.69998],\n        ...,\n...\n        ...,\n        [292.99   , 292.79   , 293.19   ],\n        [294.29   , 294.09   , 294.29   ],\n        [295.49   , 295.19   , 294.69   ]],\n\n       [[279.38998, 280.09   , 281.99   ],\n        [280.49   , 282.59   , 284.29   ],\n        [283.38998, 285.38998, 285.99   ],\n        ...,\n        [292.59   , 292.88998, 293.29   ],\n        [293.88998, 293.88998, 293.99   ],\n        [295.19   , 295.29   , 294.49   ]],\n\n       [[279.88998, 281.79   , 283.69   ],\n        [281.69   , 283.09   , 283.79   ],\n        [283.59   , 284.79   , 284.69   ],\n        ...,\n        [293.59   , 293.59   , 293.49   ],\n        [294.99   , 294.59   , 294.19   ],\n        [295.49   , 295.59   , 295.09   ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 50.0 47.5 45.0 42.5 40.0 ... 35.0 32.5 30.0 27.5 25.0\n  * lon      (lon) float32 210.0 212.5 215.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 11</li><li>lon: 3</li></ul><ul><li>279.5 280.1 280.6 279.4 280.3 281.3 ... 294.6 294.2 295.5 295.6 295.1<pre>array([[[279.5    , 280.1    , 280.6    ],\n        [279.4    , 280.29   , 281.29   ],\n        [280.29   , 282.     , 283.29   ],\n        ...,\n        [294.5    , 294.9    , 293.5    ],\n        [295.4    , 294.69998, 293.19998],\n        [295.4    , 294.     , 292.9    ]],\n\n       [[278.4    , 279.19998, 280.6    ],\n        [279.1    , 279.69998, 280.79   ],\n        [280.1    , 280.6    , 281.69998],\n        ...,\n        [294.     , 294.5    , 294.19998],\n        [295.29   , 294.79   , 293.6    ],\n        [295.6    , 294.29   , 292.9    ]],\n\n       [[277.5    , 277.6    , 278.79   ],\n        [278.79   , 278.29   , 279.1    ],\n        [280.5    , 279.6    , 279.69998],\n        ...,\n...\n        ...,\n        [292.99   , 292.79   , 293.19   ],\n        [294.29   , 294.09   , 294.29   ],\n        [295.49   , 295.19   , 294.69   ]],\n\n       [[279.38998, 280.09   , 281.99   ],\n        [280.49   , 282.59   , 284.29   ],\n        [283.38998, 285.38998, 285.99   ],\n        ...,\n        [292.59   , 292.88998, 293.29   ],\n        [293.88998, 293.88998, 293.99   ],\n        [295.19   , 295.29   , 294.49   ]],\n\n       [[279.88998, 281.79   , 283.69   ],\n        [281.69   , 283.09   , 283.79   ],\n        [283.59   , 284.79   , 284.69   ],\n        ...,\n        [293.59   , 293.59   , 293.49   ],\n        [294.99   , 294.59   , 294.19   ],\n        [295.49   , 295.59   , 295.09   ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3250.0 47.5 45.0 ... 30.0 27.5 25.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([50. , 47.5, 45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. ],\n      dtype=float32)</pre></li><li>lon(lon)float32210.0 212.5 215.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([210. , 212.5, 215. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([50.0, 47.5, 45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0], dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([210.0, 212.5, 215.0], dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[24]: Copied! <pre>da\n</pre> da Out[24]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 25, lon: 53)&gt;\narray([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 53</li></ul><ul><li>241.2 242.5 243.5 244.0 244.1 243.9 ... 297.4 297.2 296.5 296.2 295.7<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[25]: Copied! <pre>da.drop_sel(lat=75.0, lon=200.0)\n</pre> da.drop_sel(lat=75.0, lon=200.0) Out[25]: <pre>&lt;xarray.DataArray 'air' (time: 2920, lat: 24, lon: 52)&gt;\narray([[[244.5    , 244.7    , 244.2    , ..., 232.79999, 235.29999,\n         239.29999],\n        [249.79999, 248.89   , 247.5    , ..., 233.2    , 236.39   ,\n         241.7    ],\n        [267.1    , 267.1    , 266.69998, ..., 249.2    , 253.09999,\n         256.9    ],\n        ...,\n        [296.19998, 296.4    , 296.5    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [296.19998, 296.79   , 296.5    , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.79   , 297.1    , 297.     , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[244.09999, 244.2    , 244.09999, ..., 231.     , 232.5    ,\n         235.7    ],\n        [252.89   , 252.09999, 250.79999, ..., 230.79999, 233.39   ,\n         238.5    ],\n        [269.4    , 268.6    , 267.4    , ..., 247.2    , 250.5    ,\n         254.39   ],\n...\n        [293.88998, 295.38998, 297.19   , ..., 295.09   , 294.69   ,\n         294.29   ],\n        [297.19   , 297.59   , 297.88998, ..., 295.29   , 295.09   ,\n         294.38998],\n        [298.38998, 298.49   , 298.59   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[249.29   , 248.39   , 246.98999, ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.19   , 261.38998, 259.99   , ..., 239.89   , 242.59   ,\n         246.29   ],\n        [272.09   , 271.99   , 271.59   , ..., 255.39   , 258.99   ,\n         262.49   ],\n        ...,\n        [293.69   , 295.09   , 296.69   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.88998, 297.19   , 297.49   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [298.09   , 298.09   , 298.49   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 72.5 70.0 67.5 65.0 62.5 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 202.5 205.0 207.5 210.0 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li><li>lat: 24</li><li>lon: 52</li></ul><ul><li>244.5 244.7 244.2 243.4 242.4 241.7 ... 297.4 297.2 296.5 296.2 295.7<pre>array([[[244.5    , 244.7    , 244.2    , ..., 232.79999, 235.29999,\n         239.29999],\n        [249.79999, 248.89   , 247.5    , ..., 233.2    , 236.39   ,\n         241.7    ],\n        [267.1    , 267.1    , 266.69998, ..., 249.2    , 253.09999,\n         256.9    ],\n        ...,\n        [296.19998, 296.4    , 296.5    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [296.19998, 296.79   , 296.5    , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.79   , 297.1    , 297.     , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[244.09999, 244.2    , 244.09999, ..., 231.     , 232.5    ,\n         235.7    ],\n        [252.89   , 252.09999, 250.79999, ..., 230.79999, 233.39   ,\n         238.5    ],\n        [269.4    , 268.6    , 267.4    , ..., 247.2    , 250.5    ,\n         254.39   ],\n...\n        [293.88998, 295.38998, 297.19   , ..., 295.09   , 294.69   ,\n         294.29   ],\n        [297.19   , 297.59   , 297.88998, ..., 295.29   , 295.09   ,\n         294.38998],\n        [298.38998, 298.49   , 298.59   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[249.29   , 248.39   , 246.98999, ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.19   , 261.38998, 259.99   , ..., 239.89   , 242.59   ,\n         246.29   ],\n        [272.09   , 271.99   , 271.59   , ..., 255.39   , 258.99   ,\n         262.49   ],\n        ...,\n        [293.69   , 295.09   , 296.69   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.88998, 297.19   , 297.49   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [298.09   , 298.09   , 298.49   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3272.5 70.0 67.5 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5, 45. ,\n       42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5, 15. ],\n      dtype=float32)</pre></li><li>lon(lon)float32202.5 205.0 207.5 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5, 225. ,\n       227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5, 250. ,\n       252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5, 275. ,\n       277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5, 300. ,\n       302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5, 325. ,\n       327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5, 45.0,\n       42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5, 15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5, 225.0,\n       227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5, 250.0,\n       252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5, 275.0,\n       277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5, 300.0,\n       302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5, 325.0,\n       327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> <p>So far, all the above will require us to specify exact coordinate values, but what if we don't have the exact values? We can use nearest neighbor lookups to address this issue:</p> In\u00a0[26]: Copied! <pre>da.sel(lat=52.25, lon=251.8998, method=\"nearest\")\n</pre> da.sel(lat=52.25, lon=251.8998, method=\"nearest\") Out[26]: <pre>&lt;xarray.DataArray 'air' (time: 2920)&gt;\narray([262.69998, 263.19998, 270.9    , ..., 264.19   , 265.19   ,\n       266.99   ], dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 252.5\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li></ul><ul><li>262.7 263.2 270.9 274.1 273.3 270.6 ... 253.4 261.6 264.2 265.2 267.0<pre>array([262.69998, 263.19998, 270.9    , ..., 264.19   , 265.19   ,\n       266.99   ], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32252.5standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(252.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[27]: Copied! <pre>da.sel(lat=52.25, lon=251.8998, method=\"ffill\")\n</pre> da.sel(lat=52.25, lon=251.8998, method=\"ffill\") Out[27]: <pre>&lt;xarray.DataArray 'air' (time: 2920)&gt;\narray([269.5    , 269.29   , 273.69998, ..., 267.49   , 269.29   ,\n       268.69   ], dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 250.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li></ul><ul><li>269.5 269.3 273.7 273.5 272.4 270.3 ... 257.4 266.5 267.5 269.3 268.7<pre>array([269.5    , 269.29   , 273.69998, ..., 267.49   , 269.29   ,\n       268.69   ], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32250.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(250., dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> <p><code>tolerance</code> argument limits the maximum distance for valid matches with an inexact lookup:</p> In\u00a0[28]: Copied! <pre>da.sel(lat=52.25, lon=251.8998, method=\"nearest\", tolerance=2)\n</pre> da.sel(lat=52.25, lon=251.8998, method=\"nearest\", tolerance=2) Out[28]: <pre>&lt;xarray.DataArray 'air' (time: 2920)&gt;\narray([262.69998, 263.19998, 270.9    , ..., 264.19   , 265.19   ,\n       266.99   ], dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 252.5\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li></ul><ul><li>262.7 263.2 270.9 274.1 273.3 270.6 ... 253.4 261.6 264.2 265.2 267.0<pre>array([262.69998, 263.19998, 270.9    , ..., 264.19   , 265.19   ,\n       266.99   ], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32252.5standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(252.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> In\u00a0[29]: Copied! <pre>da.sel(lat=52.25, lon=198, method=\"nearest\", tolerance=2)\n</pre> da.sel(lat=52.25, lon=198, method=\"nearest\", tolerance=2) Out[29]: <pre>&lt;xarray.DataArray 'air' (time: 2920)&gt;\narray([276.69998, 275.79   , 275.29   , ..., 277.49   , 276.79   ,\n       276.88998], dtype=float32)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 200.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nAttributes:\n    long_name:     4xDaily Air temperature at sigma level 995\n    units:         degK\n    precision:     2\n    GRIB_id:       11\n    GRIB_name:     TMP\n    var_desc:      Air temperature\n    dataset:       NMC Reanalysis\n    level_desc:    Surface\n    statistic:     Individual Obs\n    parent_stat:   Other\n    actual_range:  [185.16 322.1 ]\n    new_attr:      xarray</pre>xarray.DataArray'air'<ul><li>time: 2920</li></ul><ul><li>276.7 275.8 275.3 275.6 275.7 276.2 ... 277.7 277.2 277.5 276.8 276.9<pre>array([276.69998, 275.79   , 275.29   , ..., 277.49   , 276.79   ,\n       276.88998], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat()float3252.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32200.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(200., dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (12)long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray</li></ul> <pre><code>{tip}\nAll of these indexing methods work on the dataset too!\n</code></pre> <p>We can also use these methods to index all variables in a dataset simultaneously, returning a new dataset:</p> In\u00a0[30]: Copied! <pre>ds.sel(lat=52.25, lon=251.8998, method=\"nearest\")\n</pre> ds.sel(lat=52.25, lon=251.8998, method=\"nearest\") Out[30]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (time: 2920)\nCoordinates:\n    lat      float32 52.5\n    lon      float32 252.5\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time) float32 262.7 263.2 270.9 274.1 ... 261.6 264.2 265.2 267.0\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 2920</li></ul></li><li>Coordinates: (3)<ul><li>lat()float3252.5standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array(52.5, dtype=float32)</pre></li><li>lon()float32252.5standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array(252.5, dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time)float32262.7 263.2 270.9 ... 265.2 267.0long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([262.69998, 263.19998, 270.9    , ..., 264.19   , 265.19   ,\n       266.99   ], dtype=float32)</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[31]: Copied! <pre>ds.sel(time='2013-01-01 06:00')\n</pre> ds.sel(time='2013-01-01 06:00') Out[31]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n    time     datetime64[ns] 2013-01-01T06:00:00\nData variables:\n    air      (lat, lon) float32 242.1 242.7 243.1 243.4 ... 296.4 296.4 296.6\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time()datetime64[ns]2013-01-01T06:00:00standard_name :timelong_name :Time<pre>array('2013-01-01T06:00:00.000000000', dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(lat, lon)float32242.1 242.7 243.1 ... 296.4 296.6long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n        235.79999],\n       [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n        235.7    ],\n       [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n        238.5    ],\n       ...,\n       [296.4    , 295.9    , 296.19998, ..., 295.4    , 295.1    ,\n        294.79   ],\n       [296.19998, 296.69998, 296.79   , ..., 295.6    , 295.5    ,\n        295.1    ],\n       [296.29   , 297.19998, 297.4    , ..., 296.4    , 296.4    ,\n        296.6    ]], dtype=float32)</pre></li></ul></li><li>Indexes: (2)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>By default, datetime selection will return a range of values that match the provided string. For e.g. <code>time=\"2013-01-01\"</code> will return all timestamps for that day (4 of them here):</p> In\u00a0[32]: Copied! <pre>ds.sel(time='2013-01-01')\n</pre> ds.sel(time='2013-01-01') Out[32]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 4, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2013-01-01T18:00:00\nData variables:\n    air      (time, lat, lon) float32 241.2 242.5 243.5 ... 297.8 298.0 297.9\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 4</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2013-01-01T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', '2013-01-01T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32241.2 242.5 243.5 ... 298.0 297.9long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [295.6    , 295.4    , 295.4    , ..., 296.29   , 295.29   ,\n         295.     ],\n        [296.19998, 296.5    , 296.29   , ..., 296.4    , 296.     ,\n         295.6    ],\n        [296.4    , 296.29   , 296.4    , ..., 297.     , 297.     ,\n         296.79   ]],\n\n       [[241.89   , 241.79999, 241.79999, ..., 234.39   , 235.5    ,\n         237.59999],\n        [246.29999, 245.29999, 244.2    , ..., 230.89   , 231.5    ,\n         234.5    ],\n        [256.6    , 254.7    , 252.09999, ..., 230.7    , 231.79999,\n         236.09999],\n        ...,\n        [296.6    , 296.4    , 296.     , ..., 296.5    , 295.79   ,\n         295.29   ],\n        [297.     , 297.5    , 297.1    , ..., 296.79   , 296.6    ,\n         296.29   ],\n        [297.5    , 297.69998, 297.5    , ..., 297.79   , 298.     ,\n         297.9    ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>We can use this feature to select all points in a year:</p> In\u00a0[33]: Copied! <pre>ds.sel(time=\"2014\")\n</pre> ds.sel(time=\"2014\") Out[33]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 1460, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2014-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 252.3 251.2 250.0 ... 296.5 296.2 295.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 1460</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2014-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2014-01-01T00:00:00.000000000', '2014-01-01T06:00:00.000000000',\n       '2014-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32252.3 251.2 250.0 ... 296.2 295.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[252.29999, 251.2    , 250.     , ..., 240.29999, 241.59999,\n         243.2    ],\n        [252.39   , 252.79999, 253.     , ..., 235.59999, 238.29999,\n         242.29999],\n        [246.5    , 247.59999, 249.2    , ..., 241.5    , 245.2    ,\n         250.39   ],\n        ...,\n        [297.5    , 297.19998, 296.9    , ..., 295.9    , 295.19998,\n         294.6    ],\n        [298.19998, 298.1    , 297.6    , ..., 295.9    , 295.6    ,\n         294.69998],\n        [298.29   , 298.6    , 298.4    , ..., 296.     , 295.29   ,\n         294.69998]],\n\n       [[252.5    , 251.2    , 249.7    , ..., 240.2    , 241.5    ,\n         243.2    ],\n        [253.5    , 253.59999, 253.39   , ..., 237.39   , 239.29999,\n         242.59999],\n        [250.     , 250.7    , 251.7    , ..., 241.5    , 244.59999,\n         249.     ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2014-01-01 00:00:00', '2014-01-01 06:00:00',\n               '2014-01-01 12:00:00', '2014-01-01 18:00:00',\n               '2014-01-02 00:00:00', '2014-01-02 06:00:00',\n               '2014-01-02 12:00:00', '2014-01-02 18:00:00',\n               '2014-01-03 00:00:00', '2014-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=1460, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>or a month:</p> In\u00a0[34]: Copied! <pre>ds.sel(time=\"2014-May\")\n\n# ds.sel(time=\"2014-05\")\n</pre> ds.sel(time=\"2014-May\")  # ds.sel(time=\"2014-05\") Out[34]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 124, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2014-05-01 ... 2014-05-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 264.9 265.0 265.0 ... 296.5 296.2 296.2\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 124</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2014-05-01 ... 2014-05-31T18:00:00standard_name :timelong_name :Time<pre>array(['2014-05-01T00:00:00.000000000', '2014-05-01T06:00:00.000000000',\n       '2014-05-01T12:00:00.000000000', '2014-05-01T18:00:00.000000000',\n       '2014-05-02T00:00:00.000000000', '2014-05-02T06:00:00.000000000',\n       '2014-05-02T12:00:00.000000000', '2014-05-02T18:00:00.000000000',\n       '2014-05-03T00:00:00.000000000', '2014-05-03T06:00:00.000000000',\n       '2014-05-03T12:00:00.000000000', '2014-05-03T18:00:00.000000000',\n       '2014-05-04T00:00:00.000000000', '2014-05-04T06:00:00.000000000',\n       '2014-05-04T12:00:00.000000000', '2014-05-04T18:00:00.000000000',\n       '2014-05-05T00:00:00.000000000', '2014-05-05T06:00:00.000000000',\n       '2014-05-05T12:00:00.000000000', '2014-05-05T18:00:00.000000000',\n       '2014-05-06T00:00:00.000000000', '2014-05-06T06:00:00.000000000',\n       '2014-05-06T12:00:00.000000000', '2014-05-06T18:00:00.000000000',\n       '2014-05-07T00:00:00.000000000', '2014-05-07T06:00:00.000000000',\n       '2014-05-07T12:00:00.000000000', '2014-05-07T18:00:00.000000000',\n       '2014-05-08T00:00:00.000000000', '2014-05-08T06:00:00.000000000',\n       '2014-05-08T12:00:00.000000000', '2014-05-08T18:00:00.000000000',\n       '2014-05-09T00:00:00.000000000', '2014-05-09T06:00:00.000000000',\n       '2014-05-09T12:00:00.000000000', '2014-05-09T18:00:00.000000000',\n       '2014-05-10T00:00:00.000000000', '2014-05-10T06:00:00.000000000',\n       '2014-05-10T12:00:00.000000000', '2014-05-10T18:00:00.000000000',\n       '2014-05-11T00:00:00.000000000', '2014-05-11T06:00:00.000000000',\n       '2014-05-11T12:00:00.000000000', '2014-05-11T18:00:00.000000000',\n       '2014-05-12T00:00:00.000000000', '2014-05-12T06:00:00.000000000',\n       '2014-05-12T12:00:00.000000000', '2014-05-12T18:00:00.000000000',\n       '2014-05-13T00:00:00.000000000', '2014-05-13T06:00:00.000000000',\n       '2014-05-13T12:00:00.000000000', '2014-05-13T18:00:00.000000000',\n       '2014-05-14T00:00:00.000000000', '2014-05-14T06:00:00.000000000',\n       '2014-05-14T12:00:00.000000000', '2014-05-14T18:00:00.000000000',\n       '2014-05-15T00:00:00.000000000', '2014-05-15T06:00:00.000000000',\n       '2014-05-15T12:00:00.000000000', '2014-05-15T18:00:00.000000000',\n       '2014-05-16T00:00:00.000000000', '2014-05-16T06:00:00.000000000',\n       '2014-05-16T12:00:00.000000000', '2014-05-16T18:00:00.000000000',\n       '2014-05-17T00:00:00.000000000', '2014-05-17T06:00:00.000000000',\n       '2014-05-17T12:00:00.000000000', '2014-05-17T18:00:00.000000000',\n       '2014-05-18T00:00:00.000000000', '2014-05-18T06:00:00.000000000',\n       '2014-05-18T12:00:00.000000000', '2014-05-18T18:00:00.000000000',\n       '2014-05-19T00:00:00.000000000', '2014-05-19T06:00:00.000000000',\n       '2014-05-19T12:00:00.000000000', '2014-05-19T18:00:00.000000000',\n       '2014-05-20T00:00:00.000000000', '2014-05-20T06:00:00.000000000',\n       '2014-05-20T12:00:00.000000000', '2014-05-20T18:00:00.000000000',\n       '2014-05-21T00:00:00.000000000', '2014-05-21T06:00:00.000000000',\n       '2014-05-21T12:00:00.000000000', '2014-05-21T18:00:00.000000000',\n       '2014-05-22T00:00:00.000000000', '2014-05-22T06:00:00.000000000',\n       '2014-05-22T12:00:00.000000000', '2014-05-22T18:00:00.000000000',\n       '2014-05-23T00:00:00.000000000', '2014-05-23T06:00:00.000000000',\n       '2014-05-23T12:00:00.000000000', '2014-05-23T18:00:00.000000000',\n       '2014-05-24T00:00:00.000000000', '2014-05-24T06:00:00.000000000',\n       '2014-05-24T12:00:00.000000000', '2014-05-24T18:00:00.000000000',\n       '2014-05-25T00:00:00.000000000', '2014-05-25T06:00:00.000000000',\n       '2014-05-25T12:00:00.000000000', '2014-05-25T18:00:00.000000000',\n       '2014-05-26T00:00:00.000000000', '2014-05-26T06:00:00.000000000',\n       '2014-05-26T12:00:00.000000000', '2014-05-26T18:00:00.000000000',\n       '2014-05-27T00:00:00.000000000', '2014-05-27T06:00:00.000000000',\n       '2014-05-27T12:00:00.000000000', '2014-05-27T18:00:00.000000000',\n       '2014-05-28T00:00:00.000000000', '2014-05-28T06:00:00.000000000',\n       '2014-05-28T12:00:00.000000000', '2014-05-28T18:00:00.000000000',\n       '2014-05-29T00:00:00.000000000', '2014-05-29T06:00:00.000000000',\n       '2014-05-29T12:00:00.000000000', '2014-05-29T18:00:00.000000000',\n       '2014-05-30T00:00:00.000000000', '2014-05-30T06:00:00.000000000',\n       '2014-05-30T12:00:00.000000000', '2014-05-30T18:00:00.000000000',\n       '2014-05-31T00:00:00.000000000', '2014-05-31T06:00:00.000000000',\n       '2014-05-31T12:00:00.000000000', '2014-05-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32264.9 265.0 265.0 ... 296.2 296.2long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[264.9    , 265.     , 265.     , ..., 252.39   , 252.89   ,\n         253.7    ],\n        [272.     , 272.29   , 272.6    , ..., 249.29999, 250.2    ,\n         252.39   ],\n        [274.1    , 274.     , 274.     , ..., 252.39   , 254.89   ,\n         258.69998],\n        ...,\n        [296.6    , 295.69998, 295.79   , ..., 294.5    , 294.19998,\n         293.9    ],\n        [297.79   , 297.4    , 296.9    , ..., 294.79   , 294.69998,\n         294.4    ],\n        [298.1    , 298.4    , 298.     , ..., 295.29   , 295.5    ,\n         295.1    ]],\n\n       [[265.79   , 265.4    , 265.1    , ..., 248.89   , 250.5    ,\n         252.     ],\n        [272.6    , 272.6    , 272.6    , ..., 247.09999, 249.     ,\n         252.09999],\n        [274.     , 274.1    , 274.29   , ..., 247.59999, 250.7    ,\n         255.7    ],\n...\n        [297.4    , 296.79   , 296.4    , ..., 295.79   , 295.     ,\n         294.5    ],\n        [297.4    , 297.19998, 296.29   , ..., 295.9    , 295.69998,\n         295.1    ],\n        [297.79   , 297.6    , 297.29   , ..., 296.1    , 295.9    ,\n         295.79   ]],\n\n       [[267.     , 266.79   , 266.5    , ..., 263.     , 265.     ,\n         267.1    ],\n        [268.9    , 269.29   , 269.4    , ..., 262.6    , 265.1    ,\n         267.9    ],\n        [272.19998, 272.19998, 272.19998, ..., 265.1    , 267.19998,\n         269.79   ],\n        ...,\n        [298.     , 297.69998, 297.19998, ..., 295.9    , 295.19998,\n         294.9    ],\n        [297.9    , 297.9    , 297.4    , ..., 296.29   , 295.9    ,\n         295.4    ],\n        [297.9    , 297.6    , 297.5    , ..., 296.5    , 296.19998,\n         296.19998]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2014-05-01 00:00:00', '2014-05-01 06:00:00',\n               '2014-05-01 12:00:00', '2014-05-01 18:00:00',\n               '2014-05-02 00:00:00', '2014-05-02 06:00:00',\n               '2014-05-02 12:00:00', '2014-05-02 18:00:00',\n               '2014-05-03 00:00:00', '2014-05-03 06:00:00',\n               ...\n               '2014-05-29 12:00:00', '2014-05-29 18:00:00',\n               '2014-05-30 00:00:00', '2014-05-30 06:00:00',\n               '2014-05-30 12:00:00', '2014-05-30 18:00:00',\n               '2014-05-31 00:00:00', '2014-05-31 06:00:00',\n               '2014-05-31 12:00:00', '2014-05-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=124, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[35]: Copied! <pre># This will return a subset of the dataset corresponding to the entire year of 2013.\nds.sel(time=slice('2013-01-01', '2013-12-31'))\n</pre> # This will return a subset of the dataset corresponding to the entire year of 2013. ds.sel(time=slice('2013-01-01', '2013-12-31')) Out[35]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 1460, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2013-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 241.2 242.5 243.5 ... 296.1 295.1 294.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 1460</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2013-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2013-12-31T06:00:00.000000000',\n       '2013-12-31T12:00:00.000000000', '2013-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32241.2 242.5 243.5 ... 295.1 294.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [296.1    , 295.1    , 295.1    , ..., 296.     , 294.69998,\n         293.79   ],\n        [297.     , 296.6    , 296.29   , ..., 295.6    , 294.6    ,\n         293.79   ],\n        [297.4    , 297.4    , 297.19998, ..., 296.1    , 295.     ,\n         294.4    ]],\n\n       [[251.89   , 251.2    , 250.29999, ..., 239.7    , 239.89   ,\n         240.7    ],\n        [252.29999, 253.     , 253.5    , ..., 237.29999, 239.5    ,\n         242.89   ],\n        [249.09999, 250.2    , 251.59999, ..., 243.     , 247.     ,\n         251.89   ],\n        ...,\n        [296.4    , 295.6    , 295.19998, ..., 295.9    , 295.1    ,\n         294.     ],\n        [297.1    , 296.79   , 296.5    , ..., 295.6    , 295.1    ,\n         294.5    ],\n        [297.29   , 297.69998, 297.69998, ..., 296.1    , 295.1    ,\n         294.69998]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2013-12-29 12:00:00', '2013-12-29 18:00:00',\n               '2013-12-30 00:00:00', '2013-12-30 06:00:00',\n               '2013-12-30 12:00:00', '2013-12-30 18:00:00',\n               '2013-12-31 00:00:00', '2013-12-31 06:00:00',\n               '2013-12-31 12:00:00', '2013-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=1460, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>The slice function takes two arguments, start and stop, to make a slice that includes these endpoints. When we use <code>slice</code> with the <code>sel</code> method, it provides an efficient way to select a range of dates. The above example shows the usage of slice for datetime indexing.</p> In\u00a0[36]: Copied! <pre>dates = ['2013-07-09', '2013-10-11', '2013-12-24']\nds.sel(time=dates)\n</pre> dates = ['2013-07-09', '2013-10-11', '2013-12-24'] ds.sel(time=dates) Out[36]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 3, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-07-09 2013-10-11 2013-12-24\nData variables:\n    air      (time, lat, lon) float32 279.0 278.6 278.1 ... 296.8 296.6 296.5\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 3</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-07-09 2013-10-11 2013-12-24standard_name :timelong_name :Time<pre>array(['2013-07-09T00:00:00.000000000', '2013-10-11T00:00:00.000000000',\n       '2013-12-24T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32279.0 278.6 278.1 ... 296.6 296.5long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[279.     , 278.6    , 278.1    , ..., 269.6    , 272.     ,\n         274.5    ],\n        [277.29   , 277.     , 276.5    , ..., 267.4    , 269.29   ,\n         271.69998],\n        [280.5    , 280.69998, 280.5    , ..., 266.69998, 268.19998,\n         270.29   ],\n        ...,\n        [299.6    , 299.1    , 298.4    , ..., 297.1    , 296.79   ,\n         296.     ],\n        [299.19998, 298.9    , 298.5    , ..., 296.69998, 296.79   ,\n         296.5    ],\n        [299.4    , 299.29   , 298.79   , ..., 297.29   , 297.29   ,\n         297.4    ]],\n\n       [[268.4    , 268.19998, 268.1    , ..., 247.09999, 247.09999,\n         247.7    ],\n        [272.69998, 272.6    , 272.6    , ..., 250.     , 250.79999,\n         252.7    ],\n        [270.69998, 269.29   , 268.4    , ..., 255.5    , 257.79   ,\n         261.4    ],\n...\n        [299.1    , 298.5    , 298.1    , ..., 298.4    , 298.1    ,\n         297.4    ],\n        [298.9    , 299.1    , 298.9    , ..., 299.19998, 298.9    ,\n         298.1    ],\n        [298.9    , 299.19998, 299.19998, ..., 299.29   , 299.29   ,\n         299.5    ]],\n\n       [[249.09999, 249.09999, 249.2    , ..., 244.59999, 246.79999,\n         249.5    ],\n        [249.79999, 250.5    , 251.     , ..., 243.89   , 246.     ,\n         249.2    ],\n        [246.29999, 246.39   , 246.79999, ..., 241.09999, 244.5    ,\n         249.09999],\n        ...,\n        [297.5    , 296.69998, 296.19998, ..., 295.     , 294.69998,\n         294.1    ],\n        [298.1    , 297.6    , 297.     , ..., 295.6    , 295.29   ,\n         294.69998],\n        [298.4    , 298.1    , 297.6    , ..., 296.79   , 296.6    ,\n         296.5    ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-07-09', '2013-10-11', '2013-12-24'], dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[37]: Copied! <pre>ds.sel(time=ds.time.dt.month == 7)\n</pre> ds.sel(time=ds.time.dt.month == 7) Out[37]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 248, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-07-01 ... 2014-07-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 273.7 273.0 272.5 ... 297.5 297.6 297.8\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 248</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-07-01 ... 2014-07-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-07-01T00:00:00.000000000', '2013-07-01T06:00:00.000000000',\n       '2013-07-01T12:00:00.000000000', ..., '2014-07-31T06:00:00.000000000',\n       '2014-07-31T12:00:00.000000000', '2014-07-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32273.7 273.0 272.5 ... 297.6 297.8long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[273.69998, 273.     , 272.5    , ..., 265.29   , 266.6    ,\n         268.19998],\n        [275.5    , 275.19998, 274.9    , ..., 265.4    , 267.29   ,\n         269.69998],\n        [285.1    , 286.     , 286.6    , ..., 265.     , 267.4    ,\n         270.6    ],\n        ...,\n        [299.19998, 298.69998, 297.69998, ..., 296.6    , 296.5    ,\n         296.4    ],\n        [298.5    , 298.6    , 298.     , ..., 296.     , 296.1    ,\n         295.9    ],\n        [298.29   , 298.69998, 298.4    , ..., 297.19998, 297.29   ,\n         297.1    ]],\n\n       [[274.     , 273.69998, 273.29   , ..., 261.6    , 263.29   ,\n         265.29   ],\n        [278.4    , 278.6    , 278.5    , ..., 260.     , 262.9    ,\n         266.19998],\n        [286.6    , 287.69998, 288.4    , ..., 260.69998, 264.9    ,\n         269.1    ],\n...\n        [298.79   , 297.79   , 297.29   , ..., 297.9    , 297.     ,\n         296.79   ],\n        [299.4    , 298.79   , 298.4    , ..., 297.4    , 297.19998,\n         297.     ],\n        [299.5    , 299.1    , 298.69998, ..., 297.4    , 297.5    ,\n         297.69998]],\n\n       [[274.     , 273.6    , 273.     , ..., 265.29   , 266.5    ,\n         268.19998],\n        [276.     , 276.     , 275.79   , ..., 265.79   , 267.5    ,\n         269.79   ],\n        [281.6    , 283.1    , 284.4    , ..., 269.4    , 271.5    ,\n         274.1    ],\n        ...,\n        [299.4    , 298.79   , 298.29   , ..., 298.1    , 297.4    ,\n         297.19998],\n        [299.79   , 299.6    , 299.1    , ..., 297.4    , 297.29   ,\n         297.19998],\n        [299.69998, 299.5    , 299.1    , ..., 297.5    , 297.6    ,\n         297.79   ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-07-01 00:00:00', '2013-07-01 06:00:00',\n               '2013-07-01 12:00:00', '2013-07-01 18:00:00',\n               '2013-07-02 00:00:00', '2013-07-02 06:00:00',\n               '2013-07-02 12:00:00', '2013-07-02 18:00:00',\n               '2013-07-03 00:00:00', '2013-07-03 06:00:00',\n               ...\n               '2014-07-29 12:00:00', '2014-07-29 18:00:00',\n               '2014-07-30 00:00:00', '2014-07-30 06:00:00',\n               '2014-07-30 12:00:00', '2014-07-30 18:00:00',\n               '2014-07-31 00:00:00', '2014-07-31 06:00:00',\n               '2014-07-31 12:00:00', '2014-07-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=248, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>Or, if you wanted to select data from a specific day of each month, you could use:</p> In\u00a0[38]: Copied! <pre>ds.sel(time=ds.time.dt.day == 15)\n</pre> ds.sel(time=ds.time.dt.day == 15) Out[38]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 96, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-15 ... 2014-12-15T18:00:00\nData variables:\n    air      (time, lat, lon) float32 243.8 243.4 242.8 ... 297.1 296.9 296.9\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 96</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-15 ... 2014-12-15T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-15T00:00:00.000000000', '2013-01-15T06:00:00.000000000',\n       '2013-01-15T12:00:00.000000000', '2013-01-15T18:00:00.000000000',\n       '2013-02-15T00:00:00.000000000', '2013-02-15T06:00:00.000000000',\n       '2013-02-15T12:00:00.000000000', '2013-02-15T18:00:00.000000000',\n       '2013-03-15T00:00:00.000000000', '2013-03-15T06:00:00.000000000',\n       '2013-03-15T12:00:00.000000000', '2013-03-15T18:00:00.000000000',\n       '2013-04-15T00:00:00.000000000', '2013-04-15T06:00:00.000000000',\n       '2013-04-15T12:00:00.000000000', '2013-04-15T18:00:00.000000000',\n       '2013-05-15T00:00:00.000000000', '2013-05-15T06:00:00.000000000',\n       '2013-05-15T12:00:00.000000000', '2013-05-15T18:00:00.000000000',\n       '2013-06-15T00:00:00.000000000', '2013-06-15T06:00:00.000000000',\n       '2013-06-15T12:00:00.000000000', '2013-06-15T18:00:00.000000000',\n       '2013-07-15T00:00:00.000000000', '2013-07-15T06:00:00.000000000',\n       '2013-07-15T12:00:00.000000000', '2013-07-15T18:00:00.000000000',\n       '2013-08-15T00:00:00.000000000', '2013-08-15T06:00:00.000000000',\n       '2013-08-15T12:00:00.000000000', '2013-08-15T18:00:00.000000000',\n       '2013-09-15T00:00:00.000000000', '2013-09-15T06:00:00.000000000',\n       '2013-09-15T12:00:00.000000000', '2013-09-15T18:00:00.000000000',\n       '2013-10-15T00:00:00.000000000', '2013-10-15T06:00:00.000000000',\n       '2013-10-15T12:00:00.000000000', '2013-10-15T18:00:00.000000000',\n       '2013-11-15T00:00:00.000000000', '2013-11-15T06:00:00.000000000',\n       '2013-11-15T12:00:00.000000000', '2013-11-15T18:00:00.000000000',\n       '2013-12-15T00:00:00.000000000', '2013-12-15T06:00:00.000000000',\n       '2013-12-15T12:00:00.000000000', '2013-12-15T18:00:00.000000000',\n       '2014-01-15T00:00:00.000000000', '2014-01-15T06:00:00.000000000',\n       '2014-01-15T12:00:00.000000000', '2014-01-15T18:00:00.000000000',\n       '2014-02-15T00:00:00.000000000', '2014-02-15T06:00:00.000000000',\n       '2014-02-15T12:00:00.000000000', '2014-02-15T18:00:00.000000000',\n       '2014-03-15T00:00:00.000000000', '2014-03-15T06:00:00.000000000',\n       '2014-03-15T12:00:00.000000000', '2014-03-15T18:00:00.000000000',\n       '2014-04-15T00:00:00.000000000', '2014-04-15T06:00:00.000000000',\n       '2014-04-15T12:00:00.000000000', '2014-04-15T18:00:00.000000000',\n       '2014-05-15T00:00:00.000000000', '2014-05-15T06:00:00.000000000',\n       '2014-05-15T12:00:00.000000000', '2014-05-15T18:00:00.000000000',\n       '2014-06-15T00:00:00.000000000', '2014-06-15T06:00:00.000000000',\n       '2014-06-15T12:00:00.000000000', '2014-06-15T18:00:00.000000000',\n       '2014-07-15T00:00:00.000000000', '2014-07-15T06:00:00.000000000',\n       '2014-07-15T12:00:00.000000000', '2014-07-15T18:00:00.000000000',\n       '2014-08-15T00:00:00.000000000', '2014-08-15T06:00:00.000000000',\n       '2014-08-15T12:00:00.000000000', '2014-08-15T18:00:00.000000000',\n       '2014-09-15T00:00:00.000000000', '2014-09-15T06:00:00.000000000',\n       '2014-09-15T12:00:00.000000000', '2014-09-15T18:00:00.000000000',\n       '2014-10-15T00:00:00.000000000', '2014-10-15T06:00:00.000000000',\n       '2014-10-15T12:00:00.000000000', '2014-10-15T18:00:00.000000000',\n       '2014-11-15T00:00:00.000000000', '2014-11-15T06:00:00.000000000',\n       '2014-11-15T12:00:00.000000000', '2014-11-15T18:00:00.000000000',\n       '2014-12-15T00:00:00.000000000', '2014-12-15T06:00:00.000000000',\n       '2014-12-15T12:00:00.000000000', '2014-12-15T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32243.8 243.4 242.8 ... 296.9 296.9long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[243.79999, 243.39   , 242.79999, ..., 232.59999, 233.2    ,\n         234.7    ],\n        [247.     , 246.79999, 246.2    , ..., 233.7    , 233.89   ,\n         236.     ],\n        [261.5    , 260.9    , 259.6    , ..., 236.39   , 238.89   ,\n         243.39   ],\n        ...,\n        [296.5    , 297.29   , 297.6    , ..., 297.1    , 296.6    ,\n         295.4    ],\n        [297.5    , 297.9    , 297.4    , ..., 297.1    , 297.     ,\n         295.79   ],\n        [297.79   , 298.19998, 298.     , ..., 297.5    , 297.19998,\n         296.6    ]],\n\n       [[244.09999, 243.59999, 242.79999, ..., 234.29999, 234.79999,\n         235.79999],\n        [246.7    , 246.5    , 246.09999, ..., 236.5    , 236.29999,\n         237.59999],\n        [258.1    , 258.5    , 258.6    , ..., 239.09999, 240.89   ,\n         244.2    ],\n...\n        [296.79   , 295.79   , 295.38998, ..., 295.79   , 295.19998,\n         295.     ],\n        [297.79   , 297.5    , 297.     , ..., 295.79   , 295.6    ,\n         295.29   ],\n        [298.29   , 298.19998, 298.     , ..., 296.6    , 296.19998,\n         296.1    ]],\n\n       [[244.5    , 243.79999, 243.     , ..., 236.39   , 237.79999,\n         240.     ],\n        [243.89   , 244.68999, 245.29999, ..., 230.89   , 231.69   ,\n         234.79999],\n        [243.29999, 243.29999, 243.5    , ..., 232.29999, 233.09999,\n         237.09999],\n        ...,\n        [296.79   , 295.69998, 295.29   , ..., 296.29   , 295.79   ,\n         295.29   ],\n        [298.1    , 297.38998, 296.88998, ..., 296.29   , 296.1    ,\n         295.88998],\n        [298.38998, 298.38998, 298.19998, ..., 297.1    , 296.88998,\n         296.88998]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-15 00:00:00', '2013-01-15 06:00:00',\n               '2013-01-15 12:00:00', '2013-01-15 18:00:00',\n               '2013-02-15 00:00:00', '2013-02-15 06:00:00',\n               '2013-02-15 12:00:00', '2013-02-15 18:00:00',\n               '2013-03-15 00:00:00', '2013-03-15 06:00:00',\n               '2013-03-15 12:00:00', '2013-03-15 18:00:00',\n               '2013-04-15 00:00:00', '2013-04-15 06:00:00',\n               '2013-04-15 12:00:00', '2013-04-15 18:00:00',\n               '2013-05-15 00:00:00', '2013-05-15 06:00:00',\n               '2013-05-15 12:00:00', '2013-05-15 18:00:00',\n               '2013-06-15 00:00:00', '2013-06-15 06:00:00',\n               '2013-06-15 12:00:00', '2013-06-15 18:00:00',\n               '2013-07-15 00:00:00', '2013-07-15 06:00:00',\n               '2013-07-15 12:00:00', '2013-07-15 18:00:00',\n               '2013-08-15 00:00:00', '2013-08-15 06:00:00',\n               '2013-08-15 12:00:00', '2013-08-15 18:00:00',\n               '2013-09-15 00:00:00', '2013-09-15 06:00:00',\n               '2013-09-15 12:00:00', '2013-09-15 18:00:00',\n               '2013-10-15 00:00:00', '2013-10-15 06:00:00',\n               '2013-10-15 12:00:00', '2013-10-15 18:00:00',\n               '2013-11-15 00:00:00', '2013-11-15 06:00:00',\n               '2013-11-15 12:00:00', '2013-11-15 18:00:00',\n               '2013-12-15 00:00:00', '2013-12-15 06:00:00',\n               '2013-12-15 12:00:00', '2013-12-15 18:00:00',\n               '2014-01-15 00:00:00', '2014-01-15 06:00:00',\n               '2014-01-15 12:00:00', '2014-01-15 18:00:00',\n               '2014-02-15 00:00:00', '2014-02-15 06:00:00',\n               '2014-02-15 12:00:00', '2014-02-15 18:00:00',\n               '2014-03-15 00:00:00', '2014-03-15 06:00:00',\n               '2014-03-15 12:00:00', '2014-03-15 18:00:00',\n               '2014-04-15 00:00:00', '2014-04-15 06:00:00',\n               '2014-04-15 12:00:00', '2014-04-15 18:00:00',\n               '2014-05-15 00:00:00', '2014-05-15 06:00:00',\n               '2014-05-15 12:00:00', '2014-05-15 18:00:00',\n               '2014-06-15 00:00:00', '2014-06-15 06:00:00',\n               '2014-06-15 12:00:00', '2014-06-15 18:00:00',\n               '2014-07-15 00:00:00', '2014-07-15 06:00:00',\n               '2014-07-15 12:00:00', '2014-07-15 18:00:00',\n               '2014-08-15 00:00:00', '2014-08-15 06:00:00',\n               '2014-08-15 12:00:00', '2014-08-15 18:00:00',\n               '2014-09-15 00:00:00', '2014-09-15 06:00:00',\n               '2014-09-15 12:00:00', '2014-09-15 18:00:00',\n               '2014-10-15 00:00:00', '2014-10-15 06:00:00',\n               '2014-10-15 12:00:00', '2014-10-15 18:00:00',\n               '2014-11-15 00:00:00', '2014-11-15 06:00:00',\n               '2014-11-15 12:00:00', '2014-11-15 18:00:00',\n               '2014-12-15 00:00:00', '2014-12-15 06:00:00',\n               '2014-12-15 12:00:00', '2014-12-15 18:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>Similar to Pandas, xarray supports different kinds of arithmetic operations</p> In\u00a0[39]: Copied! <pre>ds['air_C'] = ds['air'] - 273.15\n</pre> ds['air_C'] = ds['air'] - 273.15 In\u00a0[40]: Copied! <pre>ds['air_C']\n</pre> ds['air_C'] Out[40]: <pre>&lt;xarray.DataArray 'air_C' (time: 2920, lat: 25, lon: 53)&gt;\narray([[[-31.949997, -30.649994, -29.649994, ..., -40.350006,\n         -37.649994, -34.550003],\n        [-29.350006, -28.649994, -28.449997, ..., -40.350006,\n         -37.850006, -33.850006],\n        [-23.149994, -23.350006, -24.259995, ..., -39.949997,\n         -36.759995, -31.449997],\n        ...,\n        [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,\n          21.950012,  21.549988],\n        [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,\n          22.75    ,  22.049988],\n        [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,\n          23.640015,  23.450012]],\n\n       [[-31.050003, -30.449997, -30.050003, ..., -41.149994,\n         -39.550003, -37.350006],\n        [-29.550003, -29.050003, -28.949997, ..., -42.149994,\n         -40.649994, -37.449997],\n        [-19.949997, -20.259995, -21.050003, ..., -42.350006,\n         -39.759995, -34.649994],\n...\n        [ 20.540009,  20.73999 ,  22.23999 , ...,  21.940002,\n          21.540009,  21.140015],\n        [ 23.140015,  24.040009,  24.440002, ...,  22.140015,\n          21.940002,  21.23999 ],\n        [ 24.640015,  25.23999 ,  25.339996, ...,  22.540009,\n          22.339996,  22.040009]],\n\n       [[-28.059998, -28.86    , -29.86    , ..., -31.460007,\n         -31.660004, -31.36    ],\n        [-23.259995, -23.86    , -24.759995, ..., -33.559998,\n         -32.86    , -31.460007],\n        [-10.160004, -10.959991, -11.76001 , ..., -33.259995,\n         -30.559998, -26.86    ],\n        ...,\n        [ 20.640015,  20.540009,  21.940002, ...,  22.140015,\n          21.940002,  21.540009],\n        [ 22.940002,  23.73999 ,  24.040009, ...,  22.540009,\n          22.540009,  22.040009],\n        [ 24.540009,  24.940002,  24.940002, ...,  23.339996,\n          23.040009,  22.540009]]], dtype=float32)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00</pre>xarray.DataArray'air_C'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 53</li></ul><ul><li>-31.95 -30.65 -29.65 -29.15 -29.05 ... 24.24 24.04 23.34 23.04 22.54<pre>array([[[-31.949997, -30.649994, -29.649994, ..., -40.350006,\n         -37.649994, -34.550003],\n        [-29.350006, -28.649994, -28.449997, ..., -40.350006,\n         -37.850006, -33.850006],\n        [-23.149994, -23.350006, -24.259995, ..., -39.949997,\n         -36.759995, -31.449997],\n        ...,\n        [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,\n          21.950012,  21.549988],\n        [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,\n          22.75    ,  22.049988],\n        [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,\n          23.640015,  23.450012]],\n\n       [[-31.050003, -30.449997, -30.050003, ..., -41.149994,\n         -39.550003, -37.350006],\n        [-29.550003, -29.050003, -28.949997, ..., -42.149994,\n         -40.649994, -37.449997],\n        [-19.949997, -20.259995, -21.050003, ..., -42.350006,\n         -39.759995, -34.649994],\n...\n        [ 20.540009,  20.73999 ,  22.23999 , ...,  21.940002,\n          21.540009,  21.140015],\n        [ 23.140015,  24.040009,  24.440002, ...,  22.140015,\n          21.940002,  21.23999 ],\n        [ 24.640015,  25.23999 ,  25.339996, ...,  22.540009,\n          22.339996,  22.040009]],\n\n       [[-28.059998, -28.86    , -29.86    , ..., -31.460007,\n         -31.660004, -31.36    ],\n        [-23.259995, -23.86    , -24.759995, ..., -33.559998,\n         -32.86    , -31.460007],\n        [-10.160004, -10.959991, -11.76001 , ..., -33.259995,\n         -30.559998, -26.86    ],\n        ...,\n        [ 20.640015,  20.540009,  21.940002, ...,  22.140015,\n          21.940002,  21.540009],\n        [ 22.940002,  23.73999 ,  24.040009, ...,  22.540009,\n          22.540009,  22.040009],\n        [ 24.540009,  24.940002,  24.940002, ...,  23.339996,\n          23.040009,  22.540009]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[41]: Copied! <pre># Generate a boolean mask where temperature is higher than 0\u02daC\nds['air_C'] &gt;  0\n</pre> # Generate a boolean mask where temperature is higher than 0\u02daC ds['air_C'] &gt;  0  Out[41]: <pre>&lt;xarray.DataArray 'air_C' (time: 2920, lat: 25, lon: 53)&gt;\narray([[[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n...\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]]])\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00</pre>xarray.DataArray'air_C'<ul><li>time: 2920</li><li>lat: 25</li><li>lon: 53</li></ul><ul><li>False False False False False False ... True True True True True True<pre>array([[[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n...\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]],\n\n       [[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True],\n        [ True,  True,  True, ...,  True,  True,  True]]])</pre></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[42]: Copied! <pre># Generate a boolean mask where long-term mean temperature is higher than 0\u02daC\nds['air_C'].mean(dim='time') &gt;  0\n</pre> # Generate a boolean mask where long-term mean temperature is higher than 0\u02daC ds['air_C'].mean(dim='time') &gt;  0  Out[42]: <pre>&lt;xarray.DataArray 'air_C' (lat: 25, lon: 53)&gt;\narray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True]])\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0</pre>xarray.DataArray'air_C'<ul><li>lat: 25</li><li>lon: 53</li></ul><ul><li>False False False False False False ... True True True True True True<pre>array([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True],\n       [ True,  True,  True, ...,  True,  True,  True]])</pre></li><li>Coordinates: (2)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li></ul></li><li>Indexes: (2)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[43]: Copied! <pre>(ds['air_C'].mean(dim='time') &gt;  0).plot()\n</pre> (ds['air_C'].mean(dim='time') &gt;  0).plot() Out[43]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194bbaa30&gt;</pre> In\u00a0[44]: Copied! <pre># Apply the mask:\nds.where(ds['air_C'].mean(dim='time') &gt;  0).mean(dim = 'time').air.plot()\n</pre> # Apply the mask: ds.where(ds['air_C'].mean(dim='time') &gt;  0).mean(dim = 'time').air.plot() Out[44]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194c9b100&gt;</pre> In\u00a0[45]: Copied! <pre>ds['air_C'].mean(dim='time').plot()\n</pre> ds['air_C'].mean(dim='time').plot() Out[45]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194dd1130&gt;</pre> In\u00a0[46]: Copied! <pre>(ds['air_C'].mean(dim='time')*np.cos(np.deg2rad(ds.lat))).plot()\n</pre> (ds['air_C'].mean(dim='time')*np.cos(np.deg2rad(ds.lat))).plot() Out[46]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194e8ccd0&gt;</pre> In\u00a0[47]: Copied! <pre># Make cos(lat) two dimensional\n(xr.ones_like(ds['air_C'].mean(dim='time'))*np.cos(np.deg2rad(ds.lat))).plot()\n</pre> # Make cos(lat) two dimensional (xr.ones_like(ds['air_C'].mean(dim='time'))*np.cos(np.deg2rad(ds.lat))).plot() Out[47]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194f7a3d0&gt;</pre> In\u00a0[48]: Copied! <pre># Make cos(lat) two dimensional\n(np.cos(np.deg2rad(ds.lat))*xr.ones_like(ds.lon)).plot()\n</pre> # Make cos(lat) two dimensional (np.cos(np.deg2rad(ds.lat))*xr.ones_like(ds.lon)).plot() Out[48]: <pre>&lt;matplotlib.collections.QuadMesh at 0x194aa2f10&gt;</pre> In\u00a0[49]: Copied! <pre># here's ds\nds\n</pre> # here's ds ds Out[49]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 241.2 242.5 243.5 ... 296.5 296.2 295.7\n    air_C    (time, lat, lon) float32 -31.95 -30.65 -29.65 ... 23.34 23.04 22.54\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 2920</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32241.2 242.5 243.5 ... 296.2 295.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li><li>air_C(time, lat, lon)float32-31.95 -30.65 ... 23.04 22.54<pre>array([[[-31.949997, -30.649994, -29.649994, ..., -40.350006,\n         -37.649994, -34.550003],\n        [-29.350006, -28.649994, -28.449997, ..., -40.350006,\n         -37.850006, -33.850006],\n        [-23.149994, -23.350006, -24.259995, ..., -39.949997,\n         -36.759995, -31.449997],\n        ...,\n        [ 23.450012,  23.049988,  23.25    , ...,  22.25    ,\n          21.950012,  21.549988],\n        [ 22.75    ,  23.049988,  23.640015, ...,  22.75    ,\n          22.75    ,  22.049988],\n        [ 23.140015,  23.640015,  23.950012, ...,  23.75    ,\n          23.640015,  23.450012]],\n\n       [[-31.050003, -30.449997, -30.050003, ..., -41.149994,\n         -39.550003, -37.350006],\n        [-29.550003, -29.050003, -28.949997, ..., -42.149994,\n         -40.649994, -37.449997],\n        [-19.949997, -20.259995, -21.050003, ..., -42.350006,\n         -39.759995, -34.649994],\n...\n        [ 20.540009,  20.73999 ,  22.23999 , ...,  21.940002,\n          21.540009,  21.140015],\n        [ 23.140015,  24.040009,  24.440002, ...,  22.140015,\n          21.940002,  21.23999 ],\n        [ 24.640015,  25.23999 ,  25.339996, ...,  22.540009,\n          22.339996,  22.040009]],\n\n       [[-28.059998, -28.86    , -29.86    , ..., -31.460007,\n         -31.660004, -31.36    ],\n        [-23.259995, -23.86    , -24.759995, ..., -33.559998,\n         -32.86    , -31.460007],\n        [-10.160004, -10.959991, -11.76001 , ..., -33.259995,\n         -30.559998, -26.86    ],\n        ...,\n        [ 20.640015,  20.540009,  21.940002, ...,  22.140015,\n          21.940002,  21.540009],\n        [ 22.940002,  23.73999 ,  24.040009, ...,  22.540009,\n          22.540009,  22.040009],\n        [ 24.540009,  24.940002,  24.940002, ...,  23.339996,\n          23.040009,  22.540009]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[50]: Copied! <pre># seasonal groups\nds.groupby(\"time.season\")\n</pre> # seasonal groups ds.groupby(\"time.season\") Out[50]: <pre>DatasetGroupBy, grouped over 'season'\n4 groups with labels 'DJF', 'JJA', 'MAM', 'SON'.</pre> In\u00a0[51]: Copied! <pre># make a seasonal mean\nseasonal_mean = ds.groupby(\"time.season\").mean()\nseasonal_mean\n</pre> # make a seasonal mean seasonal_mean = ds.groupby(\"time.season\").mean() seasonal_mean Out[51]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, season: 4, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * season   (season) object 'DJF' 'JJA' 'MAM' 'SON'\nData variables:\n    air      (season, lat, lon) float32 247.0 247.0 246.7 ... 299.4 299.4 299.5\n    air_C    (season, lat, lon) float32 -26.14 -26.19 -26.43 ... 26.22 26.32\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>season: 4</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>season(season)object'DJF' 'JJA' 'MAM' 'SON'<pre>array(['DJF', 'JJA', 'MAM', 'SON'], dtype=object)</pre></li></ul></li><li>Data variables: (2)<ul><li>air(season, lat, lon)float32247.0 247.0 246.7 ... 299.4 299.5long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[247.01007, 246.95503, 246.71684, ..., 241.55386, 242.69449,\n         244.23262],\n        [248.83022, 248.98196, 248.93813, ..., 240.31064, 242.24562,\n         245.32053],\n        [250.95328, 250.49544, 250.07674, ..., 241.26309, 244.65495,\n         249.44342],\n        ...,\n        [296.19055, 295.5512 , 295.43677, ..., 295.39368, 294.8794 ,\n         294.33405],\n        [296.939  , 296.83542, 296.46448, ..., 295.6107 , 295.42157,\n         294.959  ],\n        [297.4473 , 297.49   , 297.24048, ..., 296.29694, 296.13766,\n         296.05698]],\n\n       [[273.39032, 273.2029 , 273.011  , ..., 264.78116, 266.19952,\n         267.94702],\n        [274.33145, 274.48965, 274.63034, ..., 263.89758, 265.93015,\n         268.56693],\n        [278.7285 , 279.0914 , 279.4369 , ..., 264.95203, 267.38788,\n         270.48755],\n...\n        [296.76483, 296.2117 , 295.9462 , ..., 295.5077 , 294.8774 ,\n         294.3801 ],\n        [297.43817, 297.3017 , 296.8633 , ..., 295.5603 , 295.31448,\n         294.91473],\n        [297.8931 , 297.9006 , 297.60345, ..., 295.88574, 295.74725,\n         295.72275]],\n\n       [[261.96924, 261.61057, 261.15253, ..., 248.58957, 249.53653,\n         250.96701],\n        [267.2477 , 267.07742, 266.83246, ..., 247.14966, 248.85371,\n         251.75676],\n        [268.2268 , 266.99548, 266.33118, ..., 247.50015, 250.78438,\n         255.50696],\n        ...,\n        [298.80624, 298.0542 , 297.75958, ..., 298.73898, 298.367  ,\n         297.99283],\n        [299.2114 , 299.02353, 298.54553, ..., 298.85175, 298.93045,\n         298.72104],\n        [299.21207, 299.26212, 299.0019 , ..., 299.36758, 299.37134,\n         299.47427]]], dtype=float32)</pre></li><li>air_C(season, lat, lon)float32-26.14 -26.19 ... 26.22 26.32<pre>array([[[-26.13999   , -26.194775  , -26.43317   , ..., -31.596172  ,\n         -30.455513  , -28.917418  ],\n        [-24.319826  , -24.168097  , -24.211771  , ..., -32.839237  ,\n         -30.904285  , -27.829481  ],\n        [-22.196844  , -22.654673  , -23.073437  , ..., -31.886757  ,\n         -28.495083  , -23.706408  ],\n        ...,\n        [ 23.039928  ,  22.400595  ,  22.286192  , ...,  22.242882  ,\n          21.72881   ,  21.183443  ],\n        [ 23.788368  ,  23.684774  ,  23.313797  , ...,  22.459927  ,\n          22.27082   ,  21.808601  ],\n        [ 24.29653   ,  24.339394  ,  24.089901  , ...,  23.14633   ,\n          22.987143  ,  22.906038  ]],\n\n       [[  0.23956957,   0.05219144,  -0.13998248, ...,  -8.369579  ,\n          -6.951163  ,  -5.2037587 ],\n        [  1.180723  ,   1.3389578 ,   1.4795684 , ...,  -9.2531    ,\n          -7.22022   ,  -4.583697  ],\n        [  5.577762  ,   5.9407234 ,   6.286212  , ...,  -8.1986685 ,\n          -5.7628355 ,  -2.6633291 ],\n...\n        [ 23.614012  ,  23.060812  ,  22.795355  , ...,  22.356813  ,\n          21.726547  ,  21.229237  ],\n        [ 24.287266  ,  24.150602  ,  23.712402  , ...,  22.409357  ,\n          22.16376   ,  21.763842  ],\n        [ 24.742495  ,  24.749857  ,  24.452438  , ...,  22.734667  ,\n          22.596312  ,  22.571692  ]],\n\n       [[-11.181002  , -11.5395    , -11.997769  , ..., -24.560495  ,\n         -23.613464  , -22.18285   ],\n        [ -5.9028273 ,  -6.072874  ,  -6.3179007 , ..., -26.00037   ,\n         -24.296288  , -21.393293  ],\n        [ -4.923568  ,  -6.1548376 ,  -6.819064  , ..., -25.649801  ,\n         -22.365923  , -17.643177  ],\n        ...,\n        [ 25.655682  ,  24.903734  ,  24.609102  , ...,  25.588436  ,\n          25.216568  ,  24.842041  ],\n        [ 26.060581  ,  25.872908  ,  25.394646  , ...,  25.701126  ,\n          25.779886  ,  25.570583  ],\n        [ 26.061464  ,  26.111534  ,  25.851294  , ...,  26.217041  ,\n          26.220764  ,  26.323593  ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>seasonPandasIndex<pre>PandasIndex(Index(['DJF', 'JJA', 'MAM', 'SON'], dtype='object', name='season'))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> <p>The seasons are out of order (they are alphabetically sorted). This is a common annoyance. The solution is to use <code>.sel</code> to change the order of labels</p> In\u00a0[52]: Copied! <pre>seasonal_mean = seasonal_mean.sel(season=[\"DJF\", \"MAM\", \"JJA\", \"SON\"])\nseasonal_mean\n</pre> seasonal_mean = seasonal_mean.sel(season=[\"DJF\", \"MAM\", \"JJA\", \"SON\"]) seasonal_mean Out[52]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, season: 4, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * season   (season) object 'DJF' 'MAM' 'JJA' 'SON'\nData variables:\n    air      (season, lat, lon) float32 247.0 247.0 246.7 ... 299.4 299.4 299.5\n    air_C    (season, lat, lon) float32 -26.14 -26.19 -26.43 ... 26.22 26.32\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>season: 4</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>season(season)object'DJF' 'MAM' 'JJA' 'SON'<pre>array(['DJF', 'MAM', 'JJA', 'SON'], dtype=object)</pre></li></ul></li><li>Data variables: (2)<ul><li>air(season, lat, lon)float32247.0 247.0 246.7 ... 299.4 299.5long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[247.01007, 246.95503, 246.71684, ..., 241.55386, 242.69449,\n         244.23262],\n        [248.83022, 248.98196, 248.93813, ..., 240.31064, 242.24562,\n         245.32053],\n        [250.95328, 250.49544, 250.07674, ..., 241.26309, 244.65495,\n         249.44342],\n        ...,\n        [296.19055, 295.5512 , 295.43677, ..., 295.39368, 294.8794 ,\n         294.33405],\n        [296.939  , 296.83542, 296.46448, ..., 295.6107 , 295.42157,\n         294.959  ],\n        [297.4473 , 297.49   , 297.24048, ..., 296.29694, 296.13766,\n         296.05698]],\n\n       [[258.86465, 258.69296, 258.3957 , ..., 248.1146 , 249.09572,\n         250.37955],\n        [260.2769 , 260.37476, 260.3422 , ..., 247.43277, 249.08131,\n         251.56924],\n        [260.90564, 260.45697, 260.12427, ..., 248.48018, 251.28386,\n         255.22194],\n...\n        [298.82135, 297.98038, 297.3638 , ..., 297.59656, 297.0226 ,\n         296.5534 ],\n        [298.91702, 298.57843, 298.001  , ..., 297.41306, 297.43808,\n         297.17545],\n        [298.90414, 298.88306, 298.6041 , ..., 297.80478, 297.87   ,\n         297.96603]],\n\n       [[261.96924, 261.61057, 261.15253, ..., 248.58957, 249.53653,\n         250.96701],\n        [267.2477 , 267.07742, 266.83246, ..., 247.14966, 248.85371,\n         251.75676],\n        [268.2268 , 266.99548, 266.33118, ..., 247.50015, 250.78438,\n         255.50696],\n        ...,\n        [298.80624, 298.0542 , 297.75958, ..., 298.73898, 298.367  ,\n         297.99283],\n        [299.2114 , 299.02353, 298.54553, ..., 298.85175, 298.93045,\n         298.72104],\n        [299.21207, 299.26212, 299.0019 , ..., 299.36758, 299.37134,\n         299.47427]]], dtype=float32)</pre></li><li>air_C(season, lat, lon)float32-26.14 -26.19 ... 26.22 26.32<pre>array([[[-26.13999   , -26.194775  , -26.43317   , ..., -31.596172  ,\n         -30.455513  , -28.917418  ],\n        [-24.319826  , -24.168097  , -24.211771  , ..., -32.839237  ,\n         -30.904285  , -27.829481  ],\n        [-22.196844  , -22.654673  , -23.073437  , ..., -31.886757  ,\n         -28.495083  , -23.706408  ],\n        ...,\n        [ 23.039928  ,  22.400595  ,  22.286192  , ...,  22.242882  ,\n          21.72881   ,  21.183443  ],\n        [ 23.788368  ,  23.684774  ,  23.313797  , ...,  22.459927  ,\n          22.27082   ,  21.808601  ],\n        [ 24.29653   ,  24.339394  ,  24.089901  , ...,  23.14633   ,\n          22.987143  ,  22.906038  ]],\n\n       [[-14.286038  , -14.457757  , -14.755094  , ..., -25.035625  ,\n         -24.054403  , -22.770765  ],\n        [-12.873715  , -12.775794  , -12.80842   , ..., -25.717266  ,\n         -24.068861  , -21.581238  ],\n        [-12.245043  , -12.693659  , -13.026268  , ..., -24.670092  ,\n         -21.866636  , -17.9285    ],\n...\n        [ 25.670477  ,  24.829489  ,  24.212788  , ...,  24.445515  ,\n          23.871685  ,  23.40229   ],\n        [ 25.766272  ,  25.427404  ,  24.850374  , ...,  24.262072  ,\n          24.287355  ,  24.0246    ],\n        [ 25.753113  ,  25.732016  ,  25.453396  , ...,  24.653965  ,\n          24.719198  ,  24.815287  ]],\n\n       [[-11.181002  , -11.5395    , -11.997769  , ..., -24.560495  ,\n         -23.613464  , -22.18285   ],\n        [ -5.9028273 ,  -6.072874  ,  -6.3179007 , ..., -26.00037   ,\n         -24.296288  , -21.393293  ],\n        [ -4.923568  ,  -6.1548376 ,  -6.819064  , ..., -25.649801  ,\n         -22.365923  , -17.643177  ],\n        ...,\n        [ 25.655682  ,  24.903734  ,  24.609102  , ...,  25.588436  ,\n          25.216568  ,  24.842041  ],\n        [ 26.060581  ,  25.872908  ,  25.394646  , ...,  25.701126  ,\n          25.779886  ,  25.570583  ],\n        [ 26.061464  ,  26.111534  ,  25.851294  , ...,  26.217041  ,\n          26.220764  ,  26.323593  ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>seasonPandasIndex<pre>PandasIndex(Index(['DJF', 'MAM', 'JJA', 'SON'], dtype='object', name='season'))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[53]: Copied! <pre>seasonal_mean.air.plot(col=\"season\")\n</pre> seasonal_mean.air.plot(col=\"season\") Out[53]: <pre>&lt;xarray.plot.facetgrid.FacetGrid at 0x1950926a0&gt;</pre> In\u00a0[54]: Copied! <pre># Make the figure to 2x2 plots:\n\n# facet the seasonal_mean\nseasonal_mean.air.plot(col=\"season\", col_wrap=2);\n</pre> # Make the figure to 2x2 plots:  # facet the seasonal_mean seasonal_mean.air.plot(col=\"season\", col_wrap=2); In\u00a0[55]: Copied! <pre># Calculate zonal average\nseasonal_mean.air.mean(\"lon\").plot.line(hue=\"season\", y=\"lat\");\n</pre> # Calculate zonal average seasonal_mean.air.mean(\"lon\").plot.line(hue=\"season\", y=\"lat\"); In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[56]: Copied! <pre># resample to monthly frequency\nds.resample(time=\"M\").mean()\n</pre> # resample to monthly frequency ds.resample(time=\"M\").mean() Out[56]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 24, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-31 2013-02-28 ... 2014-12-31\nData variables:\n    air      (time, lat, lon) float32 244.5 244.7 244.7 ... 297.7 297.7 297.7\n    air_C    (time, lat, lon) float32 -28.68 -28.49 -28.48 ... 24.55 24.57 24.56\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 24</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-31 ... 2014-12-31standard_name :timelong_name :Time<pre>array(['2013-01-31T00:00:00.000000000', '2013-02-28T00:00:00.000000000',\n       '2013-03-31T00:00:00.000000000', '2013-04-30T00:00:00.000000000',\n       '2013-05-31T00:00:00.000000000', '2013-06-30T00:00:00.000000000',\n       '2013-07-31T00:00:00.000000000', '2013-08-31T00:00:00.000000000',\n       '2013-09-30T00:00:00.000000000', '2013-10-31T00:00:00.000000000',\n       '2013-11-30T00:00:00.000000000', '2013-12-31T00:00:00.000000000',\n       '2014-01-31T00:00:00.000000000', '2014-02-28T00:00:00.000000000',\n       '2014-03-31T00:00:00.000000000', '2014-04-30T00:00:00.000000000',\n       '2014-05-31T00:00:00.000000000', '2014-06-30T00:00:00.000000000',\n       '2014-07-31T00:00:00.000000000', '2014-08-31T00:00:00.000000000',\n       '2014-09-30T00:00:00.000000000', '2014-10-31T00:00:00.000000000',\n       '2014-11-30T00:00:00.000000000', '2014-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (2)<ul><li>air(time, lat, lon)float32244.5 244.7 244.7 ... 297.7 297.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]new_attr :xarray<pre>array([[[244.4667 , 244.66354, 244.67027, ..., 242.49142, 243.40633,\n         244.67577],\n        [247.07323, 247.02248, 246.7275 , ..., 240.58205, 242.04489,\n         244.70726],\n        [250.37941, 249.83484, 249.10748, ..., 241.98434, 244.76712,\n         249.00505],\n        ...,\n        [295.83795, 295.15085, 294.9229 , ..., 295.36826, 294.88437,\n         294.26828],\n        [296.46942, 296.31686, 295.84802, ..., 295.5876 , 295.34058,\n         294.86536],\n        [297.05316, 297.0418 , 296.73517, ..., 296.30438, 296.09732,\n         296.0389 ]],\n\n       [[240.73384, 240.7013 , 240.4115 , ..., 241.60518, 242.71988,\n         243.94455],\n        [241.93309, 242.06935, 241.913  , ..., 241.01428, 242.32481,\n         244.72758],\n        [245.32361, 245.0261 , 244.36955, ..., 243.41588, 245.7661 ,\n         249.65858],\n...\n        [298.04895, 297.35007, 297.22195, ..., 298.01172, 297.66013,\n         297.14554],\n        [298.96484, 298.81186, 298.27136, ..., 298.10403, 298.22104,\n         297.88547],\n        [299.17334, 299.2175 , 298.89566, ..., 298.71625, 298.74167,\n         298.7802 ]],\n\n       [[246.80156, 246.88907, 246.76907, ..., 240.07089, 241.08206,\n         242.2817 ],\n        [247.72998, 248.30064, 248.74443, ..., 238.61859, 240.3222 ,\n         242.97026],\n        [249.96893, 249.58516, 249.57521, ..., 237.70308, 241.23743,\n         246.22667],\n        ...,\n        [296.4491 , 295.6914 , 295.75824, ..., 296.52817, 296.21747,\n         295.8128 ],\n        [297.44586, 297.43613, 297.1817 , ..., 296.95242, 297.05823,\n         296.72897],\n        [298.0472 , 298.22598, 298.0595 , ..., 297.6975 , 297.72318,\n         297.71024]]], dtype=float32)</pre></li><li>air_C(time, lat, lon)float32-28.68 -28.49 ... 24.57 24.56<pre>array([[[-28.68323  , -28.486452 , -28.479755 , ..., -30.658554 ,\n         -29.743628 , -28.474194 ],\n        [-26.076784 , -26.127504 , -26.4225   , ..., -32.5679   ,\n         -31.105167 , -28.442825 ],\n        [-22.770565 , -23.31516  , -24.042498 , ..., -31.165657 ,\n         -28.38291  , -24.144924 ],\n        ...,\n        [ 22.688152 ,  22.00097  ,  21.773153 , ...,  22.218397 ,\n          21.734531 ,  21.118395 ],\n        [ 23.31952  ,  23.16702  ,  22.698233 , ...,  22.43775  ,\n          22.190727 ,  21.715578 ],\n        [ 23.903486 ,  23.89203  ,  23.585333 , ...,  23.154608 ,\n          22.947426 ,  22.889124 ]],\n\n       [[-32.41607  , -32.44866  , -32.738483 , ..., -31.54482  ,\n         -30.430185 , -29.205448 ],\n        [-31.216885 , -31.08063  , -31.236965 , ..., -32.135708 ,\n         -30.825186 , -28.42241  ],\n        [-27.826433 , -28.123934 , -28.78045  , ..., -29.734114 ,\n         -27.383936 , -23.491434 ],\n...\n        [ 24.899088 ,  24.200085 ,  24.072004 , ...,  24.861843 ,\n          24.510258 ,  23.995668 ],\n        [ 25.815008 ,  25.661922 ,  25.121607 , ...,  24.954088 ,\n          25.071083 ,  24.735588 ],\n        [ 26.023424 ,  26.06767  ,  25.74576  , ...,  25.566338 ,\n          25.591848 ,  25.630259 ]],\n\n       [[-26.348473 , -26.260897 , -26.380894 , ..., -33.07903  ,\n         -32.067986 , -30.868315 ],\n        [-25.419994 , -24.849277 , -24.405483 , ..., -34.531376 ,\n         -32.82783  , -30.179682 ],\n        [-23.181051 , -23.56476  , -23.574757 , ..., -35.446938 ,\n         -31.91259  , -26.923311 ],\n        ...,\n        [ 23.299198 ,  22.541454 ,  22.60839  , ...,  23.378307 ,\n          23.067505 ,  22.662996 ],\n        [ 24.295895 ,  24.286139 ,  24.031782 , ...,  23.80259  ,\n          23.908312 ,  23.579037 ],\n        [ 24.897346 ,  25.076134 ,  24.909689 , ...,  24.547583 ,\n          24.573233 ,  24.560413 ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-31', '2013-02-28', '2013-03-31', '2013-04-30',\n               '2013-05-31', '2013-06-30', '2013-07-31', '2013-08-31',\n               '2013-09-30', '2013-10-31', '2013-11-30', '2013-12-31',\n               '2014-01-31', '2014-02-28', '2014-03-31', '2014-04-30',\n               '2014-05-31', '2014-06-30', '2014-07-31', '2014-08-31',\n               '2014-09-30', '2014-10-31', '2014-11-30', '2014-12-31'],\n              dtype='datetime64[ns]', name='time', freq='M'))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[57]: Copied! <pre>ds.resample(time=\"M\").mean().mean(dim =['lat','lon']).air.plot()\n</pre> ds.resample(time=\"M\").mean().mean(dim =['lat','lon']).air.plot() Out[57]: <pre>[&lt;matplotlib.lines.Line2D at 0x1954c0730&gt;]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_8_Xarray/#lecture-8-xarray-for-multidimensional-gridded-data","title":"Lecture 8: Xarray for multidimensional gridded data\u00b6","text":"<p>In last week's lecture, we saw how Pandas provided a way to keep track of additional \"metadata\" surrounding tabular datasets, including \"indexes\" for each row and labels for each column. These features, together with Pandas' many useful routines for all kinds of data munging and analysis, have made Pandas one of the most popular python packages in the world.</p> <p>However, not all earth and environmental science datasets easily fit into the \"tabular\" model (i.e. rows and columns) imposed by Pandas. In particular, we often deal with multidimensional data. By multidimensional data (also often called N-dimensional), I mean data with many independent dimensions or axes. For example, we might represent Earth's surface temperature $T$ as a three dimensional variable</p> <p>$$ T(x, y, t) $$</p> <p>where $x$ is longitude, $y$ is latitude, and $t$ is time.</p> <p>The point of xarray is to provide pandas-level convenience for working with this type of data.</p>"},{"location":"Lecture_8_Xarray/#xarray-data-model","title":"Xarray Data Model\u00b6","text":""},{"location":"Lecture_8_Xarray/#xarray-functionality","title":"Xarray functionality\u00b6","text":""},{"location":"Lecture_8_Xarray/#xarray-data-structures","title":"Xarray data structures\u00b6","text":"<p>Like Pandas, xarray has two fundamental data structures:</p> <ul> <li>a <code>DataArray</code>, which holds a single multi-dimensional variable and its coordinates</li> <li>a <code>Dataset</code>, which holds multiple variables that potentially share the same coordinates</li> </ul>"},{"location":"Lecture_8_Xarray/#dataarray","title":"DataArray\u00b6","text":"<p>A <code>DataArray</code> has four essential attributes:</p> <ul> <li><code>values</code>: a <code>numpy.ndarray</code> holding the array\u2019s values</li> <li><code>dims</code>: dimension names for each axis (e.g., <code>('x', 'y', 'z')</code>)</li> <li><code>coords</code>: a dict-like container of arrays (coordinates) that label each point (e.g., 1-dimensional arrays of numbers, datetime objects or strings)</li> <li><code>attrs</code>: an <code>OrderedDict</code> to hold arbitrary metadata (attributes)</li> </ul> <p>Let's start by constructing some DataArrays manually</p>"},{"location":"Lecture_8_Xarray/#install-xarray","title":"Install Xarray:\u00b6","text":"<p><code>$ conda install -c conda-forge xarray dask netCDF4 bottleneck python-graphviz </code></p>"},{"location":"Lecture_8_Xarray/#xarray-data-structure","title":"Xarray Data Structure\u00b6","text":"<p>Xarray has a few small real-world tutorial datasets hosted in this GitHub repository https://github.com/pydata/xarray-data. We'll use the xarray.tutorial.load_dataset convenience function to download and open the <code>air_temperature</code> (National Centers for Environmental Prediction) Dataset by name.</p>"},{"location":"Lecture_8_Xarray/#what-is-included-in-xarray-dataset","title":"What is included in xarray <code>Dataset</code>?\u00b6","text":"<p>The output consists of:</p> <ul> <li>a summary of all dimensions of the <code>Dataset</code> <code>(lat: 25, time: 2920, lon: 53)</code>: this tells us that the first dimension is named <code>lat</code> and has a size of <code>25</code>, the second dimension is named <code>time</code> and has a size of <code>2920</code>, and the third dimension is named <code>lon</code> and has a size of <code>53</code>. Because we will access the dimensions by name, the order doesn't matter.</li> <li>an unordered list of coordinates or dimensions with coordinates with one item per line. Each item has a name, one or more dimensions in parentheses, a dtype and a preview of the values.</li> <li>an alphabetically sorted list of dimensions without coordinates (if there are any)</li> <li>an unordered list of attributes, or metadata</li> </ul>"},{"location":"Lecture_8_Xarray/#dataarray","title":"DataArray\u00b6","text":"<p>The <code>DataArray</code> class consists of an array (data) and its associated dimension names, labels, and attributes (metadata).</p>"},{"location":"Lecture_8_Xarray/#named-dimensions","title":"Named dimensions\u00b6","text":"<p><code>.dims</code> are the named axes of your data. They may (dimension coordinates) or may not (dimensions without coordinates) have associated values.</p> <p>In this case we have 2 spatial dimensions (<code>latitude</code> and <code>longitude</code> are stored with shorthand names <code>lat</code> and <code>lon</code>) and one temporal dimension (<code>time</code>).</p>"},{"location":"Lecture_8_Xarray/#coordinates","title":"Coordinates\u00b6","text":"<p><code>.coords</code> is a simple dict-like data container for mapping coordinate names to values.</p> <p>Here we see the actual timestamps and spatial positions of our air temperature data:</p>"},{"location":"Lecture_8_Xarray/#attributes","title":"Attributes\u00b6","text":"<p><code>.attrs</code> is a dictionary that can contain arbitrary Python objects (strings, lists, integers, dictionaries, etc.) containing information about your data. Your only limitation is that some attributes may not be writeable to certain file formats.</p>"},{"location":"Lecture_8_Xarray/#working-with-labelled-data","title":"Working with Labelled Data\u00b6","text":"<p>Xarray's labels make working with multidimensional data much easier. Metadata provides context and provides code that is more legible. This reduces the likelihood of errors from typos and makes analysis more intuitive and fun!</p>"},{"location":"Lecture_8_Xarray/#selecting-data-indexing","title":"Selecting Data (Indexing)\u00b6","text":"<p>We can always use regular numpy indexing and slicing on DataArrays</p>"},{"location":"Lecture_8_Xarray/#position-based-indexing","title":"Position-based Indexing\u00b6","text":"<p>Indexing a <code>DataArray</code> directly works (mostly) just like it does for numpy <code>ndarrays</code>, except that the returned object is always another <code>DataArray</code>:</p> <p>This approach however does not take advantage of the dimension names and coordinate location information that is present in a Xarray object.</p>"},{"location":"Lecture_8_Xarray/#positional-indexing-using-dimension-names","title":"Positional Indexing Using Dimension Names\u00b6","text":""},{"location":"Lecture_8_Xarray/#label-based-indexing","title":"Label-based Indexing\u00b6","text":"<p>To select data by coordinate labels instead of integer indices we can use <code>sel</code> instead of <code>isel</code>:</p>"},{"location":"Lecture_8_Xarray/#dropping-using-drop_sel","title":"Dropping using <code>drop_sel</code>\u00b6","text":"<p>If instead of selecting data we want to drop it, we can use <code>drop_sel</code> method with syntax similar to <code>sel</code>:</p>"},{"location":"Lecture_8_Xarray/#nearest-neighbor-lookups","title":"Nearest Neighbor Lookups\u00b6","text":"<p>The label based selection methods <code>sel()</code> support <code>method</code> and <code>tolerance</code> keyword argument. The <code>method</code> parameter allows for enabling nearest neighbor (inexact) lookups by use of the methods <code>ffill</code> (propagate last valid index forward), <code>backfill</code> or <code>nearest</code>:</p>"},{"location":"Lecture_8_Xarray/#datetime-indexing","title":"Datetime Indexing\u00b6","text":"<p>Datetime indexing is a critical feature when working with time series data, which is a common occurrence in atmospheric and environmental sciences. Essentially, datetime indexing allows you to select data points or a series of data points that correspond to certain date or time criteria. This becomes essential for time-series analysis where the date or time information associated with each data point can be as critical as the data point itself.</p> <p>Let's see some of the techniques to perform datetime indexing in Xarray:</p>"},{"location":"Lecture_8_Xarray/#selecting-data-based-on-single-datetime","title":"Selecting data based on single datetime\u00b6","text":"<p>Let's say we have a Dataset ds and we want to select data at a particular date and time, for instance, '2013-01-01' at 6AM. We can do this by using the <code>sel</code> (select) method, like so:</p>"},{"location":"Lecture_8_Xarray/#selecting-data-for-a-range-of-dates","title":"Selecting data for a range of dates\u00b6","text":"<p>Now, let's say we want to select data between a certain range of dates. We can still use the <code>sel</code> method, but this time we will combine it with slice:</p>"},{"location":"Lecture_8_Xarray/#indexing-with-a-datetimeindex-or-date-string-list","title":"Indexing with a DatetimeIndex or date string list\u00b6","text":"<p>Another technique is to use a list of datetime objects or date strings for indexing. For example, you could select data for specific, non-contiguous dates like this:</p>"},{"location":"Lecture_8_Xarray/#fancy-indexing-based-on-year-month-day-or-other-datetime-components","title":"Fancy indexing based on year, month, day, or other datetime components\u00b6","text":"<p>In addition to the basic datetime indexing techniques, Xarray also supports \"fancy\" indexing options, which can provide more flexibility and efficiency in your data analysis tasks. You can directly access datetime components such as year, month, day, hour, etc. using the <code>.dt</code> accessor. Here is an example of selecting all data points from July across all years:</p>"},{"location":"Lecture_8_Xarray/#xarray-computation","title":"Xarray Computation\u00b6","text":""},{"location":"Lecture_8_Xarray/#broadcasting-expanding-data","title":"Broadcasting: expanding data\u00b6","text":""},{"location":"Lecture_8_Xarray/#xarray-groupby-and-resample","title":"Xarray Groupby and Resample\u00b6","text":""},{"location":"Lecture_8_Xarray/#groupby","title":"groupby\u00b6","text":""},{"location":"Lecture_8_Xarray/#resample","title":"resample\u00b6","text":""},{"location":"Lecture_9_Dask_Parallel_Computing/","title":"Lecture 9 Dask for Parellel Computing and Big Data","text":"<p>In past lectures, we learned how to use numpy, pandas, and xarray to analyze various types of geoscience data. In this lecture, we address an incresingly common problem: what happens if the data we wish to analyze is \"big data\"</p> In\u00a0[14]: Copied! <pre>import numpy as np\nshape = (1000, 4000)\nones_np = np.ones(shape)\nones_np\n</pre> import numpy as np shape = (1000, 4000) ones_np = np.ones(shape) ones_np Out[14]: <pre>array([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       ...,\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.]])</pre> <p>This array contains exactly 32 MB of data:</p> In\u00a0[2]: Copied! <pre>ones_np.nbytes / 1e6\n</pre> ones_np.nbytes / 1e6 Out[2]: <pre>32.0</pre> <p>Now let's create the same array using dask's array interface.</p> In\u00a0[3]: Copied! <pre>import dask\nimport dask.array as da\nones = da.ones(shape)\n</pre> import dask import dask.array as da ones = da.ones(shape) In\u00a0[4]: Copied! <pre>ones\n</pre> ones Out[4]:  Array   Chunk   Bytes   30.52 MiB   30.52 MiB   Shape   (1000, 4000)   (1000, 4000)   Dask graph   1 chunks in 1 graph layer   Data type   float64 numpy.ndarray  4000 1000 In\u00a0[5]: Copied! <pre>ones = da.ones((100,1000,1000))\n</pre> ones = da.ones((100,1000,1000)) In\u00a0[6]: Copied! <pre># Dask will determine an optimal chunk size. \nones\n</pre> # Dask will determine an optimal chunk size.  ones Out[6]:  Array   Chunk   Bytes   762.94 MiB   127.63 MiB   Shape   (100, 1000, 1000)   (100, 409, 409)   Dask graph   9 chunks in 1 graph layer   Data type   float64 numpy.ndarray  1000 1000 100 <p>By default, dask reads the entire array as a single chuck. If the data size is too big, dask will split the dataset to different chunks.  \"Chunks\" describes how the array is split up over many sub-arrays.</p> <p>There are several ways to specify chunks. In this lecture, we will use a block shape.</p> In\u00a0[7]: Copied! <pre>chunk_shape = (1000, 1000)\nshape = (1000, 4000)\nones = da.ones(shape, chunks=chunk_shape)\nones\n</pre> chunk_shape = (1000, 1000) shape = (1000, 4000) ones = da.ones(shape, chunks=chunk_shape) ones Out[7]:  Array   Chunk   Bytes   30.52 MiB   7.63 MiB   Shape   (1000, 4000)   (1000, 1000)   Dask graph   4 chunks in 1 graph layer   Data type   float64 numpy.ndarray  4000 1000 In\u00a0[8]: Copied! <pre>ones.chunksize\n</pre> ones.chunksize Out[8]: <pre>(1000, 1000)</pre> <p>Notice that we just see a symbolic represetnation of the array, including its shape, dtype, and chunksize. No data has been generated yet. When we call <code>.compute()</code> on a dask array, the computation is trigger and the dask array becomes a numpy array.</p> In\u00a0[9]: Copied! <pre>ones.compute()\n</pre> ones.compute() Out[9]: <pre>array([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       ...,\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.]])</pre> <p>In order to understand what happened when we called <code>.compute()</code>, we can visualize the dask graph, the symbolic operations that make up the array</p> In\u00a0[19]: Copied! <pre># Install graphviz: mamba install -c conda-forge python-graphviz graphviz\n</pre> # Install graphviz: mamba install -c conda-forge python-graphviz graphviz In\u00a0[18]: Copied! <pre>ones.visualize()\n</pre> ones.visualize() Out[18]: <p>Our array has four chunks. To generate it, dask calls <code>np.ones</code> four times and then concatenates this together into one array.</p> <p>Rather than immediately loading a dask array (which puts all the data into RAM), it is more common to want to reduce the data somehow. For example</p> In\u00a0[20]: Copied! <pre>sum_of_ones = ones.sum()\nsum_of_ones.visualize()\n</pre> sum_of_ones = ones.sum() sum_of_ones.visualize() Out[20]: <p>Here we see dask's strategy for finding the sum. This simple example illustrates the beauty of dask: it automatically designs an algorithm appropriate for custom operations with big data.</p> <p>If we make our operation more complex, the graph gets more complex.</p> In\u00a0[21]: Copied! <pre>fancy_calculation = (ones * ones[::-1, ::-1]).mean()\nfancy_calculation.visualize()\n</pre> fancy_calculation = (ones * ones[::-1, ::-1]).mean() fancy_calculation.visualize() Out[21]: In\u00a0[22]: Copied! <pre>bigshape = (200000, 4000)\nbig_ones = da.ones(bigshape, chunks=chunk_shape)\nbig_ones\n</pre> bigshape = (200000, 4000) big_ones = da.ones(bigshape, chunks=chunk_shape) big_ones Out[22]:  Array   Chunk   Bytes   5.96 GiB   7.63 MiB   Shape   (200000, 4000)   (1000, 1000)   Dask graph   800 chunks in 1 graph layer   Data type   float64 numpy.ndarray  4000 200000 In\u00a0[23]: Copied! <pre>big_ones.nbytes / 1e6\n</pre> big_ones.nbytes / 1e6 Out[23]: <pre>6400.0</pre> <p>This dataset is 6.4 GB, rather MB! This is probably close to or greater than the amount of available RAM than you have in your computer. Nevertheless, dask has no problem working on it.</p> <p>Do not try to <code>.visualize()</code> this array!</p> <p>When doing a big calculation, dask also has some tools to help us understand what is happening under the hood</p> In\u00a0[24]: Copied! <pre>from dask.diagnostics import ProgressBar\n\nbig_calc = (big_ones * big_ones[::-1, ::-1]).mean()\n\nwith ProgressBar():\n    result = big_calc.compute()\nresult\n</pre> from dask.diagnostics import ProgressBar  big_calc = (big_ones * big_ones[::-1, ::-1]).mean()  with ProgressBar():     result = big_calc.compute() result <pre>[########################################] | 100% Completed | 2.38 sms\n</pre> Out[24]: <pre>1.0</pre> In\u00a0[25]: Copied! <pre>big_ones_reduce = (np.cos(big_ones)**2).mean(axis=0)\nbig_ones_reduce\n</pre> big_ones_reduce = (np.cos(big_ones)**2).mean(axis=0) big_ones_reduce Out[25]:  Array   Chunk   Bytes   31.25 kiB   7.81 kiB   Shape   (4000,)   (1000,)   Dask graph   4 chunks in 8 graph layers   Data type   float64 numpy.ndarray  4000 1 <p>Plotting also triggers computation, since we need the actual values</p> In\u00a0[26]: Copied! <pre>from matplotlib import pyplot as plt\n</pre> from matplotlib import pyplot as plt In\u00a0[27]: Copied! <pre>plt.plot(big_ones_reduce)\n</pre> plt.plot(big_ones_reduce) Out[27]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f50b7bfa820&gt;]</pre> In\u00a0[1]: Copied! <pre>import numpy as np\nimport xarray as xr\n</pre> import numpy as np import xarray as xr  In\u00a0[30]: Copied! <pre>ds = xr.tutorial.open_dataset(\"air_temperature\")\n</pre> ds = xr.tutorial.open_dataset(\"air_temperature\") In\u00a0[31]: Copied! <pre>ds = xr.tutorial.open_dataset(\n    \"air_temperature\",\n    chunks={  # this tells xarray to open the dataset as a dask array\n        \"lat\": \"auto\",\n        \"lon\": \"auto\",\n        \"time\": 1000,\n    },\n)\nds\n</pre> ds = xr.tutorial.open_dataset(     \"air_temperature\",     chunks={  # this tells xarray to open the dataset as a dask array         \"lat\": \"auto\",         \"lon\": \"auto\",         \"time\": 1000,     }, ) ds Out[31]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 dask.array&lt;chunksize=(1000, 25, 53), meta=np.ndarray&gt;\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 2920</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32dask.array&lt;chunksize=(1000, 25, 53), meta=np.ndarray&gt;long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]  Array   Chunk   Bytes   14.76 MiB   5.05 MiB   Shape   (2920, 25, 53)   (1000, 25, 53)   Dask graph   3 chunks in 2 graph layers   Data type   float32 numpy.ndarray  53 25 2920 </li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[32]: Copied! <pre>ds.air.data  # dask array, not numpy\n</pre> ds.air.data  # dask array, not numpy Out[32]:  Array   Chunk   Bytes   14.76 MiB   5.05 MiB   Shape   (2920, 25, 53)   (1000, 25, 53)   Dask graph   3 chunks in 2 graph layers   Data type   float32 numpy.ndarray  53 25 2920 In\u00a0[33]: Copied! <pre>ds.air.as_numpy().data  ## numpy array\n</pre> ds.air.as_numpy().data  ## numpy array Out[33]: <pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n        ...,\n        [296.4    , 295.9    , 296.19998, ..., 295.4    , 295.1    ,\n         294.79   ],\n        [296.19998, 296.69998, 296.79   , ..., 295.6    , 295.5    ,\n         295.1    ],\n        [296.29   , 297.19998, 297.4    , ..., 296.4    , 296.4    ,\n         296.6    ]],\n\n       [[242.29999, 242.2    , 242.29999, ..., 234.29999, 236.09999,\n         238.7    ],\n        [244.59999, 244.39   , 244.     , ..., 230.29999, 232.     ,\n         235.7    ],\n        [256.19998, 255.5    , 254.2    , ..., 231.2    , 233.2    ,\n         238.2    ],\n        ...,\n        [295.6    , 295.4    , 295.4    , ..., 296.29   , 295.29   ,\n         295.     ],\n        [296.19998, 296.5    , 296.29   , ..., 296.4    , 296.     ,\n         295.6    ],\n        [296.4    , 296.29   , 296.4    , ..., 297.     , 297.     ,\n         296.79   ]],\n\n       ...,\n\n       [[243.48999, 242.98999, 242.09   , ..., 244.18999, 244.48999,\n         244.89   ],\n        [249.09   , 248.98999, 248.59   , ..., 240.59   , 241.29   ,\n         242.68999],\n        [262.69   , 262.19   , 261.69   , ..., 239.39   , 241.68999,\n         245.18999],\n        ...,\n        [294.79   , 295.29   , 297.49   , ..., 295.49   , 295.38998,\n         294.69   ],\n        [296.79   , 297.88998, 298.29   , ..., 295.49   , 295.49   ,\n         294.79   ],\n        [298.19   , 299.19   , 298.79   , ..., 296.09   , 295.79   ,\n         295.79   ]],\n\n       [[245.79   , 244.79   , 243.48999, ..., 243.29   , 243.98999,\n         244.79   ],\n        [249.89   , 249.29   , 248.48999, ..., 241.29   , 242.48999,\n         244.29   ],\n        [262.38998, 261.79   , 261.29   , ..., 240.48999, 243.09   ,\n         246.89   ],\n        ...,\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre> <pre><code>{exercise}\n:label: data-values\nTry calling `ds.air.values` and `ds.air.data`. Do you understand the difference?\n</code></pre> In\u00a0[34]: Copied! <pre>ds.air.to_numpy()\n</pre> ds.air.to_numpy() Out[34]: <pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n        ...,\n        [296.4    , 295.9    , 296.19998, ..., 295.4    , 295.1    ,\n         294.79   ],\n        [296.19998, 296.69998, 296.79   , ..., 295.6    , 295.5    ,\n         295.1    ],\n        [296.29   , 297.19998, 297.4    , ..., 296.4    , 296.4    ,\n         296.6    ]],\n\n       [[242.29999, 242.2    , 242.29999, ..., 234.29999, 236.09999,\n         238.7    ],\n        [244.59999, 244.39   , 244.     , ..., 230.29999, 232.     ,\n         235.7    ],\n        [256.19998, 255.5    , 254.2    , ..., 231.2    , 233.2    ,\n         238.2    ],\n        ...,\n        [295.6    , 295.4    , 295.4    , ..., 296.29   , 295.29   ,\n         295.     ],\n        [296.19998, 296.5    , 296.29   , ..., 296.4    , 296.     ,\n         295.6    ],\n        [296.4    , 296.29   , 296.4    , ..., 297.     , 297.     ,\n         296.79   ]],\n\n       ...,\n\n       [[243.48999, 242.98999, 242.09   , ..., 244.18999, 244.48999,\n         244.89   ],\n        [249.09   , 248.98999, 248.59   , ..., 240.59   , 241.29   ,\n         242.68999],\n        [262.69   , 262.19   , 261.69   , ..., 239.39   , 241.68999,\n         245.18999],\n        ...,\n        [294.79   , 295.29   , 297.49   , ..., 295.49   , 295.38998,\n         294.69   ],\n        [296.79   , 297.88998, 298.29   , ..., 295.49   , 295.49   ,\n         294.79   ],\n        [298.19   , 299.19   , 298.79   , ..., 296.09   , 295.79   ,\n         295.79   ]],\n\n       [[245.79   , 244.79   , 243.48999, ..., 243.29   , 243.98999,\n         244.79   ],\n        [249.89   , 249.29   , 248.48999, ..., 241.29   , 242.48999,\n         244.29   ],\n        [262.38998, 261.79   , 261.29   , ..., 240.48999, 243.09   ,\n         246.89   ],\n        ...,\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre> <p></p> In\u00a0[35]: Copied! <pre>mean = ds.air.mean(\"time\")\nmean\n</pre> mean = ds.air.mean(\"time\") mean Out[35]: <pre>&lt;xarray.DataArray 'air' (lat: 25, lon: 53)&gt;\ndask.array&lt;mean_agg-aggregate, shape=(25, 53), dtype=float32, chunksize=(25, 53), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0</pre>xarray.DataArray'air'<ul><li>lat: 25</li><li>lon: 53</li></ul><ul><li>dask.array&lt;chunksize=(25, 53), meta=np.ndarray&gt;  Array   Chunk   Bytes   5.18 kiB   5.18 kiB   Shape   (25, 53)   (25, 53)   Dask graph   1 chunks in 4 graph layers   Data type   float32 numpy.ndarray  53 25 </li><li>Coordinates: (2)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li></ul></li><li>Indexes: (2)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li></ul></li><li>Attributes: (0)</li></ul> <p>Dask actually constructs a graph of the required computation. Here it's pretty simple: The full array is subdivided into 3 arrays. Dask will load each of these subarrays in a separate thread using the default single-machine scheduling. You can visualize dask 'task graphs' which represent the requested computation:</p> In\u00a0[36]: Copied! <pre>mean.data  # dask array\n</pre> mean.data  # dask array Out[36]:  Array   Chunk   Bytes   5.18 kiB   5.18 kiB   Shape   (25, 53)   (25, 53)   Dask graph   1 chunks in 4 graph layers   Data type   float32 numpy.ndarray  53 25 In\u00a0[37]: Copied! <pre># visualize the graph for the underlying dask array\n# we ask it to visualize the graph from left to right because it looks nicer\ndask.visualize(mean.data, rankdir=\"LR\", optimize_graph =True)\n</pre> # visualize the graph for the underlying dask array # we ask it to visualize the graph from left to right because it looks nicer dask.visualize(mean.data, rankdir=\"LR\", optimize_graph =True) Out[37]: In\u00a0[38]: Copied! <pre>ds.load()\n</pre> ds.load() Out[38]: <pre>&lt;xarray.Dataset&gt;\nDimensions:  (lat: 25, time: 2920, lon: 53)\nCoordinates:\n  * lat      (lat) float32 75.0 72.5 70.0 67.5 65.0 ... 25.0 22.5 20.0 17.5 15.0\n  * lon      (lon) float32 200.0 202.5 205.0 207.5 ... 322.5 325.0 327.5 330.0\n  * time     (time) datetime64[ns] 2013-01-01 ... 2014-12-31T18:00:00\nData variables:\n    air      (time, lat, lon) float32 241.2 242.5 243.5 ... 296.5 296.2 295.7\nAttributes:\n    Conventions:  COARDS\n    title:        4x daily NMC reanalysis (1948)\n    description:  Data is from NMC initialized reanalysis\\n(4x/day).  These a...\n    platform:     Model\n    references:   http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanaly...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>lat: 25</li><li>time: 2920</li><li>lon: 53</li></ul></li><li>Coordinates: (3)<ul><li>lat(lat)float3275.0 72.5 70.0 ... 20.0 17.5 15.0standard_name :latitudelong_name :Latitudeunits :degrees_northaxis :Y<pre>array([75. , 72.5, 70. , 67.5, 65. , 62.5, 60. , 57.5, 55. , 52.5, 50. , 47.5,\n       45. , 42.5, 40. , 37.5, 35. , 32.5, 30. , 27.5, 25. , 22.5, 20. , 17.5,\n       15. ], dtype=float32)</pre></li><li>lon(lon)float32200.0 202.5 205.0 ... 327.5 330.0standard_name :longitudelong_name :Longitudeunits :degrees_eastaxis :X<pre>array([200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n       325. , 327.5, 330. ], dtype=float32)</pre></li><li>time(time)datetime64[ns]2013-01-01 ... 2014-12-31T18:00:00standard_name :timelong_name :Time<pre>array(['2013-01-01T00:00:00.000000000', '2013-01-01T06:00:00.000000000',\n       '2013-01-01T12:00:00.000000000', ..., '2014-12-31T06:00:00.000000000',\n       '2014-12-31T12:00:00.000000000', '2014-12-31T18:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (1)<ul><li>air(time, lat, lon)float32241.2 242.5 243.5 ... 296.2 295.7long_name :4xDaily Air temperature at sigma level 995units :degKprecision :2GRIB_id :11GRIB_name :TMPvar_desc :Air temperaturedataset :NMC Reanalysislevel_desc :Surfacestatistic :Individual Obsparent_stat :Otheractual_range :[185.16 322.1 ]<pre>array([[[241.2    , 242.5    , 243.5    , ..., 232.79999, 235.5    ,\n         238.59999],\n        [243.79999, 244.5    , 244.7    , ..., 232.79999, 235.29999,\n         239.29999],\n        [250.     , 249.79999, 248.89   , ..., 233.2    , 236.39   ,\n         241.7    ],\n        ...,\n        [296.6    , 296.19998, 296.4    , ..., 295.4    , 295.1    ,\n         294.69998],\n        [295.9    , 296.19998, 296.79   , ..., 295.9    , 295.9    ,\n         295.19998],\n        [296.29   , 296.79   , 297.1    , ..., 296.9    , 296.79   ,\n         296.6    ]],\n\n       [[242.09999, 242.7    , 243.09999, ..., 232.     , 233.59999,\n         235.79999],\n        [243.59999, 244.09999, 244.2    , ..., 231.     , 232.5    ,\n         235.7    ],\n        [253.2    , 252.89   , 252.09999, ..., 230.79999, 233.39   ,\n         238.5    ],\n...\n        [293.69   , 293.88998, 295.38998, ..., 295.09   , 294.69   ,\n         294.29   ],\n        [296.29   , 297.19   , 297.59   , ..., 295.29   , 295.09   ,\n         294.38998],\n        [297.79   , 298.38998, 298.49   , ..., 295.69   , 295.49   ,\n         295.19   ]],\n\n       [[245.09   , 244.29   , 243.29   , ..., 241.68999, 241.48999,\n         241.79   ],\n        [249.89   , 249.29   , 248.39   , ..., 239.59   , 240.29   ,\n         241.68999],\n        [262.99   , 262.19   , 261.38998, ..., 239.89   , 242.59   ,\n         246.29   ],\n        ...,\n        [293.79   , 293.69   , 295.09   , ..., 295.29   , 295.09   ,\n         294.69   ],\n        [296.09   , 296.88998, 297.19   , ..., 295.69   , 295.69   ,\n         295.19   ],\n        [297.69   , 298.09   , 298.09   , ..., 296.49   , 296.19   ,\n         295.69   ]]], dtype=float32)</pre></li></ul></li><li>Indexes: (3)<ul><li>latPandasIndex<pre>PandasIndex(Index([75.0, 72.5, 70.0, 67.5, 65.0, 62.5, 60.0, 57.5, 55.0, 52.5, 50.0, 47.5,\n       45.0, 42.5, 40.0, 37.5, 35.0, 32.5, 30.0, 27.5, 25.0, 22.5, 20.0, 17.5,\n       15.0],\n      dtype='float32', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([200.0, 202.5, 205.0, 207.5, 210.0, 212.5, 215.0, 217.5, 220.0, 222.5,\n       225.0, 227.5, 230.0, 232.5, 235.0, 237.5, 240.0, 242.5, 245.0, 247.5,\n       250.0, 252.5, 255.0, 257.5, 260.0, 262.5, 265.0, 267.5, 270.0, 272.5,\n       275.0, 277.5, 280.0, 282.5, 285.0, 287.5, 290.0, 292.5, 295.0, 297.5,\n       300.0, 302.5, 305.0, 307.5, 310.0, 312.5, 315.0, 317.5, 320.0, 322.5,\n       325.0, 327.5, 330.0],\n      dtype='float32', name='lon'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2013-01-01 00:00:00', '2013-01-01 06:00:00',\n               '2013-01-01 12:00:00', '2013-01-01 18:00:00',\n               '2013-01-02 00:00:00', '2013-01-02 06:00:00',\n               '2013-01-02 12:00:00', '2013-01-02 18:00:00',\n               '2013-01-03 00:00:00', '2013-01-03 06:00:00',\n               ...\n               '2014-12-29 12:00:00', '2014-12-29 18:00:00',\n               '2014-12-30 00:00:00', '2014-12-30 06:00:00',\n               '2014-12-30 12:00:00', '2014-12-30 18:00:00',\n               '2014-12-31 00:00:00', '2014-12-31 06:00:00',\n               '2014-12-31 12:00:00', '2014-12-31 18:00:00'],\n              dtype='datetime64[ns]', name='time', length=2920, freq=None))</pre></li></ul></li><li>Attributes: (5)Conventions :COARDStitle :4x daily NMC reanalysis (1948)description :Data is from NMC initialized reanalysis (4x/day).  These are the 0.9950 sigma level values.platform :Modelreferences :http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.html</li></ul> In\u00a0[2]: Copied! <pre>ds_multiple = xr.open_mfdataset('/scratch/xj103/rcaes/GEOS_Chem_Sims/GEOSChem.SpeciesConcHourlyNO2.2020*_2100z.nc4')\n</pre> ds_multiple = xr.open_mfdataset('/scratch/xj103/rcaes/GEOS_Chem_Sims/GEOSChem.SpeciesConcHourlyNO2.2020*_2100z.nc4')   In\u00a0[3]: Copied! <pre>ds_multiple\n</pre> ds_multiple Out[3]: <pre>&lt;xarray.Dataset&gt;\nDimensions:          (time: 30, lev: 47, lat: 81, lon: 65)\nCoordinates:\n  * time             (time) datetime64[ns] 2020-09-01T21:30:00 ... 2020-09-30...\n  * lev              (lev) float64 0.9925 0.9775 0.9625 ... 0.0001387 3.8e-05\n  * lat              (lat) float64 27.0 27.25 27.5 27.75 ... 46.5 46.75 47.0\n  * lon              (lon) float64 -130.0 -129.7 -129.4 ... -110.6 -110.3 -110.0\nData variables:\n    SpeciesConc_NO2  (time, lev, lat, lon) float32 dask.array&lt;chunksize=(1, 47, 81, 65), meta=np.ndarray&gt;</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 30</li><li>lev: 47</li><li>lat: 81</li><li>lon: 65</li></ul></li><li>Coordinates: (4)<ul><li>time(time)datetime64[ns]2020-09-01T21:30:00 ... 2020-09-...long_name :Timeaxis :T<pre>array(['2020-09-01T21:30:00.000000000', '2020-09-02T21:30:00.000000000',\n       '2020-09-03T21:30:00.000000000', '2020-09-04T21:30:00.000000000',\n       '2020-09-05T21:30:00.000000000', '2020-09-06T21:30:00.000000000',\n       '2020-09-07T21:30:00.000000000', '2020-09-08T21:30:00.000000000',\n       '2020-09-09T21:30:00.000000000', '2020-09-10T21:30:00.000000000',\n       '2020-09-11T21:30:00.000000000', '2020-09-12T21:30:00.000000000',\n       '2020-09-13T21:30:00.000000000', '2020-09-14T21:30:00.000000000',\n       '2020-09-15T21:30:00.000000000', '2020-09-16T21:30:00.000000000',\n       '2020-09-17T21:30:00.000000000', '2020-09-18T21:30:00.000000000',\n       '2020-09-19T21:30:00.000000000', '2020-09-20T21:30:00.000000000',\n       '2020-09-21T21:30:00.000000000', '2020-09-22T21:30:00.000000000',\n       '2020-09-23T21:30:00.000000000', '2020-09-24T21:30:00.000000000',\n       '2020-09-25T21:30:00.000000000', '2020-09-26T21:30:00.000000000',\n       '2020-09-27T21:30:00.000000000', '2020-09-28T21:30:00.000000000',\n       '2020-09-29T21:30:00.000000000', '2020-09-30T21:30:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>lev(lev)float640.9925 0.9775 ... 0.0001387 3.8e-05long_name :hybrid level at midpoints ((A/P0)+B)units :levelaxis :Zpositive :upstandard_name :atmosphere_hybrid_sigma_pressure_coordinateformula_terms :a: hyam b: hybm p0: P0 ps: PS<pre>array([9.925000e-01, 9.774999e-01, 9.624998e-01, 9.475000e-01, 9.325001e-01,\n       9.174999e-01, 9.024999e-01, 8.875000e-01, 8.725000e-01, 8.575001e-01,\n       8.425001e-01, 8.275002e-01, 8.100002e-01, 7.875000e-01, 7.625000e-01,\n       7.375001e-01, 7.125001e-01, 6.875001e-01, 6.562501e-01, 6.187502e-01,\n       5.812502e-01, 5.437501e-01, 5.062501e-01, 4.687501e-01, 4.312501e-01,\n       3.937501e-01, 3.562501e-01, 3.127916e-01, 2.664790e-01, 2.265135e-01,\n       1.925410e-01, 1.636615e-01, 1.391150e-01, 1.182500e-01, 1.005144e-01,\n       8.543901e-02, 6.745011e-02, 4.828166e-02, 3.427161e-02, 2.407970e-02,\n       1.454227e-02, 6.684757e-03, 2.863681e-03, 1.133785e-03, 4.140641e-04,\n       1.386745e-04, 3.800000e-05])</pre></li><li>lat(lat)float6427.0 27.25 27.5 ... 46.5 46.75 47.0long_name :Latitudeunits :degrees_northaxis :Y<pre>array([27.  , 27.25, 27.5 , 27.75, 28.  , 28.25, 28.5 , 28.75, 29.  , 29.25,\n       29.5 , 29.75, 30.  , 30.25, 30.5 , 30.75, 31.  , 31.25, 31.5 , 31.75,\n       32.  , 32.25, 32.5 , 32.75, 33.  , 33.25, 33.5 , 33.75, 34.  , 34.25,\n       34.5 , 34.75, 35.  , 35.25, 35.5 , 35.75, 36.  , 36.25, 36.5 , 36.75,\n       37.  , 37.25, 37.5 , 37.75, 38.  , 38.25, 38.5 , 38.75, 39.  , 39.25,\n       39.5 , 39.75, 40.  , 40.25, 40.5 , 40.75, 41.  , 41.25, 41.5 , 41.75,\n       42.  , 42.25, 42.5 , 42.75, 43.  , 43.25, 43.5 , 43.75, 44.  , 44.25,\n       44.5 , 44.75, 45.  , 45.25, 45.5 , 45.75, 46.  , 46.25, 46.5 , 46.75,\n       47.  ])</pre></li><li>lon(lon)float64-130.0 -129.7 ... -110.3 -110.0long_name :Longitudeunits :degrees_eastaxis :X<pre>array([-130.    , -129.6875, -129.375 , -129.0625, -128.75  , -128.4375,\n       -128.125 , -127.8125, -127.5   , -127.1875, -126.875 , -126.5625,\n       -126.25  , -125.9375, -125.625 , -125.3125, -125.    , -124.6875,\n       -124.375 , -124.0625, -123.75  , -123.4375, -123.125 , -122.8125,\n       -122.5   , -122.1875, -121.875 , -121.5625, -121.25  , -120.9375,\n       -120.625 , -120.3125, -120.    , -119.6875, -119.375 , -119.0625,\n       -118.75  , -118.4375, -118.125 , -117.8125, -117.5   , -117.1875,\n       -116.875 , -116.5625, -116.25  , -115.9375, -115.625 , -115.3125,\n       -115.    , -114.6875, -114.375 , -114.0625, -113.75  , -113.4375,\n       -113.125 , -112.8125, -112.5   , -112.1875, -111.875 , -111.5625,\n       -111.25  , -110.9375, -110.625 , -110.3125, -110.    ])</pre></li></ul></li><li>Data variables: (1)<ul><li>SpeciesConc_NO2(time, lev, lat, lon)float32dask.array&lt;chunksize=(1, 47, 81, 65), meta=np.ndarray&gt;long_name :Dry mixing ratio of species NO2units :mol mol-1 dryaveraging_method :time-averaged  Array   Chunk   Bytes   28.32 MiB   0.94 MiB   Shape   (30, 47, 81, 65)   (1, 47, 81, 65)   Dask graph   30 chunks in 61 graph layers   Data type   float32 numpy.ndarray  30 1 65 81 47 </li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2020-09-01 21:30:00', '2020-09-02 21:30:00',\n               '2020-09-03 21:30:00', '2020-09-04 21:30:00',\n               '2020-09-05 21:30:00', '2020-09-06 21:30:00',\n               '2020-09-07 21:30:00', '2020-09-08 21:30:00',\n               '2020-09-09 21:30:00', '2020-09-10 21:30:00',\n               '2020-09-11 21:30:00', '2020-09-12 21:30:00',\n               '2020-09-13 21:30:00', '2020-09-14 21:30:00',\n               '2020-09-15 21:30:00', '2020-09-16 21:30:00',\n               '2020-09-17 21:30:00', '2020-09-18 21:30:00',\n               '2020-09-19 21:30:00', '2020-09-20 21:30:00',\n               '2020-09-21 21:30:00', '2020-09-22 21:30:00',\n               '2020-09-23 21:30:00', '2020-09-24 21:30:00',\n               '2020-09-25 21:30:00', '2020-09-26 21:30:00',\n               '2020-09-27 21:30:00', '2020-09-28 21:30:00',\n               '2020-09-29 21:30:00', '2020-09-30 21:30:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li><li>levPandasIndex<pre>PandasIndex(Index([         0.99250002413,          0.97749990013,     0.9624997759999999,\n                  0.947499955,             0.93250006,             0.91749991,\n                   0.90249991,             0.88749996,             0.87249996,\n           0.8575000599999999,            0.842500125,             0.82750016,\n                    0.8100002,     0.7875000200000001,            0.762499965,\n           0.7375001050000001,              0.7125001,              0.6875001,\n                   0.65625015,     0.6187501999999999,             0.58125015,\n                    0.5437501,              0.5062501,    0.46875009999999995,\n          0.43125009999999997,              0.3937501,              0.3562501,\n          0.31279157999999996,             0.26647905,           0.2265135325,\n           0.1925410165877065,     0.1636615040877065,    0.13911500000000002,\n                      0.11825,             0.10051436,            0.085439015,\n                   0.06745011,   0.048281660000000004,   0.034271609999999994,\n         0.024079704999999996,   0.014542270999999999,   0.006684756500000001,\n                 0.0028636805,          0.00113378455, 0.00041406405000000003,\n               0.000138674505, 3.8000004999999996e-05],\n      dtype='float64', name='lev'))</pre></li><li>latPandasIndex<pre>PandasIndex(Index([ 27.0, 27.25,  27.5, 27.75,  28.0, 28.25,  28.5, 28.75,  29.0, 29.25,\n        29.5, 29.75,  30.0, 30.25,  30.5, 30.75,  31.0, 31.25,  31.5, 31.75,\n        32.0, 32.25,  32.5, 32.75,  33.0, 33.25,  33.5, 33.75,  34.0, 34.25,\n        34.5, 34.75,  35.0, 35.25,  35.5, 35.75,  36.0, 36.25,  36.5, 36.75,\n        37.0, 37.25,  37.5, 37.75,  38.0, 38.25,  38.5, 38.75,  39.0, 39.25,\n        39.5, 39.75,  40.0, 40.25,  40.5, 40.75,  41.0, 41.25,  41.5, 41.75,\n        42.0, 42.25,  42.5, 42.75,  43.0, 43.25,  43.5, 43.75,  44.0, 44.25,\n        44.5, 44.75,  45.0, 45.25,  45.5, 45.75,  46.0, 46.25,  46.5, 46.75,\n        47.0],\n      dtype='float64', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([   -130.0, -129.6875,  -129.375, -129.0625,   -128.75, -128.4375,\n        -128.125, -127.8125,    -127.5, -127.1875,  -126.875, -126.5625,\n         -126.25, -125.9375,  -125.625, -125.3125,    -125.0, -124.6875,\n        -124.375, -124.0625,   -123.75, -123.4375,  -123.125, -122.8125,\n          -122.5, -122.1875,  -121.875, -121.5625,   -121.25, -120.9375,\n        -120.625, -120.3125,    -120.0, -119.6875,  -119.375, -119.0625,\n         -118.75, -118.4375,  -118.125, -117.8125,    -117.5, -117.1875,\n        -116.875, -116.5625,   -116.25, -115.9375,  -115.625, -115.3125,\n          -115.0, -114.6875,  -114.375, -114.0625,   -113.75, -113.4375,\n        -113.125, -112.8125,    -112.5, -112.1875,  -111.875, -111.5625,\n         -111.25, -110.9375,  -110.625, -110.3125,    -110.0],\n      dtype='float64', name='lon'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[5]: Copied! <pre>%time ds_multiple.SpeciesConc_NO2.mean(dim = 'time').compute()\n</pre> %time ds_multiple.SpeciesConc_NO2.mean(dim = 'time').compute() <pre>CPU times: user 462 ms, sys: 89.5 ms, total: 552 ms\nWall time: 2.52 s\n</pre> Out[5]: <pre>&lt;xarray.DataArray 'SpeciesConc_NO2' (lev: 47, lat: 81, lon: 65)&gt;\narray([[[4.9062303e-11, 4.9062081e-11, 4.9061859e-11, ...,\n         4.9071434e-11, 4.9071955e-11, 4.9072468e-11],\n        [1.6923058e-11, 1.6950108e-11, 1.6952899e-11, ...,\n         9.9948189e-11, 9.9900643e-11, 9.9872791e-11],\n        [1.6929434e-11, 1.6926667e-11, 1.6934249e-11, ...,\n         9.9928288e-11, 9.9878307e-11, 9.9870709e-11],\n        ...,\n        [8.5456746e-11, 8.5386170e-11, 8.5320598e-11, ...,\n         4.0959905e-10, 4.0894488e-10, 4.1077211e-10],\n        [8.5364313e-11, 8.5232314e-11, 8.5183277e-11, ...,\n         4.0959866e-10, 4.0940437e-10, 4.1138837e-10],\n        [8.0792273e-10, 8.0792262e-10, 8.0792262e-10, ...,\n         8.0796042e-10, 8.0796181e-10, 8.0796331e-10]],\n\n       [[4.8373788e-11, 4.8373711e-11, 4.8373645e-11, ...,\n         4.8377212e-11, 4.8377392e-11, 4.8377573e-11],\n        [1.6216743e-11, 1.6300355e-11, 1.6300242e-11, ...,\n         9.9929100e-11, 9.9903898e-11, 9.9897722e-11],\n        [1.6222215e-11, 1.6223784e-11, 1.6226818e-11, ...,\n         9.9919122e-11, 9.9897909e-11, 9.9892851e-11],\n...\n        [1.2932498e-09, 1.2932503e-09, 1.2932567e-09, ...,\n         1.2929462e-09, 1.2929313e-09, 1.2928540e-09],\n        [1.2932498e-09, 1.2936645e-09, 1.2936429e-09, ...,\n         1.2944885e-09, 1.2945151e-09, 1.2928540e-09],\n        [1.2952455e-09, 1.2952455e-09, 1.2952455e-09, ...,\n         1.2952455e-09, 1.2952455e-09, 1.2952455e-09]],\n\n       [[1.3088649e-09, 1.3088649e-09, 1.3088649e-09, ...,\n         1.3088649e-09, 1.3088649e-09, 1.3088649e-09],\n        [1.3110013e-09, 1.3099452e-09, 1.3099236e-09, ...,\n         1.3121275e-09, 1.3121271e-09, 1.3131806e-09],\n        [1.3110013e-09, 1.3109217e-09, 1.3109236e-09, ...,\n         1.3131171e-09, 1.3131758e-09, 1.3131806e-09],\n        ...,\n        [1.3325602e-09, 1.3325523e-09, 1.3325528e-09, ...,\n         1.3367689e-09, 1.3354362e-09, 1.3367826e-09],\n        [1.3325604e-09, 1.3321834e-09, 1.3321892e-09, ...,\n         1.3367548e-09, 1.3367537e-09, 1.3367827e-09],\n        [1.3349080e-09, 1.3349080e-09, 1.3349080e-09, ...,\n         1.3349080e-09, 1.3349080e-09, 1.3349080e-09]]], dtype=float32)\nCoordinates:\n  * lev      (lev) float64 0.9925 0.9775 0.9625 ... 0.0004141 0.0001387 3.8e-05\n  * lat      (lat) float64 27.0 27.25 27.5 27.75 28.0 ... 46.25 46.5 46.75 47.0\n  * lon      (lon) float64 -130.0 -129.7 -129.4 -129.1 ... -110.6 -110.3 -110.0</pre>xarray.DataArray'SpeciesConc_NO2'<ul><li>lev: 47</li><li>lat: 81</li><li>lon: 65</li></ul><ul><li>4.906e-11 4.906e-11 4.906e-11 ... 1.335e-09 1.335e-09 1.335e-09<pre>array([[[4.9062303e-11, 4.9062081e-11, 4.9061859e-11, ...,\n         4.9071434e-11, 4.9071955e-11, 4.9072468e-11],\n        [1.6923058e-11, 1.6950108e-11, 1.6952899e-11, ...,\n         9.9948189e-11, 9.9900643e-11, 9.9872791e-11],\n        [1.6929434e-11, 1.6926667e-11, 1.6934249e-11, ...,\n         9.9928288e-11, 9.9878307e-11, 9.9870709e-11],\n        ...,\n        [8.5456746e-11, 8.5386170e-11, 8.5320598e-11, ...,\n         4.0959905e-10, 4.0894488e-10, 4.1077211e-10],\n        [8.5364313e-11, 8.5232314e-11, 8.5183277e-11, ...,\n         4.0959866e-10, 4.0940437e-10, 4.1138837e-10],\n        [8.0792273e-10, 8.0792262e-10, 8.0792262e-10, ...,\n         8.0796042e-10, 8.0796181e-10, 8.0796331e-10]],\n\n       [[4.8373788e-11, 4.8373711e-11, 4.8373645e-11, ...,\n         4.8377212e-11, 4.8377392e-11, 4.8377573e-11],\n        [1.6216743e-11, 1.6300355e-11, 1.6300242e-11, ...,\n         9.9929100e-11, 9.9903898e-11, 9.9897722e-11],\n        [1.6222215e-11, 1.6223784e-11, 1.6226818e-11, ...,\n         9.9919122e-11, 9.9897909e-11, 9.9892851e-11],\n...\n        [1.2932498e-09, 1.2932503e-09, 1.2932567e-09, ...,\n         1.2929462e-09, 1.2929313e-09, 1.2928540e-09],\n        [1.2932498e-09, 1.2936645e-09, 1.2936429e-09, ...,\n         1.2944885e-09, 1.2945151e-09, 1.2928540e-09],\n        [1.2952455e-09, 1.2952455e-09, 1.2952455e-09, ...,\n         1.2952455e-09, 1.2952455e-09, 1.2952455e-09]],\n\n       [[1.3088649e-09, 1.3088649e-09, 1.3088649e-09, ...,\n         1.3088649e-09, 1.3088649e-09, 1.3088649e-09],\n        [1.3110013e-09, 1.3099452e-09, 1.3099236e-09, ...,\n         1.3121275e-09, 1.3121271e-09, 1.3131806e-09],\n        [1.3110013e-09, 1.3109217e-09, 1.3109236e-09, ...,\n         1.3131171e-09, 1.3131758e-09, 1.3131806e-09],\n        ...,\n        [1.3325602e-09, 1.3325523e-09, 1.3325528e-09, ...,\n         1.3367689e-09, 1.3354362e-09, 1.3367826e-09],\n        [1.3325604e-09, 1.3321834e-09, 1.3321892e-09, ...,\n         1.3367548e-09, 1.3367537e-09, 1.3367827e-09],\n        [1.3349080e-09, 1.3349080e-09, 1.3349080e-09, ...,\n         1.3349080e-09, 1.3349080e-09, 1.3349080e-09]]], dtype=float32)</pre></li><li>Coordinates: (3)<ul><li>lev(lev)float640.9925 0.9775 ... 0.0001387 3.8e-05long_name :hybrid level at midpoints ((A/P0)+B)units :levelaxis :Zpositive :upstandard_name :atmosphere_hybrid_sigma_pressure_coordinateformula_terms :a: hyam b: hybm p0: P0 ps: PS<pre>array([9.925000e-01, 9.774999e-01, 9.624998e-01, 9.475000e-01, 9.325001e-01,\n       9.174999e-01, 9.024999e-01, 8.875000e-01, 8.725000e-01, 8.575001e-01,\n       8.425001e-01, 8.275002e-01, 8.100002e-01, 7.875000e-01, 7.625000e-01,\n       7.375001e-01, 7.125001e-01, 6.875001e-01, 6.562501e-01, 6.187502e-01,\n       5.812502e-01, 5.437501e-01, 5.062501e-01, 4.687501e-01, 4.312501e-01,\n       3.937501e-01, 3.562501e-01, 3.127916e-01, 2.664790e-01, 2.265135e-01,\n       1.925410e-01, 1.636615e-01, 1.391150e-01, 1.182500e-01, 1.005144e-01,\n       8.543901e-02, 6.745011e-02, 4.828166e-02, 3.427161e-02, 2.407970e-02,\n       1.454227e-02, 6.684757e-03, 2.863681e-03, 1.133785e-03, 4.140641e-04,\n       1.386745e-04, 3.800000e-05])</pre></li><li>lat(lat)float6427.0 27.25 27.5 ... 46.5 46.75 47.0long_name :Latitudeunits :degrees_northaxis :Y<pre>array([27.  , 27.25, 27.5 , 27.75, 28.  , 28.25, 28.5 , 28.75, 29.  , 29.25,\n       29.5 , 29.75, 30.  , 30.25, 30.5 , 30.75, 31.  , 31.25, 31.5 , 31.75,\n       32.  , 32.25, 32.5 , 32.75, 33.  , 33.25, 33.5 , 33.75, 34.  , 34.25,\n       34.5 , 34.75, 35.  , 35.25, 35.5 , 35.75, 36.  , 36.25, 36.5 , 36.75,\n       37.  , 37.25, 37.5 , 37.75, 38.  , 38.25, 38.5 , 38.75, 39.  , 39.25,\n       39.5 , 39.75, 40.  , 40.25, 40.5 , 40.75, 41.  , 41.25, 41.5 , 41.75,\n       42.  , 42.25, 42.5 , 42.75, 43.  , 43.25, 43.5 , 43.75, 44.  , 44.25,\n       44.5 , 44.75, 45.  , 45.25, 45.5 , 45.75, 46.  , 46.25, 46.5 , 46.75,\n       47.  ])</pre></li><li>lon(lon)float64-130.0 -129.7 ... -110.3 -110.0long_name :Longitudeunits :degrees_eastaxis :X<pre>array([-130.    , -129.6875, -129.375 , -129.0625, -128.75  , -128.4375,\n       -128.125 , -127.8125, -127.5   , -127.1875, -126.875 , -126.5625,\n       -126.25  , -125.9375, -125.625 , -125.3125, -125.    , -124.6875,\n       -124.375 , -124.0625, -123.75  , -123.4375, -123.125 , -122.8125,\n       -122.5   , -122.1875, -121.875 , -121.5625, -121.25  , -120.9375,\n       -120.625 , -120.3125, -120.    , -119.6875, -119.375 , -119.0625,\n       -118.75  , -118.4375, -118.125 , -117.8125, -117.5   , -117.1875,\n       -116.875 , -116.5625, -116.25  , -115.9375, -115.625 , -115.3125,\n       -115.    , -114.6875, -114.375 , -114.0625, -113.75  , -113.4375,\n       -113.125 , -112.8125, -112.5   , -112.1875, -111.875 , -111.5625,\n       -111.25  , -110.9375, -110.625 , -110.3125, -110.    ])</pre></li></ul></li><li>Indexes: (3)<ul><li>levPandasIndex<pre>PandasIndex(Index([         0.99250002413,          0.97749990013,     0.9624997759999999,\n                  0.947499955,             0.93250006,             0.91749991,\n                   0.90249991,             0.88749996,             0.87249996,\n           0.8575000599999999,            0.842500125,             0.82750016,\n                    0.8100002,     0.7875000200000001,            0.762499965,\n           0.7375001050000001,              0.7125001,              0.6875001,\n                   0.65625015,     0.6187501999999999,             0.58125015,\n                    0.5437501,              0.5062501,    0.46875009999999995,\n          0.43125009999999997,              0.3937501,              0.3562501,\n          0.31279157999999996,             0.26647905,           0.2265135325,\n           0.1925410165877065,     0.1636615040877065,    0.13911500000000002,\n                      0.11825,             0.10051436,            0.085439015,\n                   0.06745011,   0.048281660000000004,   0.034271609999999994,\n         0.024079704999999996,   0.014542270999999999,   0.006684756500000001,\n                 0.0028636805,          0.00113378455, 0.00041406405000000003,\n               0.000138674505, 3.8000004999999996e-05],\n      dtype='float64', name='lev'))</pre></li><li>latPandasIndex<pre>PandasIndex(Index([ 27.0, 27.25,  27.5, 27.75,  28.0, 28.25,  28.5, 28.75,  29.0, 29.25,\n        29.5, 29.75,  30.0, 30.25,  30.5, 30.75,  31.0, 31.25,  31.5, 31.75,\n        32.0, 32.25,  32.5, 32.75,  33.0, 33.25,  33.5, 33.75,  34.0, 34.25,\n        34.5, 34.75,  35.0, 35.25,  35.5, 35.75,  36.0, 36.25,  36.5, 36.75,\n        37.0, 37.25,  37.5, 37.75,  38.0, 38.25,  38.5, 38.75,  39.0, 39.25,\n        39.5, 39.75,  40.0, 40.25,  40.5, 40.75,  41.0, 41.25,  41.5, 41.75,\n        42.0, 42.25,  42.5, 42.75,  43.0, 43.25,  43.5, 43.75,  44.0, 44.25,\n        44.5, 44.75,  45.0, 45.25,  45.5, 45.75,  46.0, 46.25,  46.5, 46.75,\n        47.0],\n      dtype='float64', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([   -130.0, -129.6875,  -129.375, -129.0625,   -128.75, -128.4375,\n        -128.125, -127.8125,    -127.5, -127.1875,  -126.875, -126.5625,\n         -126.25, -125.9375,  -125.625, -125.3125,    -125.0, -124.6875,\n        -124.375, -124.0625,   -123.75, -123.4375,  -123.125, -122.8125,\n          -122.5, -122.1875,  -121.875, -121.5625,   -121.25, -120.9375,\n        -120.625, -120.3125,    -120.0, -119.6875,  -119.375, -119.0625,\n         -118.75, -118.4375,  -118.125, -117.8125,    -117.5, -117.1875,\n        -116.875, -116.5625,   -116.25, -115.9375,  -115.625, -115.3125,\n          -115.0, -114.6875,  -114.375, -114.0625,   -113.75, -113.4375,\n        -113.125, -112.8125,    -112.5, -112.1875,  -111.875, -111.5625,\n         -111.25, -110.9375,  -110.625, -110.3125,    -110.0],\n      dtype='float64', name='lon'))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[8]: Copied! <pre>rolling_mean = ds_multiple.SpeciesConc_NO2.rolling(time=5).mean()  \nrolling_mean  # contains dask array\n</pre> rolling_mean = ds_multiple.SpeciesConc_NO2.rolling(time=5).mean()   rolling_mean  # contains dask array Out[8]: <pre>&lt;xarray.DataArray 'SpeciesConc_NO2' (time: 30, lev: 47, lat: 81, lon: 65)&gt;\ndask.array&lt;truediv, shape=(30, 47, 81, 65), dtype=float32, chunksize=(5, 47, 81, 65), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * time     (time) datetime64[ns] 2020-09-01T21:30:00 ... 2020-09-30T21:30:00\n  * lev      (lev) float64 0.9925 0.9775 0.9625 ... 0.0004141 0.0001387 3.8e-05\n  * lat      (lat) float64 27.0 27.25 27.5 27.75 28.0 ... 46.25 46.5 46.75 47.0\n  * lon      (lon) float64 -130.0 -129.7 -129.4 -129.1 ... -110.6 -110.3 -110.0\nAttributes:\n    long_name:         Dry mixing ratio of species NO2\n    units:             mol mol-1 dry\n    averaging_method:  time-averaged</pre>xarray.DataArray'SpeciesConc_NO2'<ul><li>time: 30</li><li>lev: 47</li><li>lat: 81</li><li>lon: 65</li></ul><ul><li>dask.array&lt;chunksize=(5, 47, 81, 65), meta=np.ndarray&gt;  Array   Chunk   Bytes   28.32 MiB   4.72 MiB   Shape   (30, 47, 81, 65)   (5, 47, 81, 65)   Dask graph   6 chunks in 86 graph layers   Data type   float32 numpy.ndarray  30 1 65 81 47 </li><li>Coordinates: (4)<ul><li>time(time)datetime64[ns]2020-09-01T21:30:00 ... 2020-09-...long_name :Timeaxis :T<pre>array(['2020-09-01T21:30:00.000000000', '2020-09-02T21:30:00.000000000',\n       '2020-09-03T21:30:00.000000000', '2020-09-04T21:30:00.000000000',\n       '2020-09-05T21:30:00.000000000', '2020-09-06T21:30:00.000000000',\n       '2020-09-07T21:30:00.000000000', '2020-09-08T21:30:00.000000000',\n       '2020-09-09T21:30:00.000000000', '2020-09-10T21:30:00.000000000',\n       '2020-09-11T21:30:00.000000000', '2020-09-12T21:30:00.000000000',\n       '2020-09-13T21:30:00.000000000', '2020-09-14T21:30:00.000000000',\n       '2020-09-15T21:30:00.000000000', '2020-09-16T21:30:00.000000000',\n       '2020-09-17T21:30:00.000000000', '2020-09-18T21:30:00.000000000',\n       '2020-09-19T21:30:00.000000000', '2020-09-20T21:30:00.000000000',\n       '2020-09-21T21:30:00.000000000', '2020-09-22T21:30:00.000000000',\n       '2020-09-23T21:30:00.000000000', '2020-09-24T21:30:00.000000000',\n       '2020-09-25T21:30:00.000000000', '2020-09-26T21:30:00.000000000',\n       '2020-09-27T21:30:00.000000000', '2020-09-28T21:30:00.000000000',\n       '2020-09-29T21:30:00.000000000', '2020-09-30T21:30:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>lev(lev)float640.9925 0.9775 ... 0.0001387 3.8e-05long_name :hybrid level at midpoints ((A/P0)+B)units :levelaxis :Zpositive :upstandard_name :atmosphere_hybrid_sigma_pressure_coordinateformula_terms :a: hyam b: hybm p0: P0 ps: PS<pre>array([9.925000e-01, 9.774999e-01, 9.624998e-01, 9.475000e-01, 9.325001e-01,\n       9.174999e-01, 9.024999e-01, 8.875000e-01, 8.725000e-01, 8.575001e-01,\n       8.425001e-01, 8.275002e-01, 8.100002e-01, 7.875000e-01, 7.625000e-01,\n       7.375001e-01, 7.125001e-01, 6.875001e-01, 6.562501e-01, 6.187502e-01,\n       5.812502e-01, 5.437501e-01, 5.062501e-01, 4.687501e-01, 4.312501e-01,\n       3.937501e-01, 3.562501e-01, 3.127916e-01, 2.664790e-01, 2.265135e-01,\n       1.925410e-01, 1.636615e-01, 1.391150e-01, 1.182500e-01, 1.005144e-01,\n       8.543901e-02, 6.745011e-02, 4.828166e-02, 3.427161e-02, 2.407970e-02,\n       1.454227e-02, 6.684757e-03, 2.863681e-03, 1.133785e-03, 4.140641e-04,\n       1.386745e-04, 3.800000e-05])</pre></li><li>lat(lat)float6427.0 27.25 27.5 ... 46.5 46.75 47.0long_name :Latitudeunits :degrees_northaxis :Y<pre>array([27.  , 27.25, 27.5 , 27.75, 28.  , 28.25, 28.5 , 28.75, 29.  , 29.25,\n       29.5 , 29.75, 30.  , 30.25, 30.5 , 30.75, 31.  , 31.25, 31.5 , 31.75,\n       32.  , 32.25, 32.5 , 32.75, 33.  , 33.25, 33.5 , 33.75, 34.  , 34.25,\n       34.5 , 34.75, 35.  , 35.25, 35.5 , 35.75, 36.  , 36.25, 36.5 , 36.75,\n       37.  , 37.25, 37.5 , 37.75, 38.  , 38.25, 38.5 , 38.75, 39.  , 39.25,\n       39.5 , 39.75, 40.  , 40.25, 40.5 , 40.75, 41.  , 41.25, 41.5 , 41.75,\n       42.  , 42.25, 42.5 , 42.75, 43.  , 43.25, 43.5 , 43.75, 44.  , 44.25,\n       44.5 , 44.75, 45.  , 45.25, 45.5 , 45.75, 46.  , 46.25, 46.5 , 46.75,\n       47.  ])</pre></li><li>lon(lon)float64-130.0 -129.7 ... -110.3 -110.0long_name :Longitudeunits :degrees_eastaxis :X<pre>array([-130.    , -129.6875, -129.375 , -129.0625, -128.75  , -128.4375,\n       -128.125 , -127.8125, -127.5   , -127.1875, -126.875 , -126.5625,\n       -126.25  , -125.9375, -125.625 , -125.3125, -125.    , -124.6875,\n       -124.375 , -124.0625, -123.75  , -123.4375, -123.125 , -122.8125,\n       -122.5   , -122.1875, -121.875 , -121.5625, -121.25  , -120.9375,\n       -120.625 , -120.3125, -120.    , -119.6875, -119.375 , -119.0625,\n       -118.75  , -118.4375, -118.125 , -117.8125, -117.5   , -117.1875,\n       -116.875 , -116.5625, -116.25  , -115.9375, -115.625 , -115.3125,\n       -115.    , -114.6875, -114.375 , -114.0625, -113.75  , -113.4375,\n       -113.125 , -112.8125, -112.5   , -112.1875, -111.875 , -111.5625,\n       -111.25  , -110.9375, -110.625 , -110.3125, -110.    ])</pre></li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2020-09-01 21:30:00', '2020-09-02 21:30:00',\n               '2020-09-03 21:30:00', '2020-09-04 21:30:00',\n               '2020-09-05 21:30:00', '2020-09-06 21:30:00',\n               '2020-09-07 21:30:00', '2020-09-08 21:30:00',\n               '2020-09-09 21:30:00', '2020-09-10 21:30:00',\n               '2020-09-11 21:30:00', '2020-09-12 21:30:00',\n               '2020-09-13 21:30:00', '2020-09-14 21:30:00',\n               '2020-09-15 21:30:00', '2020-09-16 21:30:00',\n               '2020-09-17 21:30:00', '2020-09-18 21:30:00',\n               '2020-09-19 21:30:00', '2020-09-20 21:30:00',\n               '2020-09-21 21:30:00', '2020-09-22 21:30:00',\n               '2020-09-23 21:30:00', '2020-09-24 21:30:00',\n               '2020-09-25 21:30:00', '2020-09-26 21:30:00',\n               '2020-09-27 21:30:00', '2020-09-28 21:30:00',\n               '2020-09-29 21:30:00', '2020-09-30 21:30:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li><li>levPandasIndex<pre>PandasIndex(Index([         0.99250002413,          0.97749990013,     0.9624997759999999,\n                  0.947499955,             0.93250006,             0.91749991,\n                   0.90249991,             0.88749996,             0.87249996,\n           0.8575000599999999,            0.842500125,             0.82750016,\n                    0.8100002,     0.7875000200000001,            0.762499965,\n           0.7375001050000001,              0.7125001,              0.6875001,\n                   0.65625015,     0.6187501999999999,             0.58125015,\n                    0.5437501,              0.5062501,    0.46875009999999995,\n          0.43125009999999997,              0.3937501,              0.3562501,\n          0.31279157999999996,             0.26647905,           0.2265135325,\n           0.1925410165877065,     0.1636615040877065,    0.13911500000000002,\n                      0.11825,             0.10051436,            0.085439015,\n                   0.06745011,   0.048281660000000004,   0.034271609999999994,\n         0.024079704999999996,   0.014542270999999999,   0.006684756500000001,\n                 0.0028636805,          0.00113378455, 0.00041406405000000003,\n               0.000138674505, 3.8000004999999996e-05],\n      dtype='float64', name='lev'))</pre></li><li>latPandasIndex<pre>PandasIndex(Index([ 27.0, 27.25,  27.5, 27.75,  28.0, 28.25,  28.5, 28.75,  29.0, 29.25,\n        29.5, 29.75,  30.0, 30.25,  30.5, 30.75,  31.0, 31.25,  31.5, 31.75,\n        32.0, 32.25,  32.5, 32.75,  33.0, 33.25,  33.5, 33.75,  34.0, 34.25,\n        34.5, 34.75,  35.0, 35.25,  35.5, 35.75,  36.0, 36.25,  36.5, 36.75,\n        37.0, 37.25,  37.5, 37.75,  38.0, 38.25,  38.5, 38.75,  39.0, 39.25,\n        39.5, 39.75,  40.0, 40.25,  40.5, 40.75,  41.0, 41.25,  41.5, 41.75,\n        42.0, 42.25,  42.5, 42.75,  43.0, 43.25,  43.5, 43.75,  44.0, 44.25,\n        44.5, 44.75,  45.0, 45.25,  45.5, 45.75,  46.0, 46.25,  46.5, 46.75,\n        47.0],\n      dtype='float64', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([   -130.0, -129.6875,  -129.375, -129.0625,   -128.75, -128.4375,\n        -128.125, -127.8125,    -127.5, -127.1875,  -126.875, -126.5625,\n         -126.25, -125.9375,  -125.625, -125.3125,    -125.0, -124.6875,\n        -124.375, -124.0625,   -123.75, -123.4375,  -123.125, -122.8125,\n          -122.5, -122.1875,  -121.875, -121.5625,   -121.25, -120.9375,\n        -120.625, -120.3125,    -120.0, -119.6875,  -119.375, -119.0625,\n         -118.75, -118.4375,  -118.125, -117.8125,    -117.5, -117.1875,\n        -116.875, -116.5625,   -116.25, -115.9375,  -115.625, -115.3125,\n          -115.0, -114.6875,  -114.375, -114.0625,   -113.75, -113.4375,\n        -113.125, -112.8125,    -112.5, -112.1875,  -111.875, -111.5625,\n         -111.25, -110.9375,  -110.625, -110.3125,    -110.0],\n      dtype='float64', name='lon'))</pre></li></ul></li><li>Attributes: (3)long_name :Dry mixing ratio of species NO2units :mol mol-1 dryaveraging_method :time-averaged</li></ul> In\u00a0[9]: Copied! <pre>computed = rolling_mean.compute()  \ncomputed  # has real numpy values\n</pre> computed = rolling_mean.compute()   computed  # has real numpy values Out[9]: <pre>&lt;xarray.DataArray 'SpeciesConc_NO2' (time: 30, lev: 47, lat: 81, lon: 65)&gt;\narray([[[[           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         ...,\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan]],\n\n        [[           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n...\n          1.27299549e-09, 1.27348032e-09, 1.27298894e-09],\n         [1.27392474e-09, 1.27276323e-09, 1.27275179e-09, ...,\n          1.27361832e-09, 1.27358102e-09, 1.27298905e-09],\n         [1.27646427e-09, 1.27646427e-09, 1.27646427e-09, ...,\n          1.27646427e-09, 1.27646427e-09, 1.27646427e-09]],\n\n        [[1.25867883e-09, 1.25867883e-09, 1.25867883e-09, ...,\n          1.25867883e-09, 1.25867883e-09, 1.25867883e-09],\n         [1.25231525e-09, 1.25114186e-09, 1.25108790e-09, ...,\n          1.25833632e-09, 1.25830835e-09, 1.25872757e-09],\n         [1.25231525e-09, 1.25225497e-09, 1.25224831e-09, ...,\n          1.25869781e-09, 1.25869914e-09, 1.25872757e-09],\n         ...,\n         [1.28924105e-09, 1.28924049e-09, 1.28924071e-09, ...,\n          1.29703770e-09, 1.29703892e-09, 1.29704647e-09],\n         [1.28924105e-09, 1.28915789e-09, 1.28917210e-09, ...,\n          1.29697664e-09, 1.29696454e-09, 1.29704658e-09],\n         [1.29171085e-09, 1.29171085e-09, 1.29171085e-09, ...,\n          1.29171085e-09, 1.29171085e-09, 1.29171085e-09]]]],\n      dtype=float32)\nCoordinates:\n  * time     (time) datetime64[ns] 2020-09-01T21:30:00 ... 2020-09-30T21:30:00\n  * lev      (lev) float64 0.9925 0.9775 0.9625 ... 0.0004141 0.0001387 3.8e-05\n  * lat      (lat) float64 27.0 27.25 27.5 27.75 28.0 ... 46.25 46.5 46.75 47.0\n  * lon      (lon) float64 -130.0 -129.7 -129.4 -129.1 ... -110.6 -110.3 -110.0\nAttributes:\n    long_name:         Dry mixing ratio of species NO2\n    units:             mol mol-1 dry\n    averaging_method:  time-averaged</pre>xarray.DataArray'SpeciesConc_NO2'<ul><li>time: 30</li><li>lev: 47</li><li>lat: 81</li><li>lon: 65</li></ul><ul><li>nan nan nan nan nan ... 1.292e-09 1.292e-09 1.292e-09 1.292e-09<pre>array([[[[           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         ...,\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan]],\n\n        [[           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n         [           nan,            nan,            nan, ...,\n                     nan,            nan,            nan],\n...\n          1.27299549e-09, 1.27348032e-09, 1.27298894e-09],\n         [1.27392474e-09, 1.27276323e-09, 1.27275179e-09, ...,\n          1.27361832e-09, 1.27358102e-09, 1.27298905e-09],\n         [1.27646427e-09, 1.27646427e-09, 1.27646427e-09, ...,\n          1.27646427e-09, 1.27646427e-09, 1.27646427e-09]],\n\n        [[1.25867883e-09, 1.25867883e-09, 1.25867883e-09, ...,\n          1.25867883e-09, 1.25867883e-09, 1.25867883e-09],\n         [1.25231525e-09, 1.25114186e-09, 1.25108790e-09, ...,\n          1.25833632e-09, 1.25830835e-09, 1.25872757e-09],\n         [1.25231525e-09, 1.25225497e-09, 1.25224831e-09, ...,\n          1.25869781e-09, 1.25869914e-09, 1.25872757e-09],\n         ...,\n         [1.28924105e-09, 1.28924049e-09, 1.28924071e-09, ...,\n          1.29703770e-09, 1.29703892e-09, 1.29704647e-09],\n         [1.28924105e-09, 1.28915789e-09, 1.28917210e-09, ...,\n          1.29697664e-09, 1.29696454e-09, 1.29704658e-09],\n         [1.29171085e-09, 1.29171085e-09, 1.29171085e-09, ...,\n          1.29171085e-09, 1.29171085e-09, 1.29171085e-09]]]],\n      dtype=float32)</pre></li><li>Coordinates: (4)<ul><li>time(time)datetime64[ns]2020-09-01T21:30:00 ... 2020-09-...long_name :Timeaxis :T<pre>array(['2020-09-01T21:30:00.000000000', '2020-09-02T21:30:00.000000000',\n       '2020-09-03T21:30:00.000000000', '2020-09-04T21:30:00.000000000',\n       '2020-09-05T21:30:00.000000000', '2020-09-06T21:30:00.000000000',\n       '2020-09-07T21:30:00.000000000', '2020-09-08T21:30:00.000000000',\n       '2020-09-09T21:30:00.000000000', '2020-09-10T21:30:00.000000000',\n       '2020-09-11T21:30:00.000000000', '2020-09-12T21:30:00.000000000',\n       '2020-09-13T21:30:00.000000000', '2020-09-14T21:30:00.000000000',\n       '2020-09-15T21:30:00.000000000', '2020-09-16T21:30:00.000000000',\n       '2020-09-17T21:30:00.000000000', '2020-09-18T21:30:00.000000000',\n       '2020-09-19T21:30:00.000000000', '2020-09-20T21:30:00.000000000',\n       '2020-09-21T21:30:00.000000000', '2020-09-22T21:30:00.000000000',\n       '2020-09-23T21:30:00.000000000', '2020-09-24T21:30:00.000000000',\n       '2020-09-25T21:30:00.000000000', '2020-09-26T21:30:00.000000000',\n       '2020-09-27T21:30:00.000000000', '2020-09-28T21:30:00.000000000',\n       '2020-09-29T21:30:00.000000000', '2020-09-30T21:30:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>lev(lev)float640.9925 0.9775 ... 0.0001387 3.8e-05long_name :hybrid level at midpoints ((A/P0)+B)units :levelaxis :Zpositive :upstandard_name :atmosphere_hybrid_sigma_pressure_coordinateformula_terms :a: hyam b: hybm p0: P0 ps: PS<pre>array([9.925000e-01, 9.774999e-01, 9.624998e-01, 9.475000e-01, 9.325001e-01,\n       9.174999e-01, 9.024999e-01, 8.875000e-01, 8.725000e-01, 8.575001e-01,\n       8.425001e-01, 8.275002e-01, 8.100002e-01, 7.875000e-01, 7.625000e-01,\n       7.375001e-01, 7.125001e-01, 6.875001e-01, 6.562501e-01, 6.187502e-01,\n       5.812502e-01, 5.437501e-01, 5.062501e-01, 4.687501e-01, 4.312501e-01,\n       3.937501e-01, 3.562501e-01, 3.127916e-01, 2.664790e-01, 2.265135e-01,\n       1.925410e-01, 1.636615e-01, 1.391150e-01, 1.182500e-01, 1.005144e-01,\n       8.543901e-02, 6.745011e-02, 4.828166e-02, 3.427161e-02, 2.407970e-02,\n       1.454227e-02, 6.684757e-03, 2.863681e-03, 1.133785e-03, 4.140641e-04,\n       1.386745e-04, 3.800000e-05])</pre></li><li>lat(lat)float6427.0 27.25 27.5 ... 46.5 46.75 47.0long_name :Latitudeunits :degrees_northaxis :Y<pre>array([27.  , 27.25, 27.5 , 27.75, 28.  , 28.25, 28.5 , 28.75, 29.  , 29.25,\n       29.5 , 29.75, 30.  , 30.25, 30.5 , 30.75, 31.  , 31.25, 31.5 , 31.75,\n       32.  , 32.25, 32.5 , 32.75, 33.  , 33.25, 33.5 , 33.75, 34.  , 34.25,\n       34.5 , 34.75, 35.  , 35.25, 35.5 , 35.75, 36.  , 36.25, 36.5 , 36.75,\n       37.  , 37.25, 37.5 , 37.75, 38.  , 38.25, 38.5 , 38.75, 39.  , 39.25,\n       39.5 , 39.75, 40.  , 40.25, 40.5 , 40.75, 41.  , 41.25, 41.5 , 41.75,\n       42.  , 42.25, 42.5 , 42.75, 43.  , 43.25, 43.5 , 43.75, 44.  , 44.25,\n       44.5 , 44.75, 45.  , 45.25, 45.5 , 45.75, 46.  , 46.25, 46.5 , 46.75,\n       47.  ])</pre></li><li>lon(lon)float64-130.0 -129.7 ... -110.3 -110.0long_name :Longitudeunits :degrees_eastaxis :X<pre>array([-130.    , -129.6875, -129.375 , -129.0625, -128.75  , -128.4375,\n       -128.125 , -127.8125, -127.5   , -127.1875, -126.875 , -126.5625,\n       -126.25  , -125.9375, -125.625 , -125.3125, -125.    , -124.6875,\n       -124.375 , -124.0625, -123.75  , -123.4375, -123.125 , -122.8125,\n       -122.5   , -122.1875, -121.875 , -121.5625, -121.25  , -120.9375,\n       -120.625 , -120.3125, -120.    , -119.6875, -119.375 , -119.0625,\n       -118.75  , -118.4375, -118.125 , -117.8125, -117.5   , -117.1875,\n       -116.875 , -116.5625, -116.25  , -115.9375, -115.625 , -115.3125,\n       -115.    , -114.6875, -114.375 , -114.0625, -113.75  , -113.4375,\n       -113.125 , -112.8125, -112.5   , -112.1875, -111.875 , -111.5625,\n       -111.25  , -110.9375, -110.625 , -110.3125, -110.    ])</pre></li></ul></li><li>Indexes: (4)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2020-09-01 21:30:00', '2020-09-02 21:30:00',\n               '2020-09-03 21:30:00', '2020-09-04 21:30:00',\n               '2020-09-05 21:30:00', '2020-09-06 21:30:00',\n               '2020-09-07 21:30:00', '2020-09-08 21:30:00',\n               '2020-09-09 21:30:00', '2020-09-10 21:30:00',\n               '2020-09-11 21:30:00', '2020-09-12 21:30:00',\n               '2020-09-13 21:30:00', '2020-09-14 21:30:00',\n               '2020-09-15 21:30:00', '2020-09-16 21:30:00',\n               '2020-09-17 21:30:00', '2020-09-18 21:30:00',\n               '2020-09-19 21:30:00', '2020-09-20 21:30:00',\n               '2020-09-21 21:30:00', '2020-09-22 21:30:00',\n               '2020-09-23 21:30:00', '2020-09-24 21:30:00',\n               '2020-09-25 21:30:00', '2020-09-26 21:30:00',\n               '2020-09-27 21:30:00', '2020-09-28 21:30:00',\n               '2020-09-29 21:30:00', '2020-09-30 21:30:00'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li><li>levPandasIndex<pre>PandasIndex(Index([         0.99250002413,          0.97749990013,     0.9624997759999999,\n                  0.947499955,             0.93250006,             0.91749991,\n                   0.90249991,             0.88749996,             0.87249996,\n           0.8575000599999999,            0.842500125,             0.82750016,\n                    0.8100002,     0.7875000200000001,            0.762499965,\n           0.7375001050000001,              0.7125001,              0.6875001,\n                   0.65625015,     0.6187501999999999,             0.58125015,\n                    0.5437501,              0.5062501,    0.46875009999999995,\n          0.43125009999999997,              0.3937501,              0.3562501,\n          0.31279157999999996,             0.26647905,           0.2265135325,\n           0.1925410165877065,     0.1636615040877065,    0.13911500000000002,\n                      0.11825,             0.10051436,            0.085439015,\n                   0.06745011,   0.048281660000000004,   0.034271609999999994,\n         0.024079704999999996,   0.014542270999999999,   0.006684756500000001,\n                 0.0028636805,          0.00113378455, 0.00041406405000000003,\n               0.000138674505, 3.8000004999999996e-05],\n      dtype='float64', name='lev'))</pre></li><li>latPandasIndex<pre>PandasIndex(Index([ 27.0, 27.25,  27.5, 27.75,  28.0, 28.25,  28.5, 28.75,  29.0, 29.25,\n        29.5, 29.75,  30.0, 30.25,  30.5, 30.75,  31.0, 31.25,  31.5, 31.75,\n        32.0, 32.25,  32.5, 32.75,  33.0, 33.25,  33.5, 33.75,  34.0, 34.25,\n        34.5, 34.75,  35.0, 35.25,  35.5, 35.75,  36.0, 36.25,  36.5, 36.75,\n        37.0, 37.25,  37.5, 37.75,  38.0, 38.25,  38.5, 38.75,  39.0, 39.25,\n        39.5, 39.75,  40.0, 40.25,  40.5, 40.75,  41.0, 41.25,  41.5, 41.75,\n        42.0, 42.25,  42.5, 42.75,  43.0, 43.25,  43.5, 43.75,  44.0, 44.25,\n        44.5, 44.75,  45.0, 45.25,  45.5, 45.75,  46.0, 46.25,  46.5, 46.75,\n        47.0],\n      dtype='float64', name='lat'))</pre></li><li>lonPandasIndex<pre>PandasIndex(Index([   -130.0, -129.6875,  -129.375, -129.0625,   -128.75, -128.4375,\n        -128.125, -127.8125,    -127.5, -127.1875,  -126.875, -126.5625,\n         -126.25, -125.9375,  -125.625, -125.3125,    -125.0, -124.6875,\n        -124.375, -124.0625,   -123.75, -123.4375,  -123.125, -122.8125,\n          -122.5, -122.1875,  -121.875, -121.5625,   -121.25, -120.9375,\n        -120.625, -120.3125,    -120.0, -119.6875,  -119.375, -119.0625,\n         -118.75, -118.4375,  -118.125, -117.8125,    -117.5, -117.1875,\n        -116.875, -116.5625,   -116.25, -115.9375,  -115.625, -115.3125,\n          -115.0, -114.6875,  -114.375, -114.0625,   -113.75, -113.4375,\n        -113.125, -112.8125,    -112.5, -112.1875,  -111.875, -111.5625,\n         -111.25, -110.9375,  -110.625, -110.3125,    -110.0],\n      dtype='float64', name='lon'))</pre></li></ul></li><li>Attributes: (3)long_name :Dry mixing ratio of species NO2units :mol mol-1 dryaveraging_method :time-averaged</li></ul> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Lecture_9_Dask_Parallel_Computing/#lecture-9-dask-for-parellel-computing-and-big-data","title":"Lecture 9 Dask for Parellel Computing and Big Data\u00b6","text":""},{"location":"Lecture_9_Dask_Parallel_Computing/#what-is-dask","title":"What is Dask?\u00b6","text":"<p>Dask is a tool that helps us easily extend our familiar python data analysis tools to medium and big data, i.e. dataset that can't fit in our computer's RAM. In many cases, dask also allows us to speed up our analysis by using mutiple CPU cores. Dask can help us work more efficiently on our laptop, and it can also help us scale up our analysis on HPC and cloud platforms. Most importantly, dask is almost invisible to the user, meaning that you can focus on your science, rather than the details of parallel computing.</p> <p>Dask was created by the brilliant Matt Rocklin. You can learn more about it on</p> <ul> <li>The Dask Documentation</li> <li>The Dask Github Site</li> </ul> <p>Dask provides collections for big data and a scheduler for parallel computing.</p>"},{"location":"Lecture_9_Dask_Parallel_Computing/#dask-arrays","title":"Dask Arrays\u00b6","text":"<p>A dask array looks and feels a lot like a numpy array. However, a dask array doesn't directly hold any data. Instead, it symbolically represents the computations needed to generate the data. Nothing is actually computed until the actual numerical values are needed. This mode of operation is called \"lazy\"; it allows one to build up complex, large calculations symbolically before turning them over the scheduler for execution.</p> <p>If we want to create a numpy array of all ones, we do it like this:</p>"},{"location":"Lecture_9_Dask_Parallel_Computing/#a-bigger-calculation","title":"A Bigger Calculation\u00b6","text":"<p>The examples above were toy examples; the data (32 MB) is nowhere nearly big enough to warrant the use of dask.</p> <p>We can make it a lot bigger!</p>"},{"location":"Lecture_9_Dask_Parallel_Computing/#reduction","title":"Reduction\u00b6","text":"<p>All the usual numpy methods work on dask arrays. You can also apply numpy function directly to a dask array, and it will stay lazy.</p>"},{"location":"Lecture_9_Dask_Parallel_Computing/#dask-xarray","title":"Dask + Xarray\u00b6","text":""},{"location":"Lecture_9_Dask_Parallel_Computing/#extracting-underlying-data","title":"Extracting underlying data\u00b6","text":"<p>There are two ways to pull out the underlying array object in an xarray object.</p> <ol> <li><code>.to_numpy</code> or <code>.values</code> will always return a NumPy array. For dask-backed xarray objects, this means that compute will always be called</li> <li><code>.data</code> will return a Dask array</li> </ol> <pre><code>{tip}\nUse `to_numpy` or `as_numpy` instead of `.values` so that your code generalizes to other array types (like CuPy arrays, sparse arrays)\n</code></pre>"},{"location":"Lecture_9_Dask_Parallel_Computing/#lazy-computation","title":"Lazy computation\u00b6","text":"<p>Xarray seamlessly wraps dask so all computation is deferred until explicitly requested.</p>"},{"location":"Lecture_9_Dask_Parallel_Computing/#getting-concrete-values","title":"Getting concrete values\u00b6","text":"<p>At some point, you will want to actually get concrete values (usually a numpy array) from dask.</p> <p>There are two ways to compute values on dask arrays.</p> <ol> <li><code>.compute()</code> returns an xarray object just like a dask array</li> <li><code>.load()</code> replaces the dask array in the xarray object with a numpy array. This is equivalent to <code>ds = ds.compute()</code></li> </ol>"},{"location":"Lecture_9_Dask_Parallel_Computing/#reading-multi-file-dataset-with-dask","title":"Reading multi-file dataset with dask\u00b6","text":""},{"location":"Schedule/","title":"Schedule","text":""},{"location":"Schedule/#schedule","title":"Schedule","text":"date topic Assignment Sept 11 Course introduction Sept 18 Intro to Unix Shell, Python Environment, Core Python Language Amarel &amp; GitHub Account Sept 25 Intro to Git, Functions and Classes Assignment 1 due Oct 2 Basic Python: Numpy and Matplotlib Assignment 2 due Oct 9 Guest lecture: Introduction to Amarel Oct 16 Python for Tabular Data: Basic Pandas Assignment 3 Due Oct 23 Python for Tabular Data: Advanced Pandas Final Project Topic Due Oct 30 Python for Multidimensional Data: Xarray Assignment 4 Due Nov 6 Dask for Big Data Nov 13 Making Maps: Cartopy Assignment 5  Due Nov 20 Environmental Sciences Packages: GeoPandas Assignment 6 Due Nov 27 Reproducible Research: Python Packaging and Distribution, Binder Dec 4 Big Data: Cloud Computing Final Project Part I &amp; Assignment 7 Due Dec 11 No Class Final Project Part II Due"},{"location":"Syllabus/","title":"Syllabus","text":""},{"location":"Syllabus/#part-1-course-information","title":"Part 1: Course Information","text":"<p>Class Time: Monday, 2 to 5 PM  Location: ENR 323</p>"},{"location":"Syllabus/#instructor","title":"Instructor:","text":"<p>Xiaomeng Jin Department of Environmental Sciences Office: ENR 230 Email: xiaomeng.jin@rutgers.edu Office Hour: Friday, 1 \u2013 2 PM</p>"},{"location":"Syllabus/#part-2-overview","title":"Part 2: Overview","text":"<p>This course will introduce modern computing software, programming tools and best practices for open-source research that are transparent, accessible, reproducible and inclusive. The course consists of three components:   (1) Introduction to programming in the open-source Python language and in-depth exploration of the numerical analysis and visualization packages that comprise the modern scientific Python ecosystem;  (2) Introduction to the concept of open science and best practices for conducting open-source research;   (3) Introduction to cloud and parallel computing for big data analysis. The course is designed to be accessible for graduate students in atmospheric science, environmental sciences or other disciplines in earth sciences.  Student learning will be facilitated through a combination of lectures, in-class exercises, homework assignments and class projects.</p>"},{"location":"Syllabus/#part-3-course-structure","title":"Part 3: Course Structure","text":"<p>Format: The instructor will present new materials in the first half of the lecture. The second half of the class will be flipped: students will work first in small groups and then individually on assignments.  Textbook: There is no required textbook. All materials will come from free online resources and the course website itself.  Computers: Students can either bring their laptops or use the computers in ENR 323. Students will use Amarel, the university\u2019s high performance computing cluster, to work on their assignments and final project.  </p>"},{"location":"Syllabus/#part-4-grading-policy","title":"Part 4: Grading Policy","text":""},{"location":"Syllabus/#weekly-assignments-70","title":"Weekly Assignments (70%)","text":"<p>\u2022   Total: 100 \u2022   All questions complete: 50 \u2022   All questions correct: 30  \u2022   Clean, elegant, efficient code: rate between 0 and 10  \u2022   Clear comments and explanations: rate between 0 and 10  \u2022   Late penalty: -20 per day (24 hrs) \u2022   Lowest grade on an assignment will be dropped. </p>"},{"location":"Syllabus/#final-project-30","title":"Final Project (30%)","text":"<p> Part I: Individual Project (20%)  The goal of the final project is to assess your ability to combine and apply the skills you have learned in class in the context of a real-world research problem. Our class has mostly focused on tools for data analysis and visualization, so this must be the focus of your final project. Specifically, we seek to assess your ability to do the following tasks:  \u2022   Discover and download real datasets in standard formats (e.g. CSV, netCDF)  \u2022   Load the data into pandas or xarray, performing any necessary data cleanup (dealing with missing values, proper time encoding, etc.) along the way.  \u2022   Perform realistic scientific calculation involving, for example tasks such as grouping, aggregating, and applying mathematical formulas.  \u2022   Visualize your results in well-formatted plots. </p> <p> Part II: Reproducing Another Student\u2019s Project (10%)   The goal of the second part is to assess the reproducibility of the student\u2019s project, and whether the students can reproduce and collaborate with others on code development. Our class focuses on conducting open-source research that are transparent, accessible, reproducible and inclusive, so your final project should demonstrate your understanding and ability to perform open-source research. We seek to assess your ability to:  \u2022   Clearly document your analysis to make it reproducible.  \u2022   Reproduce the other student\u2019s final project.  \u2022   Bonus points will be given if the students submit pull requests and issues for code development. </p>"},{"location":"Untitled/","title":"Untitled","text":"In\u00a0[4]: Copied! <pre>(180*360*48*24*365*4)/1e6/1000\n</pre> (180*360*48*24*365*4)/1e6/1000 Out[4]: <pre>108.988416</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"assignment_1/","title":"Assignment 1 Introduction to Python","text":"<p>Now we will begin the process of reading the file with python</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <p>It should be a familiar type we learned about in class.</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <p>By now you have figured out what is in this data. Let's now transform it into a more useful format.</p> In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied!"},{"location":"assignment_1/#assignment-1-introduction-to-python","title":"Assignment 1 Introduction to Python\u00b6","text":""},{"location":"assignment_1/#preparation","title":"Preparation:\u00b6","text":"<ol> <li>Open the assignment link on Canvas.</li> <li>Accept the assignment and link it with your name.</li> <li>A repository will be created under your name.</li> </ol> <p>Use Amarel to launch a Shell terminal and use the terminal to do the following tasks:</p> <ol> <li>Create a new directory called <code>rcaes</code> within your home directory</li> <li>Go to 'rcaes' directory.</li> <li>GitHub Authentication: gh auth login</li> </ol> <ul> <li>What account do you want to log into? GitHub.com</li> <li>What is your preferred protocol for Git operations? SSH</li> <li>Generate a new SSH key to add to your GitHub account? Yes</li> <li>Enter a passphrase for your new SSH key (Optional) *********</li> <li>Title for your SSH key: GitHub CLI</li> <li>How would you like to authenticate GitHub CLI? Login with a web browser</li> <li>First copy your one-time code: XXXXXX</li> <li>Press Enter to open github.com in your browser... Enter</li> </ul> <ol> <li>In the browser, enter the one-time code.</li> <li>Go back to your GitHub repository.</li> <li>Clone your GitHub repository: 'Code' -&gt; 'GitHub CLI' -&gt; 'gh repo clone rcaes2023/assignment_1-YOURGHNAME'</li> </ol>"},{"location":"assignment_1/#python-lists-and-loops","title":"Python Lists and Loops\u00b6","text":"<p>In this problem, we will explore the basic data structures and flow controls of python by manually parsing a CSV file.</p> <p>Note that this is a futile exercise. In the \"real world\" you should never manually parse a CSV file. There are utilities out there that will do it for you much more quickly and efficiently. However, it is a useful exercise for learning python.</p> <p>Before starting the python part, use the JupyterLab file browser to browse to this file. Click to open it. What do you see?</p>"},{"location":"assignment_1/#open-the-file-using-the-open-function","title":"Open the file using the <code>open</code> function\u00b6","text":"<p>Specifically, run the command</p> <pre><code>file = open('rcaes_roster.csv')</code></pre>"},{"location":"assignment_1/#use-the-help-function-to-get-the-documentation-for-your-new-variable-file","title":"Use the <code>help</code> function to get the documentation for your new variable <code>file</code>\u00b6","text":"<p>This will produce a long list of methods you can use with <code>file</code>.</p>"},{"location":"assignment_1/#read-the-lines-of-the-file-into-a-variable-called-lines","title":"Read the lines of the file into a variable called <code>lines</code>\u00b6","text":"<p>Hint: use the documentation above to find the method that sounds most likely to do what you want.</p>"},{"location":"assignment_1/#display-lines-at-the-end-of-a-cell-in-order-to-see-its-contents","title":"Display <code>lines</code> at the end of a cell in order to see its contents\u00b6","text":""},{"location":"assignment_1/#display-the-number-of-students-in-class","title":"Display the number of students in class\u00b6","text":""},{"location":"assignment_1/#use-slicing-to-display-the-first-three-items-of-the-list-and-the-last-3","title":"Use slicing to display the first three items of the list. And the last 3\u00b6","text":""},{"location":"assignment_1/#now-iterate-through-lines-and-print-the-item-if-it-contains-your-netid","title":"Now iterate through <code>lines</code> and <code>print</code> the item if it contains your NetID\u00b6","text":""},{"location":"assignment_1/#write-code-to-transform-the-data-into-a-dictionary-whose-keys-are-netids-and-whose-values-are-full-names","title":"Write code to transform the data into a dictionary whose keys are NetIDs and whose values are full names.\u00b6","text":"<p>(Hint: You might need to review Python's string methods. You can start with creating an empty dictionary and adding keys/values in a loop.)</p>"},{"location":"assignment_1/#use-this-dictionary-to-look-up-your-own-name-using-your-netid","title":"Use this dictionary to look up your own name using your NetID\u00b6","text":""},{"location":"assignment_1/#figure-out-who-has-the-longest-last-name-in-the-class-bonus-10","title":"Figure out who has the longest last name in the class (Bonus: 10)\u00b6","text":"<p>(Hint: First create a list of last names.)</p>"},{"location":"assignment_1/#assignment-submission","title":"Assignment submission:\u00b6","text":"<p>When you're done with your assignment, submit your assignment using git:</p> <pre><code>git add *\ngit commit -m 'first commit' (or any other message)\ngit push</code></pre>"},{"location":"assignment_2/","title":"Assignment 2: Python Functions and Classes","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied!"},{"location":"assignment_2/#assignment-2-python-functions-and-classes","title":"Assignment 2: Python Functions and Classes\u00b6","text":""},{"location":"assignment_2/#part-i-writing-functions","title":"Part I: Writing Functions\u00b6","text":""},{"location":"assignment_2/#1-write-a-function-to-convert-temperature-from-kelvin-to-celsius-and-another-function-to-covert-from-celsius-to-kelvin","title":"1. Write a function to convert temperature from kelvin to celsius, and another function to covert from celsius to kelvin\u00b6","text":""},{"location":"assignment_2/#2-write-a-function-to-convert-temperature-to-fahrenheit","title":"2. Write a function to convert temperature to fahrenheit\u00b6","text":"<p>Include an optional keyword argument to specify whether the input is in  celcius or kelvin. Call your previously defined functions if necessary.</p>"},{"location":"assignment_2/#3-check-that-the-outputs-are-sensible","title":"3. Check that the outputs are sensible\u00b6","text":"<p>by trying a few examples</p>"},{"location":"assignment_2/#4-now-write-a-function-that-converts-from-farenheit","title":"4. Now write a function that converts from farenheit\u00b6","text":"<p>and uses a keyword argument to specify whether you want the output in celcius or kelvin</p>"},{"location":"assignment_2/#5-write-a-function-that-takes-two-arguments-feet-and-inches-and-returns-height-in-meters","title":"5. Write a function that takes two arguments (feet and inches) and returns height in meters\u00b6","text":"<p>Verify it gives sensible answers</p>"},{"location":"assignment_2/#6-write-a-function-takes-one-argument-height-in-meters-and-returns-two-arguments-feet-and-inches","title":"6. Write a function takes one argument (height in meters) and returns two arguments (feet and inches)\u00b6","text":"<p>(Consult the tutorial on numbers if you are stuck on how to implement this.)</p>"},{"location":"assignment_2/#7-verify-that-the-round-trip-conversion-from-and-back-to-meters-is-consistent","title":"7. Verify that the \"round trip\" conversion from and back to meters is consistent\u00b6","text":"<p>Check for 3 different values of height in meters</p>"},{"location":"assignment_2/#part-iv-classes","title":"Part IV: Classes\u00b6","text":"<p>Write a class that represents a Location. The constructor class should accept the arguments <code>name</code>, <code>latitude</code>, and <code>longitude</code>.</p> <p>Check if the latitude is between -90 to 90, and the longitude is between -180 and 180. Raise ValueError if not.</p> <p>You should implement a method to calculate its relative location to our ENR building:</p> <ul> <li><code>relative_loc_from_ENR</code>: The lat/lon of ENR buidling is: 40.476\u02daN, 74.43\u02daW. Print out if the location is 1) to the north or south or ENR; (2)to the east or west of ENR.</li> </ul>"},{"location":"intro_to_python/","title":"Core Python Language","text":"In\u00a0[1]: Copied! <pre># comments are anything that comes after the \"#\" symbol\na = 1       # assign 1 to variable a\nb = \"hello\" # assign \"hello\" to variable b\n</pre> # comments are anything that comes after the \"#\" symbol a = 1       # assign 1 to variable a b = \"hello\" # assign \"hello\" to variable b <p>The following identifiers are used as reserved words, or keywords of the language, and cannot be used as ordinary identifiers. They must be spelled exactly as written here:</p> <pre><code>False      class      finally    is         return\nNone       continue   for        lambda     try\nTrue       def        from       nonlocal   while\nand        del        global     not        with\nas         elif       if         or         yield\nassert     else       import     pass\nbreak      except     in         raise</code></pre> <p>Additionally, the following a built in functions which are always available in your namespace once you open a python interpreter</p> <pre><code>abs() dict() help() min() setattr() all() dir() hex() next() slice() any()\ndivmod() id() object() sorted() ascii() enumerate() input() oct() staticmethod()\nbin() eval() int() open() str() bool() exec() isinstance() ord() sum() bytearray()\nfilter() issubclass() pow() super() bytes() float() iter() print() tuple()\ncallable() format() len() property() type() chr() frozenset() list() range()\nvars() classmethod() getattr() locals() repr() zip() compile() globals() map()\nreversed() __import__() complex() hasattr() max() round() delattr() hash()\nmemoryview() set()</code></pre> In\u00a0[2]: Copied! <pre># how to we see our variables?\nprint(a)\nprint(b)\nprint(a,b)\n</pre> # how to we see our variables? print(a) print(b) print(a,b) <pre>1\nhello\n1 hello\n</pre> <p>All variables are objects. Every object has a type (class). To find out what type your variables are</p> In\u00a0[3]: Copied! <pre>print(type(a))\nprint(type(b))\n</pre> print(type(a)) print(type(b)) <pre>&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n</pre> In\u00a0[4]: Copied! <pre># as a shortcut, iPython notebooks will automatically print whatever is on the last line\ntype(b)\n</pre> # as a shortcut, iPython notebooks will automatically print whatever is on the last line type(b) Out[4]: <pre>str</pre> In\u00a0[5]: Copied! <pre># we can check for the type of an object\nprint(type(a) is int)\nprint(type(a) is str)\n</pre> # we can check for the type of an object print(type(a) is int) print(type(a) is str) <pre>True\nFalse\n</pre> <p>Different objects attributes and methods, which can be accessed via the syntax <code>variable.method</code></p> <p>IPython will autocomplete if you press <code>&lt;tab&gt;</code> to show you the methods available.</p> In\u00a0[6]: Copied! <pre># this returns the method itself\nb.capitalize\n</pre> # this returns the method itself b.capitalize Out[6]: <pre>&lt;function str.capitalize()&gt;</pre> In\u00a0[7]: Copied! <pre># this calls the method\nb.capitalize()\n# there are lots of other methods\n</pre> # this calls the method b.capitalize() # there are lots of other methods Out[7]: <pre>'Hello'</pre> In\u00a0[8]: Copied! <pre># binary operations act differently on different types of objects\nc = 'World'\nprint(b + c)\nprint(a + 2)\nprint(a + b)\n</pre> # binary operations act differently on different types of objects c = 'World' print(b + c) print(a + 2) print(a + b) <pre>helloWorld\n3\n</pre> <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[8], line 5\n      3 print(b + c)\n      4 print(a + 2)\n----&gt; 5 print(a + b)\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'</pre> In\u00a0[9]: Copied! <pre># addition / subtraction\n1+1-5\n</pre> # addition / subtraction 1+1-5 Out[9]: <pre>-3</pre> In\u00a0[10]: Copied! <pre># multiplication\n5 * 10\n</pre> # multiplication 5 * 10 Out[10]: <pre>50</pre> In\u00a0[11]: Copied! <pre># division\n1/2\n</pre> # division 1/2 Out[11]: <pre>0.5</pre> In\u00a0[12]: Copied! <pre># that was automatically converted to a float\ntype(1/2)\n</pre> # that was automatically converted to a float type(1/2) Out[12]: <pre>float</pre> In\u00a0[13]: Copied! <pre># exponentiation\n2**4\n</pre> # exponentiation 2**4 Out[13]: <pre>16</pre> In\u00a0[14]: Copied! <pre># rounding\nround(9/10)\n</pre> # rounding round(9/10) Out[14]: <pre>1</pre> In\u00a0[15]: Copied! <pre># built in complex number support\n(1+2j) / (3-4j)\n</pre> # built in complex number support (1+2j) / (3-4j) Out[15]: <pre>(-0.2+0.4j)</pre> In\u00a0[16]: Copied! <pre># logic\nTrue and True\n</pre> # logic True and True Out[16]: <pre>True</pre> In\u00a0[17]: Copied! <pre>True and False\n</pre> True and False Out[17]: <pre>False</pre> In\u00a0[18]: Copied! <pre>True or True\n</pre> True or True Out[18]: <pre>True</pre> In\u00a0[19]: Copied! <pre>(not True) or (not False)\n</pre> (not True) or (not False) Out[19]: <pre>True</pre> In\u00a0[20]: Copied! <pre>x = 100\nif x &gt; 0:\n    print('Positive Number')\nelif x &lt; 0:\n    print('Negative Number')\nelse:\n    print ('Zero!')\n</pre> x = 100 if x &gt; 0:     print('Positive Number') elif x &lt; 0:     print('Negative Number') else:     print ('Zero!') <pre>Positive Number\n</pre> In\u00a0[21]: Copied! <pre># indentation is MANDATORY\n# blocks are closed by indentation level\nif x &gt; 0:\n    print('Positive Number')\n    if x &gt;= 100:\n        print('Huge number!')\n</pre> # indentation is MANDATORY # blocks are closed by indentation level if x &gt; 0:     print('Positive Number')     if x &gt;= 100:         print('Huge number!') <pre>Positive Number\nHuge number!\n</pre> In\u00a0[22]: Copied! <pre># make a loop \ncount = 0\nwhile count &lt; 10:\n    # bad way\n    # count = count + 1\n    # better way\n    count += 1\nprint(count)\n</pre> # make a loop  count = 0 while count &lt; 10:     # bad way     # count = count + 1     # better way     count += 1 print(count) <pre>10\n</pre> In\u00a0[23]: Copied! <pre># use range\nfor i in range(5):\n    print(i)\n</pre> # use range for i in range(5):     print(i) <pre>0\n1\n2\n3\n4\n</pre> <p>Important point: in python, we always count from 0!</p> In\u00a0[24]: Copied! <pre># what is range?\ntype(range)\n</pre> # what is range? type(range) Out[24]: <pre>type</pre> In\u00a0[25]: Copied! <pre>range?\n</pre> range? <pre>Init signature: range(self, /, *args, **kwargs)\nDocstring:     \nrange(stop) -&gt; range object\nrange(start, stop[, step]) -&gt; range object\n\nReturn an object that produces a sequence of integers from start (inclusive)\nto stop (exclusive) by step.  range(i, j) produces i, i+1, i+2, ..., j-1.\nstart defaults to 0, and stop is omitted!  range(4) produces 0, 1, 2, 3.\nThese are exactly the valid indices for a list of 4 elements.\nWhen step is given, it specifies the increment (or decrement).\nType:           type\nSubclasses:     </pre> In\u00a0[26]: Copied! <pre># iterate over a list we make up\nfor pet in ['dog', 'cat', 'fish']:\n    print(pet, len(pet))\n</pre> # iterate over a list we make up for pet in ['dog', 'cat', 'fish']:     print(pet, len(pet)) <pre>dog 3\ncat 3\nfish 4\n</pre> <p>What is the thing in brackets? A list! Lists are one of the core python data structures.</p> In\u00a0[27]: Copied! <pre>l = ['dog', 'cat', 'fish']\ntype(l)\n</pre> l = ['dog', 'cat', 'fish'] type(l) Out[27]: <pre>list</pre> In\u00a0[28]: Copied! <pre># list have lots of methods\nl.sort()\nl\n</pre> # list have lots of methods l.sort() l Out[28]: <pre>['cat', 'dog', 'fish']</pre> In\u00a0[29]: Copied! <pre># we can convert a range to a list\nr = list(range(5))\nr\n</pre> # we can convert a range to a list r = list(range(5)) r Out[29]: <pre>[0, 1, 2, 3, 4]</pre> In\u00a0[30]: Copied! <pre>while r:\n    p = r.pop()\n    print('p:', p)\n    print('r:', r)\n</pre> while r:     p = r.pop()     print('p:', p)     print('r:', r) <pre>p: 4\nr: [0, 1, 2, 3]\np: 3\nr: [0, 1, 2]\np: 2\nr: [0, 1]\np: 1\nr: [0]\np: 0\nr: []\n</pre> <p>There are many different ways to interact with lists. Exploring them is part of the fun of python.</p> <p>list.append(x) Add an item to the end of the list. Equivalent to a[len(a):] = [x].</p> <p>list.extend(L) Extend the list by appending all the items in the given list. Equivalent to a[len(a):] = L.</p> <p>list.insert(i, x) Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x).</p> <p>list.remove(x) Remove the first item from the list whose value is x. It is an error if there is no such item.</p> <p>list.pop([i]) Remove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and returns the last item in the list. (The square brackets around the i in the method signature denote that the parameter is optional, not that you should type square brackets at that position. You will see this notation frequently in the Python Library Reference.)</p> <p>list.clear() Remove all items from the list. Equivalent to del a[:].</p> <p>list.index(x) Return the index in the list of the first item whose value is x. It is an error if there is no such item.</p> <p>list.count(x) Return the number of times x appears in the list.</p> <p>list.sort() Sort the items of the list in place.</p> <p>list.reverse() Reverse the elements of the list in place.</p> <p>list.copy() Return a shallow copy of the list. Equivalent to a[:].</p> <p>Don't assume you know how list operations work!</p> In\u00a0[31]: Copied! <pre># \"add\" two lists\nx = list(range(5))\ny = list(range(10,15))\nz = x + y\nz\n</pre> # \"add\" two lists x = list(range(5)) y = list(range(10,15)) z = x + y z Out[31]: <pre>[0, 1, 2, 3, 4, 10, 11, 12, 13, 14]</pre> In\u00a0[32]: Copied! <pre># access items from a list\nprint('first', z[0])\nprint('last', z[-1])\nprint('first 3', z[:3])\nprint('last 3', z[-3:])\nprint('middle, skipping every other item', z[5:10:2])\n</pre> # access items from a list print('first', z[0]) print('last', z[-1]) print('first 3', z[:3]) print('last 3', z[-3:]) print('middle, skipping every other item', z[5:10:2]) <pre>first 0\nlast 14\nfirst 3 [0, 1, 2]\nlast 3 [12, 13, 14]\nmiddle, skipping every other item [10, 12, 14]\n</pre> <p>MEMORIZE THIS SYNTAX! It is central to so much of python and often proves confusing for users coming from other languages.</p> <p>In terms of set notation, python indexing is left inclusive, right exclusive. If you remember this, you will never go wrong.</p> In\u00a0[33]: Copied! <pre># that means we get an error from the following\nN = len(z)\nz[N]\n</pre> # that means we get an error from the following N = len(z) z[N] <pre>\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[33], line 3\n      1 # that means we get an error from the following\n      2 N = len(z)\n----&gt; 3 z[N]\n\nIndexError: list index out of range</pre> In\u00a0[37]: Copied! <pre># this index notation also applies to strings\nname = 'Xiaomeng Jin'\nprint(name[:4])\n</pre> # this index notation also applies to strings name = 'Xiaomeng Jin' print(name[:4]) <pre>Xiao\n</pre> In\u00a0[38]: Copied! <pre>print(name[:-4])\n</pre> print(name[:-4]) <pre>Xiaomeng\n</pre> In\u00a0[39]: Copied! <pre>print(name[-4:])\n</pre> print(name[-4:]) <pre> Jin\n</pre> In\u00a0[40]: Copied! <pre># you can also test for the presence of items in a list\n5 in z\n</pre> # you can also test for the presence of items in a list 5 in z Out[40]: <pre>False</pre> <p>Lists are not meant for math! They don't have a datatype.</p> In\u00a0[41]: Copied! <pre>z[4] = 'fish'\nz\n</pre> z[4] = 'fish' z Out[41]: <pre>[0, 1, 2, 3, 'fish', 10, 11, 12, 13, 14]</pre> <p>Python is full of tricks for iterating and working with lists</p> In\u00a0[42]: Copied! <pre># a cool python trick: list comprehension\nsquares = [n**2 for n in range(5)]\nsquares\n</pre> # a cool python trick: list comprehension squares = [n**2 for n in range(5)] squares Out[42]: <pre>[0, 1, 4, 9, 16]</pre> In\u00a0[43]: Copied! <pre># iterate over two lists together uzing zip\nfor item1, item2 in zip(x,y):\n    print('first:', item1, 'second:', item2)\n</pre> # iterate over two lists together uzing zip for item1, item2 in zip(x,y):     print('first:', item1, 'second:', item2) <pre>first: 0 second: 10\nfirst: 1 second: 11\nfirst: 2 second: 12\nfirst: 3 second: 13\nfirst: 4 second: 14\n</pre> In\u00a0[48]: Copied! <pre># tuples are created with parentheses, or just commas\na = ('Jin', 32, True)\nb = 'Wang', 25, False\ntype(b)\n</pre> # tuples are created with parentheses, or just commas a = ('Jin', 32, True) b = 'Wang', 25, False type(b) Out[48]: <pre>tuple</pre> In\u00a0[50]: Copied! <pre># can be indexed like arrays\nprint(a[1]) # not the first element!\n</pre> # can be indexed like arrays print(a[1]) # not the first element! <pre>32\n</pre> In\u00a0[51]: Copied! <pre># and they can be unpacked\nname, age, status = a\n</pre> # and they can be unpacked name, age, status = a In\u00a0[52]: Copied! <pre># different ways to create dictionaries\nd = {'name': 'Jin', 'age': 32}\ne = dict(name='Wang', age=25)\ne\n</pre> # different ways to create dictionaries d = {'name': 'Jin', 'age': 32} e = dict(name='Wang', age=25) e Out[52]: <pre>{'name': 'Wang', 'age': 25}</pre> In\u00a0[53]: Copied! <pre># access a value\nd['name']\n</pre> # access a value d['name'] Out[53]: <pre>'Jin'</pre> <p>Square brackets <code>[...]</code> are python for \"get item\" in many different contexts.</p> In\u00a0[54]: Copied! <pre># test for the presence of a key\nprint('age' in d)\nprint('height' in e)\n</pre> # test for the presence of a key print('age' in d) print('height' in e) <pre>True\nFalse\n</pre> In\u00a0[55]: Copied! <pre># try to access a non-existant key\nd['height']\n</pre> # try to access a non-existant key d['height'] <pre>\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[55], line 2\n      1 # try to access a non-existant key\n----&gt; 2 d['height']\n\nKeyError: 'height'</pre> In\u00a0[56]: Copied! <pre># add a new key\nd['height'] = (5,3) # a tuple\nd\n</pre> # add a new key d['height'] = (5,3) # a tuple d Out[56]: <pre>{'name': 'Jin', 'age': 32, 'height': (5, 3)}</pre> In\u00a0[60]: Copied! <pre># keys don't have to be strings\nd[99] = 'nighty nine'\nd\n</pre> # keys don't have to be strings d[99] = 'nighty nine' d Out[60]: <pre>{'name': 'Jin', 'age': 32, 'height': (5, 3), 99: 'nighty nine'}</pre> In\u00a0[61]: Copied! <pre># iterate over keys\nfor k in d:\n    print(k, d[k])\n</pre> # iterate over keys for k in d:     print(k, d[k]) <pre>name Jin\nage 32\nheight (5, 3)\n99 nighty nine\n</pre> In\u00a0[62]: Copied! <pre># better way\n### python 2\n### for key, val in d.iteritems()\nfor key, val in d.items():\n    print(key, val)\n</pre> # better way ### python 2 ### for key, val in d.iteritems() for key, val in d.items():     print(key, val) <pre>name Jin\nage 32\nheight (5, 3)\n99 nighty nine\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"intro_to_python/#core-python-language","title":"Core Python Language\u00b6","text":"<p>Mostly copied from the official python tutorial</p>"},{"location":"intro_to_python/#invoking-python","title":"Invoking Python\u00b6","text":"<p>There are three main ways to use python.</p> <ol> <li>By running a python file, e.g. <code>python myscript.py</code></li> <li>Through an interactive console (python interpreter or ipython shell)</li> <li>In an interactive iPython notebook</li> </ol> <p>We will be using the iPython notebook.</p>"},{"location":"intro_to_python/#python-versions","title":"Python Versions\u00b6","text":"<p>There are two versions of the python language out there: python 2 and python 3. Python 2 is more common in the wild but is depracated. The community is moving to python 3. As new python learners, you should learn python 3. But it is important to be aware that python 2 exists. It is possible that a package you want to use is only supported in python 2. In general, it is pretty easy to switch between then.</p> <p>Some of the main changes in python 3 are:</p> <ul> <li><code>print</code> is a function</li> <li>Integer division returns a float</li> <li>Iterators behave differently</li> <li>Unicode is used for encoding code</li> </ul>"},{"location":"intro_to_python/#basic-variables-numbers-and-string","title":"Basic Variables: Numbers and String\u00b6","text":""},{"location":"intro_to_python/#math","title":"Math\u00b6","text":"<p>Basic arithmetic and boolean logic is part of the core python library.</p>"},{"location":"intro_to_python/#conditionals","title":"Conditionals\u00b6","text":"<p>The first step to programming. Plus an intro to python syntax.</p>"},{"location":"intro_to_python/#more-flow-control","title":"More Flow Control\u00b6","text":""},{"location":"intro_to_python/#lists","title":"Lists\u00b6","text":""},{"location":"intro_to_python/#other-data-structures","title":"Other Data Structures\u00b6","text":"<p>We are almost there. We have the building blocks we need to do basic programming. But python has some other data structures we need to learn about.</p>"},{"location":"intro_to_python/#tuples","title":"Tuples\u00b6","text":"<p>Tuples are similar to lists, but they are immutable\u2014they can't be extended or modified. What is the point of this? Generally speaking: to pack together inhomogeneous data. Tuples can then be unpacked and distributed by other parts of your code.</p> <p>Tuples may seem confusing at first, but with time you will come to appreciate them.</p>"},{"location":"intro_to_python/#dictionaries","title":"Dictionaries\u00b6","text":"<p>This is an extremely useful data structure. It maps keys to values.</p> <p>Dictionaries are unordered!</p>"},{"location":"lecture_1_intro/","title":"Lecture 1 Introduction","text":""},{"location":"lecture_1_intro/#presentation-slides-are-posted-on-canvas","title":"Presentation slides are posted on Canvas","text":""},{"location":"lecture_1_intro/#key-points","title":"Key Points","text":"<ol> <li>What is computational research?</li> <li>Data analysis pipeline for computational research. </li> <li>Challenges in research computing: Complexity, Reproducibility, Data Size. </li> <li>Topics we will cover in class.  </li> <li>Class logistics. </li> </ol>"},{"location":"lecture_1_intro/#topics-we-will-cover-in-class","title":"Topics we will cover in class","text":"<ol> <li>Python Programming</li> <li>Open-source Computing</li> <li>Big Data</li> </ol>"},{"location":"lecture_1_intro/#learning-goals","title":"Learning Goals","text":"<ol> <li>Be able to construct complete, well-structured programs in Python.</li> <li>Read and write most common atmospheric and environmental sciences data formats.</li> <li>Perform basic exploratory data analysis.</li> <li>Use visualization to enhance interpretation of environmental science data, including making maps and interactive visualizations.</li> <li>Practice open-source research through version control, packaging etc.</li> <li>Practice big-data analysis with parallel computing.</li> <li>Understand the concepts of cloud computing. </li> </ol>"}]}